{
  "items": [
    {
      "creator": "Forrest Kasler",
      "title": "Like Shooting Phish in a Barrel",
      "link": "https://posts.specterops.io/like-shooting-phish-in-a-barrel-926c1905bb4b?source=rss----f05f8696e3cc---4",
      "pubDate": "Tue, 02 Jul 2024 15:30:23 GMT",
      "content:encoded": "<h4>PHISHING SCHOOL</h4><h4>Bypassing Link Crawlers</h4><p>You’ve just convinced a target user to click your link. In doing so, you have achieved the critical step in social engineering:</p><p><strong>Convincing someone to let you in the door!</strong></p><p>Now, we just have a few more technical controls that might get in the way of us reeling in our catch. The first of which is link crawlers.</p><h3><strong>What’s a Link Crawler?</strong></h3><p>Link crawlers, or “protected links” are one of the most annoying email controls out there. I don’t hate them because of their effectiveness (or ineffectiveness) at blocking phishing. I hate them because they are a real pain for end users and so many secure email gateways (SEGs) use them as a security feature these days. Here’s what they do, and why they suck:</p><h4><strong>What link crawlers do</strong></h4><p>They replace all links in an email with a link to their own web server with some unique ID to look up the original link. Then, when a user clicks a link in the email, they first get sent to purgatory… oops, I mean the “protected link” website. The SEG’s web server looks up the original link, and then sends out a web crawler to check out the content of the link’s webpage. If it looks too phishy, the user will be blocked from accessing the link’s URL. If the crawler thinks the page is benign, it will forward the user on to the original link’s URL.</p><h4><strong>Why link crawlers suck</strong></h4><p>First, have you ever had to reset your password for some web service you rarely use, and they sent you a one-time-use link to start the reset process? If your secure email gateway (SEG) replaces that link with a “safe link”, and has to check out the real link before allowing you to visit it, then guess what? You will never be able to reset your password because your SEG keeps killing your one-time-use links! I know that some link crawlers work in the opposite order (i.e. crawling the link right after the user visits) to get around this problem, but most of them click first, and send the user to a dead one-time-use URL later.</p><p>Second, these link replacements also make it so that the end user actually has no clue where a link is really going to send them. Hovering the link in an email will always show them a URL for the SEG’s link crawling service so there is no way the user can detect a masked link.</p><p>Third, I see these “security features” as really just an overt data grab by the SEGs that implement them. They want to collect valuable user behavior telemetry more than they really care about protecting them from phishing campaigns. I wonder how many SEGs sell this data to the devil… oops, I mean “marketing firms”. It all seems very “big brother” to me.</p><p>Lastly, this control is not even that hard to bypass. I think if link crawlers were extremely effective at blocking phishing attacks, then I would be more forgiving and able to accept their downsides as a necessary evil. However, that is not the case. Let’s go ahead and talk about ways to bypass them!</p><h3><strong>Parser Bypasses</strong></h3><p>Similar to bypassing link filter protections, if the SEG’s link parser doesn’t see our link, then it can’t replace it with a safe link. By focusing on this tactic we can sometimes get two bypasses for the price of one. We’ve already covered this in <a href=\"https://medium.com/specter-ops-posts/feeding-the-phishes-276c3579bba7\">Feeding the Phishes</a>, so I’ll skip the details here.</p><h3><strong>Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA)</strong></h3><p>Link crawlers are just robots. Therefore, to defeat link crawlers, we need to wage war with the robots! We smarty pants humans have employed CAPTCHAs as robot bouncers for decades now to kick them out of our websites. We can use the same approach to protect our phishing pages from crawlers as well. Because SEGs just want a peak at our website content to make a determination of whether it’s benign, there is no real motivation for them to employ any sort of CAPTCHA solver logic. For us, that means our CAPTCHAs don’t even have to be all that complicated or secure like they would need to be to protect a real website. I personally think this approach has been overused and abused by spammers to the point that many users are sketched out by them, but it’s still a valid link crawler bypass for many SEGs and a pretty quick and obvious choice.</p><h4><strong>Fun Fact (think about it)</strong></h4><p><em>Because the test is administered by a computer, in contrast to the standard Turing test that is administered by a human, CAPTCHAs are sometimes described as reverse Turing tests.</em> — Wikipedia</p><h3><strong>Join the Redirect Arms Race</strong></h3><p><strong>Warning: </strong>I don’t actually recommend this, but it works, and therefore we have to talk about it. I’ll try to keep it brief.</p><p><strong>Q:</strong> If you are tasked with implementing a link checker, how should you treat redirects like HTTP 302 responses?</p><p><strong>A:</strong> They are common enough that you should probably follow the redirect.</p><p><strong>Q:</strong> What about if it redirects again? This time via JavaScript instead of an HTTP response code. Should you follow it?</p><p><strong>A:</strong> Yes, this is common enough too, so maybe we should follow it.</p><p><strong>Q:</strong> But how many times?</p><p><strong>A:</strong> ???</p><p>That’s up to you as the software engineer to decide. If you specify a depth of 3 and your script gets redirected 3 times, it’s going to stop following redirects and just assess the content on the current page. Phishers are going to redirect 4 times and defeat your bot. You’re going to up the depth, then they are going to up the redirects, and so on and so forth ad nauseam.</p><p><strong>Welcome to the redirect arms race.</strong></p><p>I see this “in the wild” all the time so it must work as a bypass, but it is annoying, and cliche, and kinda dumb in my opinion. So…</p><p><strong>Please don’t join the redirect arms race!!!</strong></p><h3><strong>Alert!</strong></h3><p>Link crawling bots tend to come in two different flavors:</p><ol><li>Content scraping scripts</li><li>Automated browser scripts</li></ol><p>The easiest to implement, and therefore the most common type of link crawler is just a simple content scraping script. You can think of these as being a scripted version of using a tool like cURL to pull a URL’s content and checking it for phishy language. These scripts might also look for links on the page and crawl each of them to a certain depth as well.</p><p>Because scrapers just read the content, they don’t actually execute any JavaScript like a web browser would. We can use this to our advantage by using JavaScript to detect actions that require user interaction, and then forward them on to the real phishing content. One very simple way of doing this is to include an “alert()” statement just before a “window.location” change. If we obfuscate the “window.location” change, then scraper will not see any additional content it needs to vet. When a human user clicks our link, and views our page in their browser, they will get a simple alert message that they have to accept, and then will be forwarded to the real phishing page. The content of the alert doesn’t matter, so we can use it to play into the wording of our pretext (e.g. “Downloading your document. Click Okay to continue.”).</p><p>Because it is simply too easy to defeat content scrapers with JavaScript, some SEGs have gone through the trouble of scripting automated browsers to crawl links. While the automated browser can execute JavaScript, emulating human interaction is still difficult. Once again, if we use an “alert()” function on our page, JavaScript execution will be blocked until the user accepts the message. In some cases, if the software engineer who wrote the script did not consider alert boxes, then their automated browser instance will be stuck on the page while the alert is asking for user input. If the software engineer does consider alerts, then they will likely stumble upon a common solution like the following:</p><pre>browser.target_page.on(&#39;dialog&#39;, async dialog =&gt; {<br>  await dialog.accept()<br>})</pre><p>I myself have used this very technique to accept alerts when writing web scrapers for OSINT.</p><p>The problem with this solution is that it will accept the dialog (alert) immediately when it appears. A real human is going to need at least a second or two to see the alert, read it, move their mouse to the accept button, and click. If we set a timer on the alert box acceptance, we can pretty easily detect when a bot is accepting the alert and send them somewhere else. Few software engineers who are tasked with implementing these link crawler scripts will think this many moves in advance, and therefore even simple bypasses like this tend to work surprisingly well.</p><h3><strong>Count the Clicks</strong></h3><p>If we keep in mind that most link crawlers visit link URLs just before sending the user to the same URL, we can often defeat them by simply displaying a different set of content for the first click. The link crawler sees something benign and allows the user to visit, and that’s when we swap out the content. It is possible to achieve this directly in Apache using the ‘mod_security’ feature or in Nginx using the ‘map’ feature. Though it may be easiest in most cases to use a tool like Satellite to do this for you using the ‘times_served’ feature:</p><p><a href=\"https://github.com/t94j0/satellite/wiki/Route-Configuration\">https://github.com/t94j0/satellite/wiki/Route-Configuration</a></p><p>I tend to prefer writing my own basic web servers for hosting phishing sites so I have more granular control over the data I want to track and log. It’s then pretty simple to either keep a dictionary in memory to track clicks or add a SQLite database if you are concerned about persisting data if you need to restart the server.</p><h3><strong>Browser Fingerprinting</strong></h3><p>One way to detect bots that is far less intrusive and annoying than CAPTCHAs is to use browser fingerprinting. The idea here is to use features of JavaScript to determine what type of browser is visiting your webpage. Browser fingerprinting is extremely common today for both tracking users without cookies, and defending against bots. Many automated browser frameworks like Selenium and Puppeteer have default behaviors that are easy to detect. For example, most headless browsers have ‘outerHeight’ and ‘outerWidth’ attributes set to zero. There are many other well known indicators that your site is being viewed by a bot. Here’s a nice tool if you would like to start tinkering:</p><p><a href=\"https://github.com/infosimples/detect-headless\">https://github.com/infosimples/detect-headless</a></p><p>Another more extensive open source project that was designed for user tracking but can also be useful for this type of bot protection is FingerprintJS:</p><p><a href=\"https://github.com/fingerprintjs/fingerprintjs\">https://github.com/fingerprintjs/fingerprintjs</a></p><p>Most SEGs that implement link crawlers are not really incentivized to stay on the bleeding edge when it comes to hiding their bots. Therefore, in the vast majority of cases, we will be able to block SEG link crawlers with just open source tooling. However, there are also some really amazing paid options out there that specialize in bot protection and are constantly on the bleeding edge. For example, Dylan Evans wrote a great blog and some tooling that demonstrates how to thwart bots using Cloudflare Turnstile:</p><p><a href=\"https://fin3ss3g0d.net/index.php/2024/04/08/evilgophishs-approach-to-advanced-bot-detection-with-cloudflare-turnstile/\">https://fin3ss3g0d.net/index.php/2024/04/08/evilgophishs-approach-to-advanced-bot-detection-with-cloudflare-turnstile/</a></p><p>I would imagine just about any decent paid solution will thwart any SEG link crawlers you might encounter. It’s sort of like bringing a gun to a knife fight.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/435/0*pp0VuA-mRWihq5tY\" /></figure><h3><strong>ASN Blocking</strong></h3><p>Autonomous system numbers (ASNs) are groups of IP ranges that belong to an entity or domain. In practice, every public IP address belongs to an ASN, and you can look up the organization that owns each ASN. Because most SEGs operate using a SAAS model, when their link crawler visits your site the traffic will originate from an ASN either owned by the SEG, by their internet service provider, or by a cloud computing service they use to run their software. In any case, the ASN will likely be consistent for a particular SEG, and will not be the same as the ASN associated with the IPs of your target users. If you collect IP and ASN data on your phishing sites, you can build a list of known-bad ASNs that you should block from viewing your real content. This can help you display benign content to SEG link crawlers, and will also help protect you from web crawlers in general that might put your domain on a blocklist.</p><h3><strong>Call Them</strong></h3><p>Once again, because link crawlers are an email control, we can bypass them by simply not using email as our message transport for social engineering. Calling from a spoofed number is easy and often highly effective.</p><h3><strong>Story of the Aggressive Link Crawler</strong></h3><p>Some SEGs actually crawl <strong>all </strong>links in an email, whether they are clicked by a user or not. The first time I encountered one, I thought I was having the most successful phishing campaign ever until I realized that my click rate was just under 100% (some messages must have bounced or something).</p><p>Luckily, I had already added a quick IP address lookup feature to <a href=\"https://github.com/fkasler/phishmonger\">Phishmonger</a> at this point and I was able to see that the SEG was generating clicks from IPs all around the world. What they were doing was using an IP rotation service to make themselves harder to block and/or stop.</p><p>Also luckily, my client was only based and operating out of a single U.S. state. I was able to put a GeoIP filter on <a href=\"https://github.com/claissg/humble_chameleon\">HumbleChameleon</a> which I was using as my web server, and redirect the fake clicks elsewhere.</p><p>This worked well enough as a workaround in this scenario, but it would not work for bigger companies with a wider global footprint. I got lucky. Therefore, I think a better generalized bypass for this type of link crawler is to track the time between sending an email, and when the user clicks. These aggressive link crawlers are trying to vet the links in the email before the user has a chance to see and click them, so they will visit your links almost immediately (within seconds to a couple minutes) of receiving each email. They don’t have the luxury of being able to “jitter” their click times without seriously jamming the flow of incoming emails. Therefore, we can treat any clicks that happen within 2–3 minutes of sending the email as highly suspicious and either reject them (i.e. 404 and ask the user to come back later), or apply some additional vetting logic to make sure we aren’t dealing with a bot.</p><h3><strong>In Summary</strong></h3><p>Link crawlers, or “safe links” are going to allow SEGs to use bots to vet your phishing links before users are allowed to visit them. This control is annoying, but not very difficult to bypass. We just need to use some tried and true methods of detecting bots. There are some great open source and paid solutions that can help us detect bots and show them benign content.</p><p>SEGs aren’t properly incentivized to stay on the bleeding edge of writing stealthy web crawlers, so we can get some pretty good mileage out of known techniques and free tools. Just bring a leg to the arms race:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/944/0*zVDCI2GZt0YrBZ7E\" /></figure><p>Finally, it’s always a good idea to collect data on your campaigns beyond just clicks, and to review that data for evidence of controls like link crawlers. If you aren’t tracking any browser fingerprints, or IP locations, or delivery-to-click times, then how can you say with any confidence what was a legitimate click versus a security product looking at your phishing page? Feedback loops are an essential part of developing and improving our tradecraft. Go collect some data!</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=926c1905bb4b\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/like-shooting-phish-in-a-barrel-926c1905bb4b\">Like Shooting Phish in a Barrel</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "PHISHING SCHOOL\nBypassing Link Crawlers\nYou’ve just convinced a target user to click your link. In doing so, you have achieved the critical step in social engineering:\nConvincing someone to let you in the door!\nNow, we just have a few more technical controls that might get in the way of us reeling in our catch. The first of which is link crawlers.\nWhat’s a Link Crawler?\nLink crawlers, or “protected links” are one of the most annoying email controls out there. I don’t hate them because of their effectiveness (or ineffectiveness) at blocking phishing. I hate them because they are a real pain for end users and so many secure email gateways (SEGs) use them as a security feature these days. Here’s what they do, and why they suck:\nWhat link crawlers do\nThey replace all links in an email with a link to their own web server with some unique ID to look up the original link. Then, when a user clicks a link in the email, they first get sent to purgatory… oops, I mean the “protected link” website. The SEG’s web server looks up the original link, and then sends out a web crawler to check out the content of the link’s webpage. If it looks too phishy, the user will be blocked from accessing the link’s URL. If the crawler thinks the page is benign, it will forward the user on to the original link’s URL.\nWhy link crawlers suck\nFirst, have you ever had to reset your password for some web service you rarely use, and they sent you a one-time-use link to start the reset process? If your secure email gateway (SEG) replaces that link with a “safe link”, and has to check out the real link before allowing you to visit it, then guess what? You will never be able to reset your password because your SEG keeps killing your one-time-use links! I know that some link crawlers work in the opposite order (i.e. crawling the link right after the user visits) to get around this problem, but most of them click first, and send the user to a dead one-time-use URL later.\nSecond, these link replacements also make it so that the end user actually has no clue where a link is really going to send them. Hovering the link in an email will always show them a URL for the SEG’s link crawling service so there is no way the user can detect a masked link.\nThird, I see these “security features” as really just an overt data grab by the SEGs that implement them. They want to collect valuable user behavior telemetry more than they really care about protecting them from phishing campaigns. I wonder how many SEGs sell this data to the devil… oops, I mean “marketing firms”. It all seems very “big brother” to me.\nLastly, this control is not even that hard to bypass. I think if link crawlers were extremely effective at blocking phishing attacks, then I would be more forgiving and able to accept their downsides as a necessary evil. However, that is not the case. Let’s go ahead and talk about ways to bypass them!\nParser Bypasses\nSimilar to bypassing link filter protections, if the SEG’s link parser doesn’t see our link, then it can’t replace it with a safe link. By focusing on this tactic we can sometimes get two bypasses for the price of one. We’ve already covered this in Feeding the Phishes, so I’ll skip the details here.\nCompletely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA)\nLink crawlers are just robots. Therefore, to defeat link crawlers, we need to wage war with the robots! We smarty pants humans have employed CAPTCHAs as robot bouncers for decades now to kick them out of our websites. We can use the same approach to protect our phishing pages from crawlers as well. Because SEGs just want a peak at our website content to make a determination of whether it’s benign, there is no real motivation for them to employ any sort of CAPTCHA solver logic. For us, that means our CAPTCHAs don’t even have to be all that complicated or secure like they would need to be to protect a real website. I personally think this approach has been overused and abused by spammers to the point that many users are sketched out by them, but it’s still a valid link crawler bypass for many SEGs and a pretty quick and obvious choice.\nFun Fact (think about it)\nBecause the test is administered by a computer, in contrast to the standard Turing test that is administered by a human, CAPTCHAs are sometimes described as reverse Turing tests. — Wikipedia\nJoin the Redirect Arms Race\nWarning: I don’t actually recommend this, but it works, and therefore we have to talk about it. I’ll try to keep it brief.\nQ: If you are tasked with implementing a link checker, how should you treat redirects like HTTP 302 responses?\nA: They are common enough that you should probably follow the redirect.\nQ: What about if it redirects again? This time via JavaScript instead of an HTTP response code. Should you follow it?\nA: Yes, this is common enough too, so maybe we should follow it.\nQ: But how many times?\nA: ???\nThat’s up to you as the software engineer to decide. If you specify a depth of 3 and your script gets redirected 3 times, it’s going to stop following redirects and just assess the content on the current page. Phishers are going to redirect 4 times and defeat your bot. You’re going to up the depth, then they are going to up the redirects, and so on and so forth ad nauseam.\nWelcome to the redirect arms race.\nI see this “in the wild” all the time so it must work as a bypass, but it is annoying, and cliche, and kinda dumb in my opinion. So…\nPlease don’t join the redirect arms race!!!\nAlert!\nLink crawling bots tend to come in two different flavors:\n\nContent scraping scripts\nAutomated browser scripts\n\nThe easiest to implement, and therefore the most common type of link crawler is just a simple content scraping script. You can think of these as being a scripted version of using a tool like cURL to pull a URL’s content and checking it for phishy language. These scripts might also look for links on the page and crawl each of them to a certain depth as well.\nBecause scrapers just read the content, they don’t actually execute any JavaScript like a web browser would. We can use this to our advantage by using JavaScript to detect actions that require user interaction, and then forward them on to the real phishing content. One very simple way of doing this is to include an “alert()” statement just before a “window.location” change. If we obfuscate the “window.location” change, then scraper will not see any additional content it needs to vet. When a human user clicks our link, and views our page in their browser, they will get a simple alert message that they have to accept, and then will be forwarded to the real phishing page. The content of the alert doesn’t matter, so we can use it to play into the wording of our pretext (e.g. “Downloading your document. Click Okay to continue.”).\nBecause it is simply too easy to defeat content scrapers with JavaScript, some SEGs have gone through the trouble of scripting automated browsers to crawl links. While the automated browser can execute JavaScript, emulating human interaction is still difficult. Once again, if we use an “alert()” function on our page, JavaScript execution will be blocked until the user accepts the message. In some cases, if the software engineer who wrote the script did not consider alert boxes, then their automated browser instance will be stuck on the page while the alert is asking for user input. If the software engineer does consider alerts, then they will likely stumble upon a common solution like the following:\nbrowser.target_page.on('dialog', async dialog => {\n  await dialog.accept()\n})\nI myself have used this very technique to accept alerts when writing web scrapers for OSINT.\nThe problem with this solution is that it will accept the dialog (alert) immediately when it appears. A real human is going to need at least a second or two to see the alert, read it, move their mouse to the accept button, and click. If we set a timer on the alert box acceptance, we can pretty easily detect when a bot is accepting the alert and send them somewhere else. Few software engineers who are tasked with implementing these link crawler scripts will think this many moves in advance, and therefore even simple bypasses like this tend to work surprisingly well.\nCount the Clicks\nIf we keep in mind that most link crawlers visit link URLs just before sending the user to the same URL, we can often defeat them by simply displaying a different set of content for the first click. The link crawler sees something benign and allows the user to visit, and that’s when we swap out the content. It is possible to achieve this directly in Apache using the ‘mod_security’ feature or in Nginx using the ‘map’ feature. Though it may be easiest in most cases to use a tool like Satellite to do this for you using the ‘times_served’ feature:\nhttps://github.com/t94j0/satellite/wiki/Route-Configuration\nI tend to prefer writing my own basic web servers for hosting phishing sites so I have more granular control over the data I want to track and log. It’s then pretty simple to either keep a dictionary in memory to track clicks or add a SQLite database if you are concerned about persisting data if you need to restart the server.\nBrowser Fingerprinting\nOne way to detect bots that is far less intrusive and annoying than CAPTCHAs is to use browser fingerprinting. The idea here is to use features of JavaScript to determine what type of browser is visiting your webpage. Browser fingerprinting is extremely common today for both tracking users without cookies, and defending against bots. Many automated browser frameworks like Selenium and Puppeteer have default behaviors that are easy to detect. For example, most headless browsers have ‘outerHeight’ and ‘outerWidth’ attributes set to zero. There are many other well known indicators that your site is being viewed by a bot. Here’s a nice tool if you would like to start tinkering:\nhttps://github.com/infosimples/detect-headless\nAnother more extensive open source project that was designed for user tracking but can also be useful for this type of bot protection is FingerprintJS:\nhttps://github.com/fingerprintjs/fingerprintjs\nMost SEGs that implement link crawlers are not really incentivized to stay on the bleeding edge when it comes to hiding their bots. Therefore, in the vast majority of cases, we will be able to block SEG link crawlers with just open source tooling. However, there are also some really amazing paid options out there that specialize in bot protection and are constantly on the bleeding edge. For example, Dylan Evans wrote a great blog and some tooling that demonstrates how to thwart bots using Cloudflare Turnstile:\nhttps://fin3ss3g0d.net/index.php/2024/04/08/evilgophishs-approach-to-advanced-bot-detection-with-cloudflare-turnstile/\nI would imagine just about any decent paid solution will thwart any SEG link crawlers you might encounter. It’s sort of like bringing a gun to a knife fight.\n\nASN Blocking\nAutonomous system numbers (ASNs) are groups of IP ranges that belong to an entity or domain. In practice, every public IP address belongs to an ASN, and you can look up the organization that owns each ASN. Because most SEGs operate using a SAAS model, when their link crawler visits your site the traffic will originate from an ASN either owned by the SEG, by their internet service provider, or by a cloud computing service they use to run their software. In any case, the ASN will likely be consistent for a particular SEG, and will not be the same as the ASN associated with the IPs of your target users. If you collect IP and ASN data on your phishing sites, you can build a list of known-bad ASNs that you should block from viewing your real content. This can help you display benign content to SEG link crawlers, and will also help protect you from web crawlers in general that might put your domain on a blocklist.\nCall Them\nOnce again, because link crawlers are an email control, we can bypass them by simply not using email as our message transport for social engineering. Calling from a spoofed number is easy and often highly effective.\nStory of the Aggressive Link Crawler\nSome SEGs actually crawl all links in an email, whether they are clicked by a user or not. The first time I encountered one, I thought I was having the most successful phishing campaign ever until I realized that my click rate was just under 100% (some messages must have bounced or something).\nLuckily, I had already added a quick IP address lookup feature to Phishmonger at this point and I was able to see that the SEG was generating clicks from IPs all around the world. What they were doing was using an IP rotation service to make themselves harder to block and/or stop.\nAlso luckily, my client was only based and operating out of a single U.S. state. I was able to put a GeoIP filter on HumbleChameleon which I was using as my web server, and redirect the fake clicks elsewhere.\nThis worked well enough as a workaround in this scenario, but it would not work for bigger companies with a wider global footprint. I got lucky. Therefore, I think a better generalized bypass for this type of link crawler is to track the time between sending an email, and when the user clicks. These aggressive link crawlers are trying to vet the links in the email before the user has a chance to see and click them, so they will visit your links almost immediately (within seconds to a couple minutes) of receiving each email. They don’t have the luxury of being able to “jitter” their click times without seriously jamming the flow of incoming emails. Therefore, we can treat any clicks that happen within 2–3 minutes of sending the email as highly suspicious and either reject them (i.e. 404 and ask the user to come back later), or apply some additional vetting logic to make sure we aren’t dealing with a bot.\nIn Summary\nLink crawlers, or “safe links” are going to allow SEGs to use bots to vet your phishing links before users are allowed to visit them. This control is annoying, but not very difficult to bypass. We just need to use some tried and true methods of detecting bots. There are some great open source and paid solutions that can help us detect bots and show them benign content.\nSEGs aren’t properly incentivized to stay on the bleeding edge of writing stealthy web crawlers, so we can get some pretty good mileage out of known techniques and free tools. Just bring a leg to the arms race:\n\nFinally, it’s always a good idea to collect data on your campaigns beyond just clicks, and to review that data for evidence of controls like link crawlers. If you aren’t tracking any browser fingerprints, or IP locations, or delivery-to-click times, then how can you say with any confidence what was a legitimate click versus a security product looking at your phishing page? Feedback loops are an essential part of developing and improving our tradecraft. Go collect some data!\n\nLike Shooting Phish in a Barrel was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Forrest Kasler",
      "guid": "https://medium.com/p/926c1905bb4b",
      "categories": [
        "penetration-testing",
        "phishing",
        "social-engineering",
        "hacking",
        "red-team"
      ],
      "isoDate": "2024-07-02T15:30:23.000Z"
    },
    {
      "creator": "hotnops",
      "title": "An AWS Administrator Identity Crisis: Part 1",
      "link": "https://posts.specterops.io/an-aws-administrator-identity-crisis-part-1-919e6171ec0a?source=rss----f05f8696e3cc---4",
      "pubDate": "Fri, 28 Jun 2024 16:58:09 GMT",
      "content:encoded": "<p>BLUF: Every attack path needs a destination. This is a formalized way of describing destinations in AWS. In cloud providers where we only have data plane access, we divert our focus from an arbitrary definition of administrator to resources we care about.</p><blockquote>How many administrators are in your AWS environment? Does it even matter?</blockquote><p>This is seemingly a simple and frequent question, but tends to be very difficult to answer particularly in large AWS environments. To be able to answer this question, we need to first understand <em>“What is an administrator?”</em>. Off the cuff, you may say that an administrator is any principal with the <em>AdministratorAccess</em> policy attached, or even more specifically, a principal that has:</p><pre>{<br>  “Effect”: “Allow”,<br>  “Action”: “*”,<br>  “Resource”: “*”<br>}</pre><p>in one of their policies. For the AWS uninitiated, this statement says that any action is permitted (out of 16982 defined AWS actions) on any resource in the account. This is a logical place to start but ultimately a far too simplistic and limiting definition. If we were to modify the policy as such, it would not fit our current definition of administrator:</p><pre>[<br>  {<br>    “Effect”: “Allow”,<br>    “Action”: “*”,<br>    “Resource”: “*”<br>  },<br>  {<br>    “Effect”: “Deny”,<br>    “Action”:“elastictranscoder:readpipeline”,<br>    “Resource”: &quot;*&quot;<br>  }<br>]</pre><p>The only modification here is that we can no longer call one of the 16982 actions, leaving only 16981 at our disposal. I think most would intuit that we are indeed still considered an administrator, even though it doesn’t fit our first strict definition. In this case, how much privilege can we whittle away before we are no longer considered an administrator? In this context, I think it is helpful to separate principals into two groups:</p><ol><li>Principals that are currently an “administrator”. We will call these <strong>direct</strong> permissions.</li><li>Principals that can modify some aspect of the environment to become an administrator. We will call these <strong>indirect</strong> permissions.</li></ol><p>The key difference between the two is that the latter requires some sort of write operation to obtain the necessary privileges. The rest of this post is going to focus on the <strong>direct</strong> permissions, and I will discuss graph modification in a later post. In broad strokes, we can define an administrator as a principal that has no limitations as to what they can do within their account.</p><p>One possible route is to flag specific actions as high value “administrator” actions. This can include actions such as <em>iam:updaterolepolicy</em>,<em> iam:passrole</em>, <em>iam:createuserkeys</em>, etc. I don’t like this approach because of the flexible nature of AWS policy definitions. For example, I can specify that a user can update role policies for all principals but themselves. That’s kind of like an admin, but doesn’t let the principal auto elevate. It certainly is not as powerful as it could be, but is still very powerful. In addition, this requires the definition to have a more concrete awareness of AWS and the actions that it provides, so the definition won’t scale well to other cloud platforms. It may be helpful to identify “administrator actions” for auditing, but I want concrete definitions on which to build a foundation. Lastly, it mixes in <strong>indirect</strong> and <strong>direct</strong> permissions, which should be treated differently.</p><p>In that vein, it may be sufficient to say “An administrator can perform all applicable actions on all resources in the account.” This is different from the first <em>AdministratorAccess</em> policy which translates to “Can perform all actions on all resources that can possibly exist ‘’. In plain English, this is a meaningful distinction because most (if not all) AWS accounts don’t utilize every service AWS has to offer. For example, most AWS accounts probably aren’t using the <em>elastictranscoder </em>service.</p><p><strong>If the ability to perform all <em>elastictranscoder</em> actions on all <em>elastictranscoder</em> resources (even if they don’t exist) is a requirement for Administrator consideration, then that definition is far too constrained.</strong></p><p>The consequence of this is omitting principals that should be considered an administrator and overlooking the scrutiny that should come with them.</p><p>Let’s take a step back for a minute and consider the following statement:</p><pre>{<br>  “Effect”: “Allow”,<br>  “Action”: “ec2:stopinstances”,<br>  “Resource”: “arn:aws:ec2:us-west-2:123456789012:instance/i-0abcd1234efgh5678”<br>}</pre><p>This statement is unique because it allows only one action on a single resource. It creates an action-to-resource pairing of <em>ec2:stopinstances</em> to <em>arn:aws:ec2:us-west-2:123456789012:instance/i-0abcd1234efgh5678</em>. This action-to-resource mapping is the atomic unit of our set processing and represents a successful API call that a caller can make. To extrapolate this out, consider the modified statement:</p><pre>{<br>  “Effect”: “Allow”,<br>  “Action”: “ec2:*”,<br>  “Resource”: “arn:aws:ec2:us-west-2:123456789012:instance/i-0abcd1234efgh5678”<br>}</pre><p>This statement creates a set of action-to-resource entries. Because not every <em>ec2</em> action can act on an <em>ec2</em> instance, we may only include the actions that can act on the resource type. Our resulting table looks like this, and we’ll call it a permission matrix, which is simply a <a href=\"https://en.wikipedia.org/wiki/Cartesian_product\">Cartesian product</a> of the actions and the resources.</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/f63d3cd23d003d1b9bbe91ce3b3adb13/href\">https://medium.com/media/f63d3cd23d003d1b9bbe91ce3b3adb13/href</a></iframe><p>Conversely, if we put a wildcard in the resource instead of the action, we populate the table with all ec2 instances that exist in the account. Once again, <em>ec2:stopinstances</em> can only act on <em>ec2:instance </em>resources, so we may omit all other types of resources.</p><pre>{<br>  “Effect”: “Allow”,<br>  “Action”: “ec2:stopinstances”,<br>  “Resource”: “*”<br>}</pre><p>Results in the following permission matrix:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/ada8e0f78bfda6f79e91a1d8fbbb737d/href\">https://medium.com/media/ada8e0f78bfda6f79e91a1d8fbbb737d/href</a></iframe><p>And when we use wildcards in both, our matrix gets really big, but the idea stays the same. Using these action-to-resource sets, we can define our administrator as follows:</p><pre>for resource in (allResourcesInTheAccount):<br>  actions = getAllActions(resource) // Getting all the actions that can act on that resource<br>  addEntryToPermissionMatrix(action, resource)</pre><p>In this pseudocode, we enumerate every resource in the account, determine which actions can be performed on that resource, and add that action/resource pair to a permission matrix which we will call the “Ridiculous Administrator Matrix” (RAM). If we reconsider the <em>AdministratorAccess</em> policy, the permission matrix is defined as this:</p><pre>AdministratorAccess = CartesianProduct(Every Possible ARN, Every Possible Action)</pre><p>At this point, we can say that the RAM is a subset of the permission matrix derived from the <em>AdministratorAccess</em> policy. It becomes clear that if we want to identify administrators, we should define it as any principal that has a resulting set of policy (RSOP) permission matrix that is a superset of the RAM. The RSOP is calculated as follows and is an implementation of the policy evaluation logic provided by AWS:</p><pre># These statements represent every statement that can affect the principal<br>statements = getAllStatementsAttachedToPrincipal(principal, context)<br><br>for each statement in statements:<br>  # Gather all the statements that provide permissions<br>  allowActions = getAllowPermissionMatrix()<br><br>  # Gather all the statements that prohibit<br>  denyActions = getDenyPermissionMatrix()<br><br>  conditonalAllowActions = getConditionalAllowPermissionMatrix()<br>  conditionalDenyActions = getConditionalDenyPermissionMatrix()<br><br>  # Resolve every conditional statement based on things we can deduce,<br>  # and use a pre-populated context for things we cannot deduce<br>  for conditionalDeny in conditionalDenyActions:<br>      denyActions += resolveCondition(conditionalDeny, principal, context)<br>  for conditionalAllow in conditionalAllowActions:<br>      allowActions += resolveCondition(conditionalAllow, principal, context)<br><br>  # Ensure that session policies and Service Control Policies are accounted for<br>  processSessionPolicy(principal, allowStatements, denyStatement)<br>  processSCPs(principal, allowStatements, denyStatements)<br><br>return relativeComplement(allowActions, denyActions)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*PbHGl4wMDWMJBfekhoewBg.png\" /><figcaption>The relative complement is the area in green</figcaption></figure><p>This gives us the following pseudo definition of an administrator:</p><pre>IsAdministrator(principal, context) = (RAM) ⊆ RSOP(principal, context)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*YfjQcGDveQ1N4xztBcLS8A.png\" /><figcaption>Visual set logic of an Administrator</figcaption></figure><p>Whenever we discuss RSOP going forward, it is understood that this is the <strong><em>resultant</em></strong> set of policy and that all <a href=\"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\">SCPs</a>, conditions, permission boundaries, and session policies have considered when producing the permission matrix.</p><p>It stands to reason that if a role is an administrator, then a principal that can assume that role is also an administrator. We will identify <em>sts:AssumeRole</em> as a type of “IdentityTransform”. We can introduce a new term, “Transitive RSOP” to include all permission matrices of all roles that our role can assume. For example, If:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*a-2VOHDV5_ORRAEw8ntqcQ.png\" /></figure><p>Then, we can identify TransitiveRSOP as follows:</p><pre>TransitiveRSOP(A, context) = RSOP(a, context) ∪ RSOP(b, context) ∪ RSOP(C, context)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*CSZfiQXYCqF8EAkWjDLchA.png\" /></figure><p>Which means, the TransitiveRSOP is the collection of all the things each principal can perform in a given context. Therefore, we can define our administrator as follows:</p><pre>IsAdministrator(principal, context) = (RAM) ⊆ TransitiveRSOP(principal, context)</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*5B0G_4--hbBWjyIeFLMHrw.png\" /></figure><p>In this definition, it’s possible that the RSOP of neither Role A, B, or C contain the RAM subset individually, but in sum, they do. This reflects the true nature of Role A being an “administrator” or whatever set of permissions we care about.</p><p>At first glance, this comes off as a needlessly complicated set of rules for defining an administrator. To me, this seems like an exercise in being overly academic for something that is very intuitive to most. I personally hate this definition of an Administrator because it’s not even remotely practical, the administrator definition is simply too strict.</p><p>After all this pedantic theorizing about permissions, one must ask themselves</p><blockquote>Does defining an administrator even matter?</blockquote><p>What are we doing here? For example, what does it matter if the Administrator can call <em>TagResource</em> on our <em>dynamodb</em> table if we don’t use <a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_attribute-based-access-control.html\">ABAC</a>?</p><p>Let’s forget about administrators. What if, instead, we identify the resources we care about (and yes, principals are resources) and explicitly state why we care about them?</p><p>Here’s an example.</p><p>Let’s say we have a domain controller running as an EC2 instance and it has the ARN of:</p><pre>arn:aws:ec2:us-west-2:1234567891012:instance/i-domaincontroller</pre><p>Because it is a high value asset and considered “Tier 0/Super Duper Important”, we care who has access to it. According to AWS documentation, the following actions are allowed to be performed on an EC2 instance:</p><iframe src=\"\" width=\"0\" height=\"0\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/cf0fe8e2585f7a493970d902bfb66d0a/href\">https://medium.com/media/cf0fe8e2585f7a493970d902bfb66d0a/href</a></iframe><p>Some of these are potentially benign, some are not. Let’s say we want to identify all principals that can perform all of these actions on the domain controller. This is easy using our formula above, we simply replace the definition of “Administrator” to something we actually care about, like “who can mess with the domain controller.” We will call this our Permission Matrix 0, and define it as:</p><pre>PM0 = CartesianProduct(All Actions above, arn:aws:ec2:us-west-2:1234567891012:instance/i-domaincontroller)</pre><p>We can now identify those principals, same as above:</p><pre>isPrincipalWeActuallyCareAbout(prinipal) = PM0 ⊆ TransitiveRSOP(principal) </pre><p>Applying this formula to every principal in an AWS environment provides us a list of all the principals, including identity transformations, that have all of the permissions above which can compromise the integrity of our domain controller.</p><p>Of course, this is an extremely narrow definition because the definition requires that a principal must have all of these actions, when realistically, only a handful may suffice to compromise the domain controller. This is an easy fix, we can define each action, or maybe a handful, as their own permission matrices. For example, we can define <em>ec2:stopinstances</em> and <em>ec2:detachvolume</em> as their own permission matrix. This is to account for a specific attack path of stopping an instance and detaching the volume so it can be exfiltrated out of the account.</p><pre>permissionMatrix = CartesianProduct([ec2:stopinstances, ec2:detachvolume], &quot;arn:aws:ec2:us-west-2:1234567891012:instance/i-domaincontroller&quot;)<br>def isPrincipalWeActionCareAbout(principal):<br>  if permissionMatrix ⊆ TransitiveRSOP(principal):<br>    return true<br>  return false</pre><p>We now have a concrete and testable definition, and we can produce a very real answer to “<em>Who can compromise this resource</em>”, based on <em>our</em> definition of compromise. Resources can be anything in the AWS account, including principals. So this definition can work just as well on a privileged principal that one would deem an “Administrator”. And there’s no limitation on how many sets we can define. Unlike traditional attack path management where identity or infrastructure is the destination, <strong><em>our permission sets are the destination.</em></strong></p><p>If it’s not already apparent, all of this is about building attack paths in AWS. Up until now, it has been based on intuition, known knowns, and approximations, like the <em>AdministratorAccess</em> policy. Every path needs a destination, and all of this effort is to identify the resources defenders care about so we can identify the paths to them, and ensure those paths are protected and more importantly, intended. My goal with this rant is to clarify how we discuss IAM attack paths and introduce language with which we can be precise when discussing IAM attack paths.</p><p>What do we do about this? How does this help? I am introducing these concepts to make sense of the implementation, which comes in the form of a tool that I will showcase at <a href=\"https://www.blackhat.com/us-24/arsenal/schedule/index.html#apeman-the-aws-policy-evaluation-manager-39474\">Blackhat Arsenal</a> in August. In the next post, we’ll talk about identifying indirect privileges, so that we can expand our definition of “who can perform action X on resource Y?”.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=919e6171ec0a\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/an-aws-administrator-identity-crisis-part-1-919e6171ec0a\">An AWS Administrator Identity Crisis: Part 1</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "BLUF: Every attack path needs a destination. This is a formalized way of describing destinations in AWS. In cloud providers where we only have data plane access, we divert our focus from an arbitrary definition of administrator to resources we care about.\nHow many administrators are in your AWS environment? Does it even matter?\nThis is seemingly a simple and frequent question, but tends to be very difficult to answer particularly in large AWS environments. To be able to answer this question, we need to first understand “What is an administrator?”. Off the cuff, you may say that an administrator is any principal with the AdministratorAccess policy attached, or even more specifically, a principal that has:\n{\n  “Effect”: “Allow”,\n  “Action”: “*”,\n  “Resource”: “*”\n}\nin one of their policies. For the AWS uninitiated, this statement says that any action is permitted (out of 16982 defined AWS actions) on any resource in the account. This is a logical place to start but ultimately a far too simplistic and limiting definition. If we were to modify the policy as such, it would not fit our current definition of administrator:\n[\n  {\n    “Effect”: “Allow”,\n    “Action”: “*”,\n    “Resource”: “*”\n  },\n  {\n    “Effect”: “Deny”,\n    “Action”:“elastictranscoder:readpipeline”,\n    “Resource”: \"*\"\n  }\n]\nThe only modification here is that we can no longer call one of the 16982 actions, leaving only 16981 at our disposal. I think most would intuit that we are indeed still considered an administrator, even though it doesn’t fit our first strict definition. In this case, how much privilege can we whittle away before we are no longer considered an administrator? In this context, I think it is helpful to separate principals into two groups:\n\nPrincipals that are currently an “administrator”. We will call these direct permissions.\nPrincipals that can modify some aspect of the environment to become an administrator. We will call these indirect permissions.\n\nThe key difference between the two is that the latter requires some sort of write operation to obtain the necessary privileges. The rest of this post is going to focus on the direct permissions, and I will discuss graph modification in a later post. In broad strokes, we can define an administrator as a principal that has no limitations as to what they can do within their account.\nOne possible route is to flag specific actions as high value “administrator” actions. This can include actions such as iam:updaterolepolicy, iam:passrole, iam:createuserkeys, etc. I don’t like this approach because of the flexible nature of AWS policy definitions. For example, I can specify that a user can update role policies for all principals but themselves. That’s kind of like an admin, but doesn’t let the principal auto elevate. It certainly is not as powerful as it could be, but is still very powerful. In addition, this requires the definition to have a more concrete awareness of AWS and the actions that it provides, so the definition won’t scale well to other cloud platforms. It may be helpful to identify “administrator actions” for auditing, but I want concrete definitions on which to build a foundation. Lastly, it mixes in indirect and direct permissions, which should be treated differently.\nIn that vein, it may be sufficient to say “An administrator can perform all applicable actions on all resources in the account.” This is different from the first AdministratorAccess policy which translates to “Can perform all actions on all resources that can possibly exist ‘’. In plain English, this is a meaningful distinction because most (if not all) AWS accounts don’t utilize every service AWS has to offer. For example, most AWS accounts probably aren’t using the elastictranscoder service.\nIf the ability to perform all elastictranscoder actions on all elastictranscoder resources (even if they don’t exist) is a requirement for Administrator consideration, then that definition is far too constrained.\nThe consequence of this is omitting principals that should be considered an administrator and overlooking the scrutiny that should come with them.\nLet’s take a step back for a minute and consider the following statement:\n{\n  “Effect”: “Allow”,\n  “Action”: “ec2:stopinstances”,\n  “Resource”: “arn:aws:ec2:us-west-2:123456789012:instance/i-0abcd1234efgh5678”\n}\nThis statement is unique because it allows only one action on a single resource. It creates an action-to-resource pairing of ec2:stopinstances to arn:aws:ec2:us-west-2:123456789012:instance/i-0abcd1234efgh5678. This action-to-resource mapping is the atomic unit of our set processing and represents a successful API call that a caller can make. To extrapolate this out, consider the modified statement:\n{\n  “Effect”: “Allow”,\n  “Action”: “ec2:*”,\n  “Resource”: “arn:aws:ec2:us-west-2:123456789012:instance/i-0abcd1234efgh5678”\n}\nThis statement creates a set of action-to-resource entries. Because not every ec2 action can act on an ec2 instance, we may only include the actions that can act on the resource type. Our resulting table looks like this, and we’ll call it a permission matrix, which is simply a Cartesian product of the actions and the resources.\nhttps://medium.com/media/f63d3cd23d003d1b9bbe91ce3b3adb13/href\nConversely, if we put a wildcard in the resource instead of the action, we populate the table with all ec2 instances that exist in the account. Once again, ec2:stopinstances can only act on ec2:instance resources, so we may omit all other types of resources.\n{\n  “Effect”: “Allow”,\n  “Action”: “ec2:stopinstances”,\n  “Resource”: “*”\n}\nResults in the following permission matrix:\nhttps://medium.com/media/ada8e0f78bfda6f79e91a1d8fbbb737d/href\nAnd when we use wildcards in both, our matrix gets really big, but the idea stays the same. Using these action-to-resource sets, we can define our administrator as follows:\nfor resource in (allResourcesInTheAccount):\n  actions = getAllActions(resource) // Getting all the actions that can act on that resource\n  addEntryToPermissionMatrix(action, resource)\nIn this pseudocode, we enumerate every resource in the account, determine which actions can be performed on that resource, and add that action/resource pair to a permission matrix which we will call the “Ridiculous Administrator Matrix” (RAM). If we reconsider the AdministratorAccess policy, the permission matrix is defined as this:\nAdministratorAccess = CartesianProduct(Every Possible ARN, Every Possible Action)\nAt this point, we can say that the RAM is a subset of the permission matrix derived from the AdministratorAccess policy. It becomes clear that if we want to identify administrators, we should define it as any principal that has a resulting set of policy (RSOP) permission matrix that is a superset of the RAM. The RSOP is calculated as follows and is an implementation of the policy evaluation logic provided by AWS:\n# These statements represent every statement that can affect the principal\nstatements = getAllStatementsAttachedToPrincipal(principal, context)\nfor each statement in statements:\n  # Gather all the statements that provide permissions\n  allowActions = getAllowPermissionMatrix()\n  # Gather all the statements that prohibit\n  denyActions = getDenyPermissionMatrix()\n  conditonalAllowActions = getConditionalAllowPermissionMatrix()\n  conditionalDenyActions = getConditionalDenyPermissionMatrix()\n  # Resolve every conditional statement based on things we can deduce,\n  # and use a pre-populated context for things we cannot deduce\n  for conditionalDeny in conditionalDenyActions:\n      denyActions += resolveCondition(conditionalDeny, principal, context)\n  for conditionalAllow in conditionalAllowActions:\n      allowActions += resolveCondition(conditionalAllow, principal, context)\n  # Ensure that session policies and Service Control Policies are accounted for\n  processSessionPolicy(principal, allowStatements, denyStatement)\n  processSCPs(principal, allowStatements, denyStatements)\nreturn relativeComplement(allowActions, denyActions)\nThe relative complement is the area in green\nThis gives us the following pseudo definition of an administrator:\nIsAdministrator(principal, context) = (RAM) ⊆ RSOP(principal, context)\nVisual set logic of an Administrator\nWhenever we discuss RSOP going forward, it is understood that this is the resultant set of policy and that all SCPs, conditions, permission boundaries, and session policies have considered when producing the permission matrix.\nIt stands to reason that if a role is an administrator, then a principal that can assume that role is also an administrator. We will identify sts:AssumeRole as a type of “IdentityTransform”. We can introduce a new term, “Transitive RSOP” to include all permission matrices of all roles that our role can assume. For example, If:\n\nThen, we can identify TransitiveRSOP as follows:\nTransitiveRSOP(A, context) = RSOP(a, context) ∪ RSOP(b, context) ∪ RSOP(C, context)\n\nWhich means, the TransitiveRSOP is the collection of all the things each principal can perform in a given context. Therefore, we can define our administrator as follows:\nIsAdministrator(principal, context) = (RAM) ⊆ TransitiveRSOP(principal, context)\n\nIn this definition, it’s possible that the RSOP of neither Role A, B, or C contain the RAM subset individually, but in sum, they do. This reflects the true nature of Role A being an “administrator” or whatever set of permissions we care about.\nAt first glance, this comes off as a needlessly complicated set of rules for defining an administrator. To me, this seems like an exercise in being overly academic for something that is very intuitive to most. I personally hate this definition of an Administrator because it’s not even remotely practical, the administrator definition is simply too strict.\nAfter all this pedantic theorizing about permissions, one must ask themselves\nDoes defining an administrator even matter?\nWhat are we doing here? For example, what does it matter if the Administrator can call TagResource on our dynamodb table if we don’t use ABAC?\nLet’s forget about administrators. What if, instead, we identify the resources we care about (and yes, principals are resources) and explicitly state why we care about them?\nHere’s an example.\nLet’s say we have a domain controller running as an EC2 instance and it has the ARN of:\narn:aws:ec2:us-west-2:1234567891012:instance/i-domaincontroller\nBecause it is a high value asset and considered “Tier 0/Super Duper Important”, we care who has access to it. According to AWS documentation, the following actions are allowed to be performed on an EC2 instance:\nhttps://medium.com/media/cf0fe8e2585f7a493970d902bfb66d0a/href\nSome of these are potentially benign, some are not. Let’s say we want to identify all principals that can perform all of these actions on the domain controller. This is easy using our formula above, we simply replace the definition of “Administrator” to something we actually care about, like “who can mess with the domain controller.” We will call this our Permission Matrix 0, and define it as:\nPM0 = CartesianProduct(All Actions above, arn:aws:ec2:us-west-2:1234567891012:instance/i-domaincontroller)\nWe can now identify those principals, same as above:\nisPrincipalWeActuallyCareAbout(prinipal) = PM0 ⊆ TransitiveRSOP(principal) \nApplying this formula to every principal in an AWS environment provides us a list of all the principals, including identity transformations, that have all of the permissions above which can compromise the integrity of our domain controller.\nOf course, this is an extremely narrow definition because the definition requires that a principal must have all of these actions, when realistically, only a handful may suffice to compromise the domain controller. This is an easy fix, we can define each action, or maybe a handful, as their own permission matrices. For example, we can define ec2:stopinstances and ec2:detachvolume as their own permission matrix. This is to account for a specific attack path of stopping an instance and detaching the volume so it can be exfiltrated out of the account.\npermissionMatrix = CartesianProduct([ec2:stopinstances, ec2:detachvolume], \"arn:aws:ec2:us-west-2:1234567891012:instance/i-domaincontroller\")\ndef isPrincipalWeActionCareAbout(principal):\n  if permissionMatrix ⊆ TransitiveRSOP(principal):\n    return true\n  return false\nWe now have a concrete and testable definition, and we can produce a very real answer to “Who can compromise this resource”, based on our definition of compromise. Resources can be anything in the AWS account, including principals. So this definition can work just as well on a privileged principal that one would deem an “Administrator”. And there’s no limitation on how many sets we can define. Unlike traditional attack path management where identity or infrastructure is the destination, our permission sets are the destination.\nIf it’s not already apparent, all of this is about building attack paths in AWS. Up until now, it has been based on intuition, known knowns, and approximations, like the AdministratorAccess policy. Every path needs a destination, and all of this effort is to identify the resources defenders care about so we can identify the paths to them, and ensure those paths are protected and more importantly, intended. My goal with this rant is to clarify how we discuss IAM attack paths and introduce language with which we can be precise when discussing IAM attack paths.\nWhat do we do about this? How does this help? I am introducing these concepts to make sense of the implementation, which comes in the form of a tool that I will showcase at Blackhat Arsenal in August. In the next post, we’ll talk about identifying indirect privileges, so that we can expand our definition of “who can perform action X on resource Y?”.\n\nAn AWS Administrator Identity Crisis: Part 1 was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "hotnops",
      "guid": "https://medium.com/p/919e6171ec0a",
      "categories": [
        "cloud-security",
        "attack-path-management",
        "aws",
        "iam-policy"
      ],
      "isoDate": "2024-06-28T16:58:09.000Z"
    },
    {
      "creator": "Forrest Kasler",
      "title": "I Will Make you Phishers of Men",
      "link": "https://posts.specterops.io/i-will-make-you-phishers-of-men-608268c4c669?source=rss----f05f8696e3cc---4",
      "pubDate": "Tue, 25 Jun 2024 14:12:04 GMT",
      "content:encoded": "<h4>PHISHING SCHOOL</h4><h4>Convincing Targets to Click Your Links</h4><p>When it comes to phishing advice, the number one question I get from co-workers is <strong>“what campaigns are you using?”</strong>. People see my success, and wish to emulate it. Well, if a phish is what you wish, I would like you to meet my friend Ish:</p><p><em>Who am I? My name is Ish<br>On my hand I have a dish.<br>I have this dish to help me wish.<br>When I wish to make a wish<br>I wave my hand with a big swish swish.<br>Then I say, “I wish for phish!”<br>And I get phish right on my dish.<br>So…<br>If you wish to make a wish,<br>you may swish for phish with my Ish wish dish.</em></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/250/1*13LbacmIliYFMOmwO5OUXg.jpeg\" /><figcaption>Ish Wish Dish</figcaption></figure><p>Unfortunately, I don’t have any wish dishes to spare. What I do have are illustrations. Just as the great Dr. Seuss used silly illustrations to encourage kids to read, I would like to use some concrete examples to encourage you to craft custom phishing emails.</p><p>These lessons were hard earned. Collected over many years. And they are the foundation of my own perspective on phishing. I am giving you a shortcut. You can learn to think about phishing just the way I do, but there is a catch:</p><p><strong>I need you to live these experiences with me</strong>.</p><p>Otherwise it won’t stick. As you read these examples, I need you to imagine it was you behind the keyboard. Feel the sly grin as you craft your cunning lure. Notice that tense anticipation of waiting for that first click. Hear the <em>ding</em> of your Telegram bot letting you know you have a visitor. See the password hit your Phishmonger dashboard. And taste sweet victory when your C2 agent calls home! Take a moment to immerse yourself in these experiences and make them your own. Get stoked, buckle up, and hang with me for a very short but critical tangent…</p><h3><strong>What are the Odds?</strong></h3><p>I’m about to teach you how to win at phishing. Consistently. But first, we will have to do a tiny bit of math. Don’t panic. I’ve written down all the answers for you. Just trust the math is correct. More importantly, trust what the math is telling us!</p><p>If we want to have a successful phishing campaign, we should be focusing on quality over quantity. But how likely are we to ‘win’ at this game? Keep in mind, for a phishing campaign to be successful, we typically only need a single employee to let us in the door. Therefore, winning at this game means just getting at least one click.</p><p>Let’s say we focus on crafting a highly targeted pretext that will seem very convincing to a small number of users and we can get an expected click-through rate of roughly 50%. If we send our pretext to only 5 targets, our chances of getting at least one click is 96.9%! To calculate the chance of at least one click, we can calculate the chances of getting zero clicks, and subtract that from 100% or 1 for short:</p><p><strong>1 — (0.5) ^ 5 = 0.96875</strong></p><p>If we compare that to a generic campaign that might have a click-through rate of 10%, our chances of success for a sample of 5 targets is only 41% total:</p><p><strong>1 — (0.9) ^ 5 = 0.40951</strong></p><p>To achieve the same 96.9% confidence interval with the generic campaign, we would need to target 33 employees:</p><p><strong>1 — (0.9) ^ 33 = 0.9690</strong></p><p>We would have to send more than six times the emails and have a very high chance of at least one employee reporting our campaign. Therefore, I think it is always worth the effort to be highly targeted with my pretexts. Even if I have to send 5 individualized messages to 5 separate targets, my chances are far better than sending some canned generic campaign to dozens of users hoping for a win before the blue team blocks my phishing site.</p><h3><strong>How to Achieve 50%+ Click-Through Rate</strong></h3><p>Rather than spew a bunch of theory, I think some examples will be much better at teaching this subject. Let’s look at some pretexts that I’ve used on assessments and achieved well over 50% click-through.</p><h4><strong>Warning</strong></h4><p>Highly effective social engineering pretexts are also often likely to ruffle some feathers, piss some people off, and potentially hurt some targets’ feelings. Always work closely with your client contacts to obtain approval for each scenario before sending to targets. Ideally, send a sample email to your contacts to let them know exactly what it will look like to the end users. Never assume that because a pretext went well at one organization that it will be fine at another. It is always better to maintain a positive relationship with your client than to over-do it because you really wanted some shells. In addition, if you are going to use a pretext that might upset people, it’s always best to upset as few as possible. In general, I prefer to send out emails very slowly, maybe every 20–30 minutes, and then pause the campaign the moment I get my first user interactions. If you use a pretext with an 80% click-through rate against a target list of 100 users, and it’s raining shells faster than you can interact with them, this is a clear sign you are making too much noise.</p><h4><strong>Stalk Your Prey</strong></h4><p>One of my favorite sources for collecting email addresses for target users is Hunter.io’s API. The API not only gives you email accounts, but also a timestamp of when they were found online, and most importantly, the URL of the web page where the email was found. Oftentimes, I find cases of employees posting their work email address as a general contact for non-work related communications. In one case, I found an employee who was highly involved with their child’s high school fundraising events, and had posted their work email address as a way for other parents to get involved. As it turns out, this high school had their own domain and website, but had neglected to set up an SPF record to prevent spoofing emails from their domain. This high school also had a full employee directory, complete with contact information for all of their employees, including administrative staff.</p><p>So, I sent my target user an email, spoofing the principal of the high school, instructing them that there was an incident with their child, and they would be evaluating the need for disciplinary action, along with a link to see a report of the incident. While this email was from an external source, and likely was stamped with some generic warning about “be careful clicking links”, any legitimate emails from the school always have this message, and my spoof was truly indistinguishable from the real thing to the end user. What do you think was the click-through rate for this pretext? If you guessed 100%, you are absolutely correct. I sent one email, and obtained command and control on one employee’s system within an hour of sending the message. While I had a limited time frame to move off their system and establish a foothold elsewhere in the network before they discovered my message was fake, the pretext itself was highly effective.</p><h4><strong>Appeal to Curiosity/Fear</strong></h4><p>Every time I perform a phishing assessment, I make sure to ask my client contacts for phishing ideas. In general, I want to make sure my client contacts know that they are on “my team” and vice versa. In many cases, my clients are excited about the proposition of being an honorary member of the red team and helping to hack their organization. Your clients will always have a much better understanding of the inner workings of their organization and will generally have some great ideas about which pretexts will be successful against their co-workers that you would never think of.</p><p>In one case, my client contact let me know that the company had just recently hosted a big company wide pool party and thought it would be fun to spoof a message saying “we just posted a bunch of pictures from the company pool party and some of these pics are hilarious! Click here to check out the album”. I felt like this pretext was almost too mean, but we got approval to run it anyway. Ultimately, the curiosity sparked by this message, in combination with the fear that there might be some embarrassing photos out there that everyone is going to see, culminated in a very high click-through rate for the sample of employees we targeted. Remember that your client contacts can be excellent team members when you invite them to be. Engagements will tend to run more smoothly and be way more fun when you do.</p><h4><strong>Blending in and Abusing External Trust</strong></h4><p>One of my favorite reusable pretexts when targeting banks and other financial institutions is to spoof the local chamber of commerce. Especially for regional banks and credit unions, I frequently find that a handful of bank employees will join their local chamber of commerce and use it as a cheap marketing platform to build a reputation in the community. In these cases, our targets are usually paying yearly dues for membership, and these chamber of commerce domains are rarely set up with proper SPF records. By spoofing the treasurer of the chamber of commerce, and telling our targets that the membership fees are about to change soon, I can often generate enough curiosity to convince at least one or two targets to click on my link. These campaigns tend to target anywhere from one to five employees and have a very high overall click-through rate for such a seemingly benign message. I would guess that my overall click-through rate for this targeted pretext over the years has been somewhere around 60–80%.</p><h4><strong>Appeal to Altruism</strong></h4><p>Many financial institutions and not-for-profit organizations these days either directly run or partner with philanthropic organizations to build community involvement and recognition as a good brand. Often, these philanthropic branches are legally separate entities with their own distinct names, and their own separate online presence. You can usually find these organizations by looking at your target organization’s recent news, press releases, and social media posts. Employees at your target organization will likely be familiar with their company’s philanthropic arm and may even receive frequent emails from that domain. Because the domains and websites for these philanthropic organizations are typically just used for promotional and marketing materials, they rarely have a strong security posture and may lack email security settings like SPF. One of my favorite pretexts in this case is to email target employees, spoofing the philanthropic organization’s domain, and let them know that they can opt to take a day off of work and volunteer at a number of upcoming philanthropy events. The message might start out something like: “At XYZ company, we know that charity is not always just about financial donations. To foster charity and support our community, we would like to announce that employees can now elect to take a day off work to come help any one of these upcoming charity events…”. I then list some fake partner organizations that include common themes like schools, hospitals, homeless shelters, and food pantries. I also always make sure to look up the local humane society and include them somewhere in the middle of the list. People tend to get pretty excited about the idea of taking a day off work to go hang out with puppies, kitties, and other furry friends, and are usually eager to click on a link to “view a list of upcoming events”. If you stalk your list of potential targets ahead of time, you may also be able to find social media posts with guest appearances from their pets to help narrow down a good list.</p><p><strong>Side Note</strong>: If abusing people’s innate goodwill and love for animals feels wrong, that’s because it is. As with many aspects of red teaming, we sometimes need to perform activities that would be considered illegal or morally wrong under normal circumstances, in order to emulate threats in a realistic manner. Even though scenarios like this can seem harsh, we need to keep in mind that real criminals frequently use even more extreme tactics that we cannot emulate as red teamers because of ethical boundaries, like using threats of physical violence against targets and their families. It is from this perspective that I hold the personal opinion that ‘appeal to altruism’ and similar scenarios should be considered fair game for red team engagements against organizations with a mature security posture. Though you should be aware of the potential impact on trust within your target organization and use tactics like this sparingly.</p><h4><strong>Appeal to Hunger (No Such Thing as a Free Lunch)</strong></h4><p>Phishing is not always about sending fake emails, so here’s an example where I’ve used spoofed phone calls instead. I once had a client that wanted us to include social engineering phone calls but requested that we not use our usual go-to of just spoofing someone in IT. In fact, they specifically requested that we do some sort of ‘free giveaway’ pretext instead. I thought this idea was completely corny and there was no way it would work, so I had to think over the potential angles for quite a while. Eventually, I decided I would like to spoof a local restaurant, and act like the restaurant owner who was calling local businesses to drum up some catering business. With a little searching on Google and Yelp reviews, I was able to actually find that a Cheddars restaurant had recently opened up just down the street from the headquarters of my target organization. I went and cloned their website, and swapped the content on one of the pages to include a ‘Free Entree Coupon’ button that would download an initial access payload. I then spent about an hour practicing a sales pitch for ‘slow cooked BBQ, award winning sauces and loaded salads with homemade salad dressing, all the sides you can’t get enough of like cornbread, cole slaw, green beans with bacon, mashed potatoes, and mac-n-cheese…” until I could rattle off a long list of delicious foods very quickly.</p><p>On my first phishing call, when the target picked up the phone, I just launched straight into my sales pitch about how we were now offering catering, and how great our food is, and how they should definitely consider us any time the company needs catering for an event, and I intentionally talked so fast that the target couldn’t get a word in edgewise. After about a full minute of talking their ear off non-stop, I heard some soft laughter on the other end. I could tell that they admired my ‘entrepreneurial grit’ and didn’t want to be rude back. They responded with something like: “that sounds lovely, but you’re talking to the absolute wrong person. I don’t deal with event planning here at all”. I apologized, and asked if they might be able to forward me on to someone that does deal with event planning. They kindly agreed to forward my call to the right person, but before they did, I thanked them profusely for listening to my whole pitch, and I said I would like to send them a coupon for a free meal for all the trouble. They were reluctant at first, but I convinced them to tell me an email address of where to send the “coupon”. I registered a Gmail account called something like <em>ceddarsrestaurant&lt;city-state&gt;@gmail.com</em> and sent them a link to my phishing site. Just as I was gearing up to make my next phone call to my next target, I got an alert from my phishing server that someone had downloaded my payload. A few moments later, I had a remote shell on my first target’s system. In fact, they attempted to open the fake coupon link, and ran the payload multiple times. Maybe calling just before lunch worked in my favor, or maybe I just got lucky, but either way the overall success rate of this campaign turned out to be 100%.</p><h4><strong>Appeal to Greed</strong></h4><p>Another highly targeted and often effective phishing technique is what I like to jokingly refer to as ‘the long con’. Most phishing campaigns are fully-packaged pretexts that attempt to elicit action from the targets using a single message. The long con, on the other hand, is when you tease a target with an initial message and try to get the target to engage in a back-and-forth conversation with you before sending them the intended payload. In my experience, this tends to work best when we can appeal to a target’s greed, or play into their desires. For example, my team has had multiple “one shot, one kill” phishing campaigns where we targeted sales people in the organization, and impersonated a potential big buyer. We would try to learn a bit of lingo from our organization’s marketing info, and then set up a fake company that looked like an ideal potential customer for one or more sales offerings. We would then check LinkedIn to find the sales people at our target organization and who they had connections with at other companies. We would then send a short message to a target in the sales department, starting with something like: “I was chatting with my friend Dave over at XYZ company, and he mentioned you might be the right guy to talk to about buying large orders of wizbangs to use in our manufacturing of zippitydoodas… could you send me a price sheet?”. Usually, these sales folks would see dollar signs right away, and were thrilled that this potentially big phish had just fallen into their lap. They’re too busy daydreaming about how a big last-minute sale like this could help them smash their quota in Q4 to realize that this is a little too good to be true. Normally, if we could just get an initial response, we knew we could get the target to download and try to open just about any “purchase order” we followed up with. On two occasions, we had a click-through rate over 100% with this scenario. That is, our initial target clicked our link and executed our payload only to find that “nothing happened”, and then forwarded our payload link to a co-worker or superior so that they could try to open the “purchase order”, and we got two shells for the price of one. In one of these instances, our initial target actually had an account on the wrong Active Directory domain, but their superior who also executed the payload had an account on the corporate domain that we intended to compromise.</p><h4><strong>Abusing Internal Trust</strong></h4><p>In general, if you can spoof an internal user at your target organization, the number of options for believable pretexts goes way up, in addition to the overall expected click-through rates for those campaigns. That’s because people inherently trust their co-workers. If they didn’t, then most organizations would simply cease to function. So, whenever possible, it’s useful to attempt to spoof an internal employee or department. In recent years, it seems that a lot more organizations have started to regularly phish their own people to raise awareness about the threat of spoofed emails, so a lot of the oldy-but-goodie scenarios like “new dress code policy” and “change to your w2&#39;’ are quickly losing effectiveness against most users. However, there are still a few lesser known tricks to put a twist on your standard internal employee spoof. One method I’ve found that can help add some legitimacy to spoofed messages is to spoof an email thread instead of just a single email. You simply send emails back and forth between two or more email accounts you own to build up a fake conversation, then forward the whole thread to a tool like <a href=\"https://github.com/fkasler/phishmonger\">Phishmonger</a> where you can do a quick find-and-replace to swap your email addresses for ones at your target organization. So, instead of just asking our target user to do something like clicking a link, we make it appear that multiple of their co-workers have agreed that they must click the link. Another similar technique is to play with the on-behalf-of email header. This header is rarely set in normal conversations, but is supported by all the major email clients, and can be used to make it look like a message is coming from an internal source when it is really coming from a domain we own. These tend to work really well in conjunction with “you need to run ABC update from XYZ vendor”. You buy a doppelganger domain for the vendor, and then make it look like the vendor is sending “on behalf of” someone in the IT department. If you dig around in the RFCs that define SMTP’s headers, you will actually find a few other useful but lesser known headers like this.</p><h3><strong>Bypassing Warning Banners</strong></h3><p>Many mail servers today add an extra context clue for users of when a message originates from an external source in the form of a banner in the message itself. These banners are usually some obnoxious color like bright red and say something like “This email originated from an external source. Be extremely careful clicking any links in this message”. Luckily for us, these messages are stamped on every external email, and tend to be included in message sources for email threads. Therefore, by simply getting any user to respond to any email, we can usually know whether our target organization has this control in place, and exactly how it has been implemented. When gearing up for a red team engagement, you will usually be emailing your client contact ahead of the engagement and therefore automatically be privy to this useful data. If you are concerned about warning banners killing your click-through rates, let’s talk about how to address this control.</p><h4><strong>Option one</strong></h4><p>Don’t worry too much about them. Most users are completely desensitized to them anyway. You might be surprised how many clicks I’ve gotten when this control was in place and I was still spoofing an internal user without any attempt to bypass the banner. If you can come up with any pretext that spoofs an external trusted source, it will actually play into your favor because messages from those sources always have the banner. If you’re still concerned, let’s talk about a couple bypass options.</p><h4><strong>Option Two</strong></h4><p>Push them out of view. I’ve seen a few cases of these banners that were actually applied to the bottom of each email message instead of the top. In these cases, all I had to do to make sure the user never saw the banner was to add a bunch of line breaks (&lt;br&gt; tags) after my message. This would push the banner way down below the bottom of the user’s email preview pane.</p><h4><strong>Option Three</strong></h4><p>Collapse them. Another option that works in far more cases is to use CSS to collapse the banner by setting the “font-size” attribute to 0px for all of the banner’s elements. If you have access to an email thread from a user at your target organization, you can usually see how the banner is constructed in the email source. You can then apply styling to specifically collapse the banner. A more generic approach that works in many cases is to apply a global style to collapse all elements in the email, and then apply in-line styles with the “!important” property to elements in your pretext to make them visible.</p><p><strong>Note:</strong> CSS tricks like this will not work against web-based email clients. If your target uses Outlook to view their emails, these tricks will work just fine. If they use the O365 web portal to view their emails, it will not work. Though, I don’t know of many people who prefer the web portal over a traditional mail client.</p><h3>In Short</h3><p>Go write some custom, targeted phishing campaigns! It can be very fun!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TbvfKLvzNJVZiFnYz_-Z4A.jpeg\" /></figure><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=608268c4c669\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/i-will-make-you-phishers-of-men-608268c4c669\">I Will Make you Phishers of Men</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "PHISHING SCHOOL\nConvincing Targets to Click Your Links\nWhen it comes to phishing advice, the number one question I get from co-workers is “what campaigns are you using?”. People see my success, and wish to emulate it. Well, if a phish is what you wish, I would like you to meet my friend Ish:\nWho am I? My name is Ish\nOn my hand I have a dish.\nI have this dish to help me wish.\nWhen I wish to make a wish\nI wave my hand with a big swish swish.\nThen I say, “I wish for phish!”\nAnd I get phish right on my dish.\nSo…\nIf you wish to make a wish,\nyou may swish for phish with my Ish wish dish.\nIsh Wish Dish\nUnfortunately, I don’t have any wish dishes to spare. What I do have are illustrations. Just as the great Dr. Seuss used silly illustrations to encourage kids to read, I would like to use some concrete examples to encourage you to craft custom phishing emails.\nThese lessons were hard earned. Collected over many years. And they are the foundation of my own perspective on phishing. I am giving you a shortcut. You can learn to think about phishing just the way I do, but there is a catch:\nI need you to live these experiences with me.\nOtherwise it won’t stick. As you read these examples, I need you to imagine it was you behind the keyboard. Feel the sly grin as you craft your cunning lure. Notice that tense anticipation of waiting for that first click. Hear the ding of your Telegram bot letting you know you have a visitor. See the password hit your Phishmonger dashboard. And taste sweet victory when your C2 agent calls home! Take a moment to immerse yourself in these experiences and make them your own. Get stoked, buckle up, and hang with me for a very short but critical tangent…\nWhat are the Odds?\nI’m about to teach you how to win at phishing. Consistently. But first, we will have to do a tiny bit of math. Don’t panic. I’ve written down all the answers for you. Just trust the math is correct. More importantly, trust what the math is telling us!\nIf we want to have a successful phishing campaign, we should be focusing on quality over quantity. But how likely are we to ‘win’ at this game? Keep in mind, for a phishing campaign to be successful, we typically only need a single employee to let us in the door. Therefore, winning at this game means just getting at least one click.\nLet’s say we focus on crafting a highly targeted pretext that will seem very convincing to a small number of users and we can get an expected click-through rate of roughly 50%. If we send our pretext to only 5 targets, our chances of getting at least one click is 96.9%! To calculate the chance of at least one click, we can calculate the chances of getting zero clicks, and subtract that from 100% or 1 for short:\n1 — (0.5) ^ 5 = 0.96875\nIf we compare that to a generic campaign that might have a click-through rate of 10%, our chances of success for a sample of 5 targets is only 41% total:\n1 — (0.9) ^ 5 = 0.40951\nTo achieve the same 96.9% confidence interval with the generic campaign, we would need to target 33 employees:\n1 — (0.9) ^ 33 = 0.9690\nWe would have to send more than six times the emails and have a very high chance of at least one employee reporting our campaign. Therefore, I think it is always worth the effort to be highly targeted with my pretexts. Even if I have to send 5 individualized messages to 5 separate targets, my chances are far better than sending some canned generic campaign to dozens of users hoping for a win before the blue team blocks my phishing site.\nHow to Achieve 50%+ Click-Through Rate\nRather than spew a bunch of theory, I think some examples will be much better at teaching this subject. Let’s look at some pretexts that I’ve used on assessments and achieved well over 50% click-through.\nWarning\nHighly effective social engineering pretexts are also often likely to ruffle some feathers, piss some people off, and potentially hurt some targets’ feelings. Always work closely with your client contacts to obtain approval for each scenario before sending to targets. Ideally, send a sample email to your contacts to let them know exactly what it will look like to the end users. Never assume that because a pretext went well at one organization that it will be fine at another. It is always better to maintain a positive relationship with your client than to over-do it because you really wanted some shells. In addition, if you are going to use a pretext that might upset people, it’s always best to upset as few as possible. In general, I prefer to send out emails very slowly, maybe every 20–30 minutes, and then pause the campaign the moment I get my first user interactions. If you use a pretext with an 80% click-through rate against a target list of 100 users, and it’s raining shells faster than you can interact with them, this is a clear sign you are making too much noise.\nStalk Your Prey\nOne of my favorite sources for collecting email addresses for target users is Hunter.io’s API. The API not only gives you email accounts, but also a timestamp of when they were found online, and most importantly, the URL of the web page where the email was found. Oftentimes, I find cases of employees posting their work email address as a general contact for non-work related communications. In one case, I found an employee who was highly involved with their child’s high school fundraising events, and had posted their work email address as a way for other parents to get involved. As it turns out, this high school had their own domain and website, but had neglected to set up an SPF record to prevent spoofing emails from their domain. This high school also had a full employee directory, complete with contact information for all of their employees, including administrative staff.\nSo, I sent my target user an email, spoofing the principal of the high school, instructing them that there was an incident with their child, and they would be evaluating the need for disciplinary action, along with a link to see a report of the incident. While this email was from an external source, and likely was stamped with some generic warning about “be careful clicking links”, any legitimate emails from the school always have this message, and my spoof was truly indistinguishable from the real thing to the end user. What do you think was the click-through rate for this pretext? If you guessed 100%, you are absolutely correct. I sent one email, and obtained command and control on one employee’s system within an hour of sending the message. While I had a limited time frame to move off their system and establish a foothold elsewhere in the network before they discovered my message was fake, the pretext itself was highly effective.\nAppeal to Curiosity/Fear\nEvery time I perform a phishing assessment, I make sure to ask my client contacts for phishing ideas. In general, I want to make sure my client contacts know that they are on “my team” and vice versa. In many cases, my clients are excited about the proposition of being an honorary member of the red team and helping to hack their organization. Your clients will always have a much better understanding of the inner workings of their organization and will generally have some great ideas about which pretexts will be successful against their co-workers that you would never think of.\nIn one case, my client contact let me know that the company had just recently hosted a big company wide pool party and thought it would be fun to spoof a message saying “we just posted a bunch of pictures from the company pool party and some of these pics are hilarious! Click here to check out the album”. I felt like this pretext was almost too mean, but we got approval to run it anyway. Ultimately, the curiosity sparked by this message, in combination with the fear that there might be some embarrassing photos out there that everyone is going to see, culminated in a very high click-through rate for the sample of employees we targeted. Remember that your client contacts can be excellent team members when you invite them to be. Engagements will tend to run more smoothly and be way more fun when you do.\nBlending in and Abusing External Trust\nOne of my favorite reusable pretexts when targeting banks and other financial institutions is to spoof the local chamber of commerce. Especially for regional banks and credit unions, I frequently find that a handful of bank employees will join their local chamber of commerce and use it as a cheap marketing platform to build a reputation in the community. In these cases, our targets are usually paying yearly dues for membership, and these chamber of commerce domains are rarely set up with proper SPF records. By spoofing the treasurer of the chamber of commerce, and telling our targets that the membership fees are about to change soon, I can often generate enough curiosity to convince at least one or two targets to click on my link. These campaigns tend to target anywhere from one to five employees and have a very high overall click-through rate for such a seemingly benign message. I would guess that my overall click-through rate for this targeted pretext over the years has been somewhere around 60–80%.\nAppeal to Altruism\nMany financial institutions and not-for-profit organizations these days either directly run or partner with philanthropic organizations to build community involvement and recognition as a good brand. Often, these philanthropic branches are legally separate entities with their own distinct names, and their own separate online presence. You can usually find these organizations by looking at your target organization’s recent news, press releases, and social media posts. Employees at your target organization will likely be familiar with their company’s philanthropic arm and may even receive frequent emails from that domain. Because the domains and websites for these philanthropic organizations are typically just used for promotional and marketing materials, they rarely have a strong security posture and may lack email security settings like SPF. One of my favorite pretexts in this case is to email target employees, spoofing the philanthropic organization’s domain, and let them know that they can opt to take a day off of work and volunteer at a number of upcoming philanthropy events. The message might start out something like: “At XYZ company, we know that charity is not always just about financial donations. To foster charity and support our community, we would like to announce that employees can now elect to take a day off work to come help any one of these upcoming charity events…”. I then list some fake partner organizations that include common themes like schools, hospitals, homeless shelters, and food pantries. I also always make sure to look up the local humane society and include them somewhere in the middle of the list. People tend to get pretty excited about the idea of taking a day off work to go hang out with puppies, kitties, and other furry friends, and are usually eager to click on a link to “view a list of upcoming events”. If you stalk your list of potential targets ahead of time, you may also be able to find social media posts with guest appearances from their pets to help narrow down a good list.\nSide Note: If abusing people’s innate goodwill and love for animals feels wrong, that’s because it is. As with many aspects of red teaming, we sometimes need to perform activities that would be considered illegal or morally wrong under normal circumstances, in order to emulate threats in a realistic manner. Even though scenarios like this can seem harsh, we need to keep in mind that real criminals frequently use even more extreme tactics that we cannot emulate as red teamers because of ethical boundaries, like using threats of physical violence against targets and their families. It is from this perspective that I hold the personal opinion that ‘appeal to altruism’ and similar scenarios should be considered fair game for red team engagements against organizations with a mature security posture. Though you should be aware of the potential impact on trust within your target organization and use tactics like this sparingly.\nAppeal to Hunger (No Such Thing as a Free Lunch)\nPhishing is not always about sending fake emails, so here’s an example where I’ve used spoofed phone calls instead. I once had a client that wanted us to include social engineering phone calls but requested that we not use our usual go-to of just spoofing someone in IT. In fact, they specifically requested that we do some sort of ‘free giveaway’ pretext instead. I thought this idea was completely corny and there was no way it would work, so I had to think over the potential angles for quite a while. Eventually, I decided I would like to spoof a local restaurant, and act like the restaurant owner who was calling local businesses to drum up some catering business. With a little searching on Google and Yelp reviews, I was able to actually find that a Cheddars restaurant had recently opened up just down the street from the headquarters of my target organization. I went and cloned their website, and swapped the content on one of the pages to include a ‘Free Entree Coupon’ button that would download an initial access payload. I then spent about an hour practicing a sales pitch for ‘slow cooked BBQ, award winning sauces and loaded salads with homemade salad dressing, all the sides you can’t get enough of like cornbread, cole slaw, green beans with bacon, mashed potatoes, and mac-n-cheese…” until I could rattle off a long list of delicious foods very quickly.\nOn my first phishing call, when the target picked up the phone, I just launched straight into my sales pitch about how we were now offering catering, and how great our food is, and how they should definitely consider us any time the company needs catering for an event, and I intentionally talked so fast that the target couldn’t get a word in edgewise. After about a full minute of talking their ear off non-stop, I heard some soft laughter on the other end. I could tell that they admired my ‘entrepreneurial grit’ and didn’t want to be rude back. They responded with something like: “that sounds lovely, but you’re talking to the absolute wrong person. I don’t deal with event planning here at all”. I apologized, and asked if they might be able to forward me on to someone that does deal with event planning. They kindly agreed to forward my call to the right person, but before they did, I thanked them profusely for listening to my whole pitch, and I said I would like to send them a coupon for a free meal for all the trouble. They were reluctant at first, but I convinced them to tell me an email address of where to send the “coupon”. I registered a Gmail account called something like ceddarsrestaurant<city-state>@gmail.com and sent them a link to my phishing site. Just as I was gearing up to make my next phone call to my next target, I got an alert from my phishing server that someone had downloaded my payload. A few moments later, I had a remote shell on my first target’s system. In fact, they attempted to open the fake coupon link, and ran the payload multiple times. Maybe calling just before lunch worked in my favor, or maybe I just got lucky, but either way the overall success rate of this campaign turned out to be 100%.\nAppeal to Greed\nAnother highly targeted and often effective phishing technique is what I like to jokingly refer to as ‘the long con’. Most phishing campaigns are fully-packaged pretexts that attempt to elicit action from the targets using a single message. The long con, on the other hand, is when you tease a target with an initial message and try to get the target to engage in a back-and-forth conversation with you before sending them the intended payload. In my experience, this tends to work best when we can appeal to a target’s greed, or play into their desires. For example, my team has had multiple “one shot, one kill” phishing campaigns where we targeted sales people in the organization, and impersonated a potential big buyer. We would try to learn a bit of lingo from our organization’s marketing info, and then set up a fake company that looked like an ideal potential customer for one or more sales offerings. We would then check LinkedIn to find the sales people at our target organization and who they had connections with at other companies. We would then send a short message to a target in the sales department, starting with something like: “I was chatting with my friend Dave over at XYZ company, and he mentioned you might be the right guy to talk to about buying large orders of wizbangs to use in our manufacturing of zippitydoodas… could you send me a price sheet?”. Usually, these sales folks would see dollar signs right away, and were thrilled that this potentially big phish had just fallen into their lap. They’re too busy daydreaming about how a big last-minute sale like this could help them smash their quota in Q4 to realize that this is a little too good to be true. Normally, if we could just get an initial response, we knew we could get the target to download and try to open just about any “purchase order” we followed up with. On two occasions, we had a click-through rate over 100% with this scenario. That is, our initial target clicked our link and executed our payload only to find that “nothing happened”, and then forwarded our payload link to a co-worker or superior so that they could try to open the “purchase order”, and we got two shells for the price of one. In one of these instances, our initial target actually had an account on the wrong Active Directory domain, but their superior who also executed the payload had an account on the corporate domain that we intended to compromise.\nAbusing Internal Trust\nIn general, if you can spoof an internal user at your target organization, the number of options for believable pretexts goes way up, in addition to the overall expected click-through rates for those campaigns. That’s because people inherently trust their co-workers. If they didn’t, then most organizations would simply cease to function. So, whenever possible, it’s useful to attempt to spoof an internal employee or department. In recent years, it seems that a lot more organizations have started to regularly phish their own people to raise awareness about the threat of spoofed emails, so a lot of the oldy-but-goodie scenarios like “new dress code policy” and “change to your w2'’ are quickly losing effectiveness against most users. However, there are still a few lesser known tricks to put a twist on your standard internal employee spoof. One method I’ve found that can help add some legitimacy to spoofed messages is to spoof an email thread instead of just a single email. You simply send emails back and forth between two or more email accounts you own to build up a fake conversation, then forward the whole thread to a tool like Phishmonger where you can do a quick find-and-replace to swap your email addresses for ones at your target organization. So, instead of just asking our target user to do something like clicking a link, we make it appear that multiple of their co-workers have agreed that they must click the link. Another similar technique is to play with the on-behalf-of email header. This header is rarely set in normal conversations, but is supported by all the major email clients, and can be used to make it look like a message is coming from an internal source when it is really coming from a domain we own. These tend to work really well in conjunction with “you need to run ABC update from XYZ vendor”. You buy a doppelganger domain for the vendor, and then make it look like the vendor is sending “on behalf of” someone in the IT department. If you dig around in the RFCs that define SMTP’s headers, you will actually find a few other useful but lesser known headers like this.\nBypassing Warning Banners\nMany mail servers today add an extra context clue for users of when a message originates from an external source in the form of a banner in the message itself. These banners are usually some obnoxious color like bright red and say something like “This email originated from an external source. Be extremely careful clicking any links in this message”. Luckily for us, these messages are stamped on every external email, and tend to be included in message sources for email threads. Therefore, by simply getting any user to respond to any email, we can usually know whether our target organization has this control in place, and exactly how it has been implemented. When gearing up for a red team engagement, you will usually be emailing your client contact ahead of the engagement and therefore automatically be privy to this useful data. If you are concerned about warning banners killing your click-through rates, let’s talk about how to address this control.\nOption one\nDon’t worry too much about them. Most users are completely desensitized to them anyway. You might be surprised how many clicks I’ve gotten when this control was in place and I was still spoofing an internal user without any attempt to bypass the banner. If you can come up with any pretext that spoofs an external trusted source, it will actually play into your favor because messages from those sources always have the banner. If you’re still concerned, let’s talk about a couple bypass options.\nOption Two\nPush them out of view. I’ve seen a few cases of these banners that were actually applied to the bottom of each email message instead of the top. In these cases, all I had to do to make sure the user never saw the banner was to add a bunch of line breaks (<br> tags) after my message. This would push the banner way down below the bottom of the user’s email preview pane.\nOption Three\nCollapse them. Another option that works in far more cases is to use CSS to collapse the banner by setting the “font-size” attribute to 0px for all of the banner’s elements. If you have access to an email thread from a user at your target organization, you can usually see how the banner is constructed in the email source. You can then apply styling to specifically collapse the banner. A more generic approach that works in many cases is to apply a global style to collapse all elements in the email, and then apply in-line styles with the “!important” property to elements in your pretext to make them visible.\nNote: CSS tricks like this will not work against web-based email clients. If your target uses Outlook to view their emails, these tricks will work just fine. If they use the O365 web portal to view their emails, it will not work. Though, I don’t know of many people who prefer the web portal over a traditional mail client.\nIn Short\nGo write some custom, targeted phishing campaigns! It can be very fun!\n\nI Will Make you Phishers of Men was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Forrest Kasler",
      "guid": "https://medium.com/p/608268c4c669",
      "categories": [
        "cybersecurity",
        "phishing",
        "social-engineering",
        "red-team",
        "penetration-testing"
      ],
      "isoDate": "2024-06-25T14:12:04.000Z"
    },
    {
      "creator": "Garrett White",
      "title": "Deconstructing Logon Session Enumeration",
      "link": "https://posts.specterops.io/deconstructing-logon-session-enumeration-0426b8452ef5?source=rss----f05f8696e3cc---4",
      "pubDate": "Fri, 21 Jun 2024 18:18:02 GMT",
      "content:encoded": "<h4>Purple Teaming</h4><h4>How we define and create test cases for our purple team runbooks</h4><h3>Intro</h3><p>In our purple team service, we try to take a depth and quality approach and run many different functionally diverse test cases for a given technique. In this blog, I will describe our process of defining and implementing test cases for our purple team runbooks. The goal of this blog post is to provide the community with a bit more information about how we implement test cases for logon session enumeration, what preventative controls might be, and how this process can be applied to other techniques.</p><h3>Defining Unique Test Cases</h3><p>We wanted to develop a logical numbering system to separate test cases for each technique. After a couple of iterations of our purple team service, we started to deliberately select test cases and run variations based on three distinct categories:</p><ol><li><strong>Distinct Procedures:</strong> Jared <a href=\"https://posts.specterops.io/on-detection-tactical-to-function-810c14798f63\">defines</a> this as “<strong><em>a sequence of operations that, when combined, implement a technique or sub-technique.</em></strong>” We attempt to deconstruct tools that implement the technique to find functional differences, whether that tool is open-source or a Microsoft binary. This can require reverse engineering or reviewing source code to reveal what the tool is doing under the hood. It also might involve writing or altering existing tooling to meet your needs. An example of this can be found in part 1 of Jared’s blog <a href=\"https://posts.specterops.io/on-detection-tactical-to-functional-d71da6505720\">On Detection: Tactical to Functional</a>, where he reviews the source code of Mimikatz’s sekurlsa::logonPasswords module. If the tool implements a unique set of operations in the call graph, then we define that as a distinct procedure.</li><li><strong>Execution Modality:</strong> We then alter the execution modality, which changes how the set of functions is implemented. This is outlined in part 12 of Jared’s blog <a href=\"https://posts.specterops.io/behavior-vs-execution-modality-3318e8e81739\">On Detection: Tactical to Functional</a>: “one tool that is built into the operating system (Built-in Console Application), a tool that had to be dropped to disk (Third-Party Console Application), a tool that could run in PowerShell’s memory (PowerShell Script), a tool that runs in the memory of an arbitrary process (Beacon Object File), and a tool that can run via a proxy without ever touching the subject endpoint (Direct RPC Request)”. This variation helps us determine if we run the same distinct procedure but with a different execution mechanism (Beacon Object File, Unmanaged PowerShell, etc.) or is implemented in a different programming language (C, Python, PowerShell, etc.) will alter whether your security controls detected or prevented it.</li><li><strong>Minor Variations:</strong> Finally, we introduce slight variations to alter the payload, target user, computer, or process depending on the technique we are working on. In the case of logon session enumeration, we alter local vs. remote logon sessions and the machine we are targeting (i.e., file server, workstation, etc). During purple team assessments, we often find ourselves using this variation based on the organization’s environmental factors. For other techniques, these environmental factors normally include choosing which account to Kerberoast or which process to inject into.</li></ol><p>Defining test cases in this manner allows us to triangulate a technique’s coverage estimation rather than treat the techniques in the MITRE ATT&amp;CK matrix as a bingo card where we run net session and net1 session, fill in the box for this technique, and move on to the next one. After running each test case during the purple team assessment, we look for whether the test case was <a href=\"https://youtu.be/B_2AfoT2WxU?t=2820\">prevented, detected, or observed (telemetry)</a> by any security controls the organization may have.</p><h3>Deconstructing Distinct Logon Session Enumeration Procedures</h3><p>Let’s dive into logon session enumeration by deconstructing the functional differences between three distinct procedures. If you want to learn more (or want to apply this methodology yourself), you can find out more about the process we use to examine the function call stack of tools in Nathan’s <a href=\"https://posts.specterops.io/beyond-procedures-digging-into-the-function-call-stack-88c082aeb573\">Beyond Procedures: Digging into the Function Call Stack</a> and Jared’s <a href=\"https://posts.specterops.io/on-detection/home\">On Detection: Tactical to Functional</a> series.</p><p>We can start by examining the three distinct procedures that <a href=\"https://github.com/BloodHoundAD/SharpHound\">SharpHound</a> implements. Rohan <a href=\"https://blog.cptjesus.com/posts/sharphoundtargetting/#session-collection\">blogged</a> about the three different methods SharpHound uses. SharpHound can attempt to use all three depending on the context it’s running under and what arguments are passed to it. The implementation of each procedure can be found here: <a href=\"https://github.com/BloodHoundAD/SharpHoundCommon/blob/v3/src/CommonLib/Processors/ComputerSessionProcessor.cs#L48\">NetSessionEnum</a>, <a href=\"https://github.com/BloodHoundAD/SharpHoundCommon/blob/v3/src/CommonLib/Processors/ComputerSessionProcessor.cs#L174\">NetWkstaEnum</a>, and <a href=\"https://github.com/BloodHoundAD/SharpHoundCommon/blob/v3/src/CommonLib/Processors/ComputerSessionProcessor.cs#L279\">GetSubKeyNames</a> in the SharpHoundCommon library. Matt also talks about this in his <a href=\"https://posts.specterops.io/bofhound-session-integration-7b88b6f18423\">BOFHound: Session Integration</a> blog.</p><p>Here is a breakdown of each of the three unique procedures implemented in SharpHound for remote session enumeration:</p><p><strong>Distinct Procedure #1: Network Session Enumeration (</strong><a href=\"https://learn.microsoft.com/en-us/windows/win32/api/lmshare/nf-lmshare-netsessionenum\"><strong>NetSessionEnum</strong></a><strong>)</strong></p><p>NetSessionEnum is a Win32 API implemented in <em>netapi32.dll</em>. The <a href=\"https://posts.specterops.io/behavior-vs-execution-modality-3318e8e81739\">image</a> below shows where each tool is implemented in the function call stack:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/0*myV1JGjROFFoGeqZ\" /><figcaption>NetSessionEnum Function Call Graph</figcaption></figure><p>This Win32 API returns a list of active <strong>remote </strong>or <strong>network </strong>logon sessions. These two blogs (<a href=\"https://blog.netwrix.com/2022/11/18/making-internal-reconnaissance-harder-using-netcease-and-samri1o/\">Netwrix</a> and <a href=\"https://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-2/\">Compass Security</a>) go into detail about which operating systems allow “Authenticated Users” to query logon sessions and how to check and restrict access to this API remotely by altering the security descriptor in the HKLM/SYSTEM/CurrentControlSet/Services/LanmanServer/DefaultSecurity/SrvsvcSessionInfo registry key. If we read Microsoft’s documentation on the RPC server, we see the <a href=\"https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-srvs/c30de0d7-f503-441a-8789-89c69f81ad39\">MS-SRVS RPC server</a> is <strong><em>only </em></strong>implemented via the \\PIPE\\srvsvc named pipe (RPC servers can also be commonly implemented via TCP as well). As Microsoft’s documentation states, <a href=\"https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-wpo/4de75e21-36fd-440a-859b-75accc74487c\">named pipes</a> communicate over CIFS\\SMB via port 445.</p><p>In our purple team service, we usually target the organization’s most active file server for two reasons. First, port 445 (SMB) will generally be open from everywhere on the internal network for this server. Second, this server has the most value to an attacker since it could contain hundreds or even thousands of user-to-machine mappings an attacker could use for “user hunting.”</p><p><strong>Distinct Procedure #2: </strong>Interactive, Service, and Batch Logon Session Enumeration (<a href=\"https://learn.microsoft.com/en-us/windows/win32/api/lmwksta/nf-lmwksta-netwkstauserenum\"><strong>NetWkstaUserEnum</strong></a><strong>)</strong></p><p>NetWkstaUserEnum is also a Win32 API implemented in <em>netapi32.dll</em>. Below is the breakdown of the function call stack and where each tool is implemented:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/0*OxaI27ZE89q3WDpk\" /><figcaption>NetWkstaUserEnum Function Call Graph</figcaption></figure><p>As Microsoft documentation says: “This list includes interactive, service, and batch logons” and “Members of the Administrators, and the Server, System, and Print Operator local groups can also view information.” This API call has different permission requirements and returns a different set of information than the NetSessionEnum API call; however, just like NetSessionEnum, the <a href=\"https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-wkst/5061f908-06b2-4752-9cc7-4008763b338f\">RPC server</a> is implemented <strong><em>only </em></strong>via the \\PIPE\\wkssvc named pipe. Again, this <a href=\"https://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-2/\">blog</a> from Compass Security goes into more detail about the requirements.</p><p>Since this, by default, requires administrator or other privileged rights on the target machine, we will again attempt to target file servers and usually get an access denied response when running this procedure. As a detection engineer, if someone attempts to enumerate sessions, do we have the telemetry even if they are unsuccessful? Next, we will attempt to target a workstation on which we have administrator rights to enumerate sessions using this minor variation in a different test case.</p><p><strong>Distinct Procedure #3: Interactive Session Enumeration (</strong><a href=\"https://learn.microsoft.com/en-us/windows/win32/api/winreg/nf-winreg-regenumkeyexw\"><strong>RegEnumKeyExW</strong></a><strong>)</strong></p><blockquote><strong><em>Note</em></strong>: I’m only showing the function call stack of RegEnumKeyExW, SharpHound calls OpenRemoteBaseKey to get a handle to the remote key before calling RegEnumKeyExW. I also left out calls to <a href=\"https://learn.microsoft.com/en-us/windows/win32/apiindex/windows-apisets\">API sets</a> in this graph.</blockquote><p>RegEnumKeyExW is, again, a Win32 API implemented in <em>advapi32.dll</em>. Below is the breakdown of the function call stack and where each tool is implemented:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/0*EcPtqX1_9Yepgw3-\" /><figcaption>RegEnumKeyExW Function Call Graph</figcaption></figure><p>As Microsoft documentation says, the remote system “requires the Remote Registry service to be running on the remote computer.” Again, this <a href=\"https://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-3/\">blog</a> from Compass Security goes into more detail about the requirements, but by default, the service is disabled on workstation operating systems like Windows 11 and 10 and set to trigger start on server operating systems by interacting with the \\PIPE\\winreg named pipe. If the remote registry service is running (or triggerable), then the HKEY_USERS hive can be queried for a list of subkeys. These subkeys contain SIDs for users that are interactively logged on. Like NetWkstaUserEnum and NetSessionEnum, the <a href=\"https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-rrp/01e7fc6d-0c96-425a-a26a-6b75c67ca77d\">RPC server</a> is implemented <strong>only </strong>via the \\PIPE\\winreg named pipe.</p><h3>Putting it all Together with Test Cases</h3><p>Now that we have a diverse set of procedures and tooling examples that use a variety of execution modalities, we can start creating test cases to run for this technique. Below, I have included an example set of test cases and associated numbering system using each of the three distinct procedures and altering the execution modality for each one.</p><p>You can also find a full TOML runbook for the examples below here: <a href=\"https://ghst.ly/session-enumeration-runbook\">https://ghst.ly/session-enumeration-runbook</a>. All of the test cases are free or open source and can be executed via an <a href=\"https://github.com/MythicAgents/Apollo\">Apollo</a> agent with the <a href=\"https://github.com/its-a-feature/Mythic\">Mythic C2</a> framework.</p><p>For example, our numbering looks like: Test Case X.Y.Z</p><ul><li>X — Distinct Procedure</li><li>Y — Execution Modality</li><li>Z — Minor Variation</li></ul><p>A sample set of test cases we might include:</p><p><strong>Network Session Enumeration (</strong><a href=\"https://learn.microsoft.com/en-us/windows/win32/api/lmshare/nf-lmshare-netsessionenum\"><strong>NetSessionEnum</strong></a><strong>)</strong></p><ul><li>Test Case 1.0.0 — Enumerate SMB Sessions From Third-Party Utility On Disk (NetSess)</li><li>Test Case 1.1.0 — Enumerate SMB Sessions via Beacon Object File (BOF) — get-netsession</li><li>Test Case 1.2.0 — Enumerate SMB Sessions via PowerView’s Get-NetSession</li><li>Test Case 1.3.0 — Enumerate SMB Sessions via Proxied RPC</li></ul><p><strong>Interactive, Service, and Batch Logon Session Enumeration</strong> (<a href=\"https://learn.microsoft.com/en-us/windows/win32/api/lmwksta/nf-lmwksta-netwkstauserenum\"><strong>NetWkstaUserEnum</strong></a><strong>)</strong></p><ul><li>Test Case 2.0.0 — Enumerate Interactive, Service, and Batch Logon Sessions from BOF (netloggedon) — Server</li><li>Test Case 2.0.1 — Enumerate Interactive, Service, and Batch Logon Sessions from BOF (netloggedon) — Workstation</li><li>Test Case 2.1.0 — Enumerate Interactive, Service, and Batch Logon Sessions from Impacket (netloggedon.py)</li><li>Test Case 2.2.0 — Enumerate SMB Sessions via PowerView’s Get-NetLoggedOn</li></ul><p><strong>Interactive Session Enumeration (</strong><a href=\"https://learn.microsoft.com/en-us/windows/win32/api/winreg/nf-winreg-regenumkeyexw\"><strong>RegEnumKeyExW</strong></a><strong>)</strong></p><ul><li>Test Case 3.0.0 — Enumerate Interactive Sessions via reg_query BOF (Server)</li><li>Test Case 3.0.1 — Enumerate Interactive Logon Sessions via reg_query BOF (workstation)</li><li>Test Case 3.1.0 — Enumerate Interactive Sessions from Impacket (reg.py)</li></ul><p>After executing each test case, we can determine if the test case was prevented, detected, or observed. Tracking information like this allows us to provide feedback on your controls and predict how likely they would detect or prevent an adversary’s arbitrary selection of procedure or execution modality. Also, we space test cases about 10 minutes apart; name artifacts like files, registry keys, and processes by their corresponding test case number; and alternate the machine and source user we are executing from to make finding observable telemetry easier. We may include or exclude certain test cases based on the organization’s security controls. For example, if they block and alert on all powershell.exe usage, we aren’t going to run 40 test cases across multiple techniques that attempt to call the PowerShell binary.</p><h3>Conclusion</h3><p>By researching and deconstructing each tool and looking at the underlying function call stacks, we found that regardless of which distinct procedure or execution modality was used, they all used three different RPC servers, each implemented using <strong>named pipes</strong>. This will also allow us to triangulate detection coverage and help determine if a custom or vendor-based rule is looking for a brittle indicator or a tool-specific detail\\toolmark.</p><p>We now have a fairly broad set of test cases for a runbook that accounts for a wide variety of attacker tradecraft for this technique. Knowing this as a blue teamer or detection engineer will allow me to implement a much more comprehensive detection strategy for this particular technique around the three named pipes we discovered. This allows us to write robust detection rules, rather than looking for the string “Get-NetSession” in a PowerShell script. Would this produce a perfect detection for session enumeration? No. Does this include every single way an attacker can determine where a user is logged? No. Does deconstructing adversary tradecraft in this manner vastly improve our coverage for the technique? Absolutely.</p><p>In my next post, I will cover many log sources native to Windows (I’m counting Sysmon as native) and a couple of EDRs that allow us to detect logon session enumeration via named pipes (or TCP in some cases). Some of these sources you might be familiar with, others aren’t very well documented. Each of these log sources can be enabled and shipped to a centralized place like a SIEM. Each source has its requirements, provides a different context, and has its pros and cons for use in a detection rule.</p><h3>References</h3><ul><li><a href=\"https://blog.cptjesus.com/posts/sharphoundtargetting/#session-collection\">https://blog.cptjesus.com/posts/sharphoundtargetting/#session-collection</a></li><li><a href=\"https://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-2/\">https://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-2/</a></li><li><a href=\"https://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-3/\">https://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-3/</a></li><li><a href=\"https://blog.netwrix.com/2022/11/18/making-internal-reconnaissance-harder-using-netcease-and-samri1o/\">https://blog.netwrix.com/2022/11/18/making-internal-reconnaissance-harder-using-netcease-and-samri1o/</a></li></ul><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=0426b8452ef5\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/deconstructing-logon-session-enumeration-0426b8452ef5\">Deconstructing Logon Session Enumeration</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "Purple Teaming\nHow we define and create test cases for our purple team runbooks\nIntro\nIn our purple team service, we try to take a depth and quality approach and run many different functionally diverse test cases for a given technique. In this blog, I will describe our process of defining and implementing test cases for our purple team runbooks. The goal of this blog post is to provide the community with a bit more information about how we implement test cases for logon session enumeration, what preventative controls might be, and how this process can be applied to other techniques.\nDefining Unique Test Cases\nWe wanted to develop a logical numbering system to separate test cases for each technique. After a couple of iterations of our purple team service, we started to deliberately select test cases and run variations based on three distinct categories:\n\nDistinct Procedures: Jared defines this as “a sequence of operations that, when combined, implement a technique or sub-technique.” We attempt to deconstruct tools that implement the technique to find functional differences, whether that tool is open-source or a Microsoft binary. This can require reverse engineering or reviewing source code to reveal what the tool is doing under the hood. It also might involve writing or altering existing tooling to meet your needs. An example of this can be found in part 1 of Jared’s blog On Detection: Tactical to Functional, where he reviews the source code of Mimikatz’s sekurlsa::logonPasswords module. If the tool implements a unique set of operations in the call graph, then we define that as a distinct procedure.\nExecution Modality: We then alter the execution modality, which changes how the set of functions is implemented. This is outlined in part 12 of Jared’s blog On Detection: Tactical to Functional: “one tool that is built into the operating system (Built-in Console Application), a tool that had to be dropped to disk (Third-Party Console Application), a tool that could run in PowerShell’s memory (PowerShell Script), a tool that runs in the memory of an arbitrary process (Beacon Object File), and a tool that can run via a proxy without ever touching the subject endpoint (Direct RPC Request)”. This variation helps us determine if we run the same distinct procedure but with a different execution mechanism (Beacon Object File, Unmanaged PowerShell, etc.) or is implemented in a different programming language (C, Python, PowerShell, etc.) will alter whether your security controls detected or prevented it.\nMinor Variations: Finally, we introduce slight variations to alter the payload, target user, computer, or process depending on the technique we are working on. In the case of logon session enumeration, we alter local vs. remote logon sessions and the machine we are targeting (i.e., file server, workstation, etc). During purple team assessments, we often find ourselves using this variation based on the organization’s environmental factors. For other techniques, these environmental factors normally include choosing which account to Kerberoast or which process to inject into.\n\nDefining test cases in this manner allows us to triangulate a technique’s coverage estimation rather than treat the techniques in the MITRE ATT&CK matrix as a bingo card where we run net session and net1 session, fill in the box for this technique, and move on to the next one. After running each test case during the purple team assessment, we look for whether the test case was prevented, detected, or observed (telemetry) by any security controls the organization may have.\nDeconstructing Distinct Logon Session Enumeration Procedures\nLet’s dive into logon session enumeration by deconstructing the functional differences between three distinct procedures. If you want to learn more (or want to apply this methodology yourself), you can find out more about the process we use to examine the function call stack of tools in Nathan’s Beyond Procedures: Digging into the Function Call Stack and Jared’s On Detection: Tactical to Functional series.\nWe can start by examining the three distinct procedures that SharpHound implements. Rohan blogged about the three different methods SharpHound uses. SharpHound can attempt to use all three depending on the context it’s running under and what arguments are passed to it. The implementation of each procedure can be found here: NetSessionEnum, NetWkstaEnum, and GetSubKeyNames in the SharpHoundCommon library. Matt also talks about this in his BOFHound: Session Integration blog.\nHere is a breakdown of each of the three unique procedures implemented in SharpHound for remote session enumeration:\nDistinct Procedure #1: Network Session Enumeration (NetSessionEnum)\nNetSessionEnum is a Win32 API implemented in netapi32.dll. The image below shows where each tool is implemented in the function call stack:\nNetSessionEnum Function Call Graph\nThis Win32 API returns a list of active remote or network logon sessions. These two blogs (Netwrix and Compass Security) go into detail about which operating systems allow “Authenticated Users” to query logon sessions and how to check and restrict access to this API remotely by altering the security descriptor in the HKLM/SYSTEM/CurrentControlSet/Services/LanmanServer/DefaultSecurity/SrvsvcSessionInfo registry key. If we read Microsoft’s documentation on the RPC server, we see the MS-SRVS RPC server is only implemented via the \\PIPE\\srvsvc named pipe (RPC servers can also be commonly implemented via TCP as well). As Microsoft’s documentation states, named pipes communicate over CIFS\\SMB via port 445.\nIn our purple team service, we usually target the organization’s most active file server for two reasons. First, port 445 (SMB) will generally be open from everywhere on the internal network for this server. Second, this server has the most value to an attacker since it could contain hundreds or even thousands of user-to-machine mappings an attacker could use for “user hunting.”\nDistinct Procedure #2: Interactive, Service, and Batch Logon Session Enumeration (NetWkstaUserEnum)\nNetWkstaUserEnum is also a Win32 API implemented in netapi32.dll. Below is the breakdown of the function call stack and where each tool is implemented:\nNetWkstaUserEnum Function Call Graph\nAs Microsoft documentation says: “This list includes interactive, service, and batch logons” and “Members of the Administrators, and the Server, System, and Print Operator local groups can also view information.” This API call has different permission requirements and returns a different set of information than the NetSessionEnum API call; however, just like NetSessionEnum, the RPC server is implemented only via the \\PIPE\\wkssvc named pipe. Again, this blog from Compass Security goes into more detail about the requirements.\nSince this, by default, requires administrator or other privileged rights on the target machine, we will again attempt to target file servers and usually get an access denied response when running this procedure. As a detection engineer, if someone attempts to enumerate sessions, do we have the telemetry even if they are unsuccessful? Next, we will attempt to target a workstation on which we have administrator rights to enumerate sessions using this minor variation in a different test case.\nDistinct Procedure #3: Interactive Session Enumeration (RegEnumKeyExW)\nNote: I’m only showing the function call stack of RegEnumKeyExW, SharpHound calls OpenRemoteBaseKey to get a handle to the remote key before calling RegEnumKeyExW. I also left out calls to API sets in this graph.\nRegEnumKeyExW is, again, a Win32 API implemented in advapi32.dll. Below is the breakdown of the function call stack and where each tool is implemented:\nRegEnumKeyExW Function Call Graph\nAs Microsoft documentation says, the remote system “requires the Remote Registry service to be running on the remote computer.” Again, this blog from Compass Security goes into more detail about the requirements, but by default, the service is disabled on workstation operating systems like Windows 11 and 10 and set to trigger start on server operating systems by interacting with the \\PIPE\\winreg named pipe. If the remote registry service is running (or triggerable), then the HKEY_USERS hive can be queried for a list of subkeys. These subkeys contain SIDs for users that are interactively logged on. Like NetWkstaUserEnum and NetSessionEnum, the RPC server is implemented only via the \\PIPE\\winreg named pipe.\nPutting it all Together with Test Cases\nNow that we have a diverse set of procedures and tooling examples that use a variety of execution modalities, we can start creating test cases to run for this technique. Below, I have included an example set of test cases and associated numbering system using each of the three distinct procedures and altering the execution modality for each one.\nYou can also find a full TOML runbook for the examples below here: https://ghst.ly/session-enumeration-runbook. All of the test cases are free or open source and can be executed via an Apollo agent with the Mythic C2 framework.\nFor example, our numbering looks like: Test Case X.Y.Z\n\nX — Distinct Procedure\nY — Execution Modality\nZ — Minor Variation\n\nA sample set of test cases we might include:\nNetwork Session Enumeration (NetSessionEnum)\n\nTest Case 1.0.0 — Enumerate SMB Sessions From Third-Party Utility On Disk (NetSess)\nTest Case 1.1.0 — Enumerate SMB Sessions via Beacon Object File (BOF) — get-netsession\nTest Case 1.2.0 — Enumerate SMB Sessions via PowerView’s Get-NetSession\nTest Case 1.3.0 — Enumerate SMB Sessions via Proxied RPC\n\nInteractive, Service, and Batch Logon Session Enumeration (NetWkstaUserEnum)\n\nTest Case 2.0.0 — Enumerate Interactive, Service, and Batch Logon Sessions from BOF (netloggedon) — Server\nTest Case 2.0.1 — Enumerate Interactive, Service, and Batch Logon Sessions from BOF (netloggedon) — Workstation\nTest Case 2.1.0 — Enumerate Interactive, Service, and Batch Logon Sessions from Impacket (netloggedon.py)\nTest Case 2.2.0 — Enumerate SMB Sessions via PowerView’s Get-NetLoggedOn\n\nInteractive Session Enumeration (RegEnumKeyExW)\n\nTest Case 3.0.0 — Enumerate Interactive Sessions via reg_query BOF (Server)\nTest Case 3.0.1 — Enumerate Interactive Logon Sessions via reg_query BOF (workstation)\nTest Case 3.1.0 — Enumerate Interactive Sessions from Impacket (reg.py)\n\nAfter executing each test case, we can determine if the test case was prevented, detected, or observed. Tracking information like this allows us to provide feedback on your controls and predict how likely they would detect or prevent an adversary’s arbitrary selection of procedure or execution modality. Also, we space test cases about 10 minutes apart; name artifacts like files, registry keys, and processes by their corresponding test case number; and alternate the machine and source user we are executing from to make finding observable telemetry easier. We may include or exclude certain test cases based on the organization’s security controls. For example, if they block and alert on all powershell.exe usage, we aren’t going to run 40 test cases across multiple techniques that attempt to call the PowerShell binary.\nConclusion\nBy researching and deconstructing each tool and looking at the underlying function call stacks, we found that regardless of which distinct procedure or execution modality was used, they all used three different RPC servers, each implemented using named pipes. This will also allow us to triangulate detection coverage and help determine if a custom or vendor-based rule is looking for a brittle indicator or a tool-specific detail\\toolmark.\nWe now have a fairly broad set of test cases for a runbook that accounts for a wide variety of attacker tradecraft for this technique. Knowing this as a blue teamer or detection engineer will allow me to implement a much more comprehensive detection strategy for this particular technique around the three named pipes we discovered. This allows us to write robust detection rules, rather than looking for the string “Get-NetSession” in a PowerShell script. Would this produce a perfect detection for session enumeration? No. Does this include every single way an attacker can determine where a user is logged? No. Does deconstructing adversary tradecraft in this manner vastly improve our coverage for the technique? Absolutely.\nIn my next post, I will cover many log sources native to Windows (I’m counting Sysmon as native) and a couple of EDRs that allow us to detect logon session enumeration via named pipes (or TCP in some cases). Some of these sources you might be familiar with, others aren’t very well documented. Each of these log sources can be enabled and shipped to a centralized place like a SIEM. Each source has its requirements, provides a different context, and has its pros and cons for use in a detection rule.\nReferences\n\nhttps://blog.cptjesus.com/posts/sharphoundtargetting/#session-collection\nhttps://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-2/\nhttps://blog.compass-security.com/2022/05/bloodhound-inner-workings-part-3/\nhttps://blog.netwrix.com/2022/11/18/making-internal-reconnaissance-harder-using-netcease-and-samri1o/\n\nDeconstructing Logon Session Enumeration was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Garrett White",
      "guid": "https://medium.com/p/0426b8452ef5",
      "categories": [
        "specterops",
        "detection-engineering",
        "purple-team",
        "information-security",
        "infosec"
      ],
      "isoDate": "2024-06-21T18:18:02.000Z"
    },
    {
      "creator": "Hope Walker",
      "title": "How Privileged Identity Management Affects Conditional Access Policies",
      "link": "https://posts.specterops.io/how-privileged-identity-management-affects-conditional-access-policies-03371d06cfe3?source=rss----f05f8696e3cc---4",
      "pubDate": "Thu, 20 Jun 2024 15:19:36 GMT",
      "content:encoded": "<h3>Introduction</h3><p>When administrators use directory roles (aka Entra ID roles) when configuring Conditional Access Policies (CAPs), users are not included in the enforcement of that CAP until after that user’s role assignment is activated. If administrators use Privileged Identity Management (PIM) for role assignments, this adds complexity because role eligibility is not considered for roles in CAPs. This has implications for offensive testing, defensive coverage, and even disaster recovery.</p><h3>What are CAPs?</h3><p>To put it very simply, <a href=\"https://learn.microsoft.com/en-us/entra/identity/conditional-access/overview\">CAPs</a> are if-then statements for determining access. There are several <a href=\"https://learn.microsoft.com/en-us/entra/identity/conditional-access/concept-conditional-access-conditions\">conditions</a> which can be set for evaluation and Microsoft is adding more regularly. Conditions for access to resources are set in the CAPs and authentication attempts are evaluated against the policies at the time of authentication. This evaluation occurs for all authentication attempts and principals to see if they match the conditions for a policy. The parameters evaluated can include details such as the device used, the location or IP address, the authentication context, and several other factors which can be configured.</p><p>CAPs can be used to provide an additional layer of protection for resources in Entra and Azure Resource Manager (Azure RM) on top of other access control. They allow administrators to more granularly specify how a principal is allowed to access resources. This is a quick explanation of CAPs and if you are unfamiliar with the concepts, it would be best to review the linked information.</p><p>Specifically, for this blog, we will focus on the conditions in a policy which apply to directory roles. Entra allows built-in roles to be specified in a policy by including directory roles in the policy for under “Users” as shown below. Directory roles can be included or excluded in a policy, and it is common to find roles used for both. Below, we can see what a directory role included in a CAP looks like.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*Yd7z79rbgOSeGBxp\" /></figure><h3>What is PIM?</h3><p><a href=\"https://learn.microsoft.com/en-us/entra/id-governance/privileged-identity-management/pim-configure\">PIM</a> is Microsoft’s solution for providing just-in-time (JIT) access to roles or groups. PIM can currently be used with Entra roles, certain types of groups for membership, and Azure RM if configured. For this blog, our focus is specifically on PIM for Entra roles. In this context, PIM is used to assign eligibility to principals for roles in Entra. These can be the built-in roles or custom roles in the tenant. In the image below, we can see the list of roles and the users who are eligible for those roles under the “Eligible assignments” in the PIM blade.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*p_Lx22ivmdaYKpHB\" /></figure><p>When a user is eligible for a role, that eligibility allows for users to activate their roles when needed, and the roles remain inactive when unneeded the privileges. When a user activates a role, they are reauthenticated automatically with the context of the role they activate.</p><p>Role policies can be configured with additional requirements to use or assign the role. This is important to note because additional requirements or notifications can be added to a role which can have a further impact on how the roles must be activated. A user must be eligible for a role in order to activate it for use with PIM. After activation, the user will have the same privileges as a user with a permanently active role assignment for the duration of the activation.</p><h3>What is the Problem?</h3><p>The issue with using PIM and CAPs together is that CAPs look at the current state of the account when it is authenticating. PIM eligibility for a role is not the same as having the role active for the account when it comes to evaluation in CAPs. <strong>Currently, CAPs do not consider role eligibility as a factor in authentication.</strong></p><p>If a user is eligible for a role but the role is not activated, then the CAPs are not applied to the user. After the role is activated, the user will reauthenticate so the active Entra ID role is reflected in their tokens for use. Activation is the point at which CAPs which apply to the role will be evaluated for conditional access.</p><p>To demonstrate this, let us look at a simple example. In this scenario, we have the following three elements configured:</p><ol><li><em>PIMUser1 </em>— Test user account with role eligibility</li><li>Organizational Messages Approver — Built-in role in the tenant with <em>PIMUser1 </em>assigned eligibility</li><li><em>PIMCAPTest </em>— Conditional access policy which requires users with the PIMTestRole assignment to authenticate from a VPN</li></ol><p>CAPs are only applicable to built-in roles; there is no significance to the role choice here</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*dDXaKYWopHvIjdNj\" /></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*gkVrlEglUAO8LAq_\" /></figure><p>To start, we can authenticate with the <em>PIMUser1 </em>user account because the role is not activated and so the CAP is not applied to the user’s logon attempt.</p><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FCADMhK2InQk%3Ffeature%3Doembed&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DCADMhK2InQk&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FCADMhK2InQk%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"854\" height=\"480\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/f7766ba5f26d7d9a285f93bdd0e57d8a/href\">https://medium.com/media/f7766ba5f26d7d9a285f93bdd0e57d8a/href</a></iframe><p>Next, if we open the PIM blade and activate the role, the user will automatically attempt to authenticate again with the new role applied. However, this time the user will be blocked because they now meet the conditions specified in the CAP.</p><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2F4EHxoIEiheI%3Ffeature%3Doembed&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4EHxoIEiheI&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2F4EHxoIEiheI%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"854\" height=\"480\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/81b87aa43e611c9a058b15326a5beb9b/href\">https://medium.com/media/81b87aa43e611c9a058b15326a5beb9b/href</a></iframe><p>CAPs will reevaluate access as soon as the role is activated because a new token must be issued when the role is activated. When that happens a new authentication request is sent by Entra automatically and CAPs will match for our <em>PIMUser1 </em>because the role is now activated for the user.</p><h3>What is the Impact?</h3><p>Since CAPs evaluate the current state of the account and there is a reevaluation when the role activates, this can cause some issues if not considered when configuring CAPs and PIM in a tenant. To get a better understanding of this impact, we can look at some common scenarios in which CAPs and PIM are used.</p><h3>Scenario 1: Loss of Access During Disaster Recovery</h3><p>One example of a potential issue is when a role is excluded from CAPs. Certain roles are often excluded from CAPs, such as Global Administrator, so those users can gain access into the environment in case of a lockout. It is recommended that <a href=\"https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/security-emergency-access\">break-glass accounts</a> be created and CAPs exclude these accounts from policies to allow for access. To simplify this, some tenants I have encountered will simply exclude their Global Administrators by role instead of having dedicated break-glass accounts. Additionally, Microsoft <a href=\"https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/best-practices#2-use-privileged-identity-management-to-grant-just-in-time-access\">recommends using PIM for roles</a> and it is not uncommon for a tenant to use PIM instead of having permanent assignments for highly privileged roles.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/722/0*lMB6-XEueU3uaGEC\" /></figure><p>In this scenario, if the tenant is using PIM for all Global Administrator roles and at the time of lockout, the role is not activated for any users, the administrators are in for a long day trying to regain access. The role eligible Global Administrator users will not be allowed to authenticate because they do not meet the requirements for access without the active role. This is part of the reason why dedicated break glass accounts with permanent Global Administrator role assignments are recommended. You should not find yourself in this situation if you are setting these up correctly, but I have seen this type of setup in environments before unfortunately.</p><h3>Scenario 2: Unforeseen Gaps in Coverage</h3><p>In cases where roles are included in CAPs as a condition, a similar issue can arise. Roles included in a CAPs will only be applied when a role is activated so those users who are role eligible are not covered in the CAP until the role is activated. For example, let us say an administrator is attempting to secure the environment and instantiates a CAP which covers the directory roles in use. The administrator also uses PIM for all role assignments so people will have JIT access to those roles instead of them being permanently active. The image below shows an example of how this policy would look.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/712/0*4FYoqfXovYJWn48X\" /></figure><p>Independently, these decisions seem to adhere to best practices. However, without additional configuration for the users who are role eligible, the CAP does not cover them until the time of activation. What an administrator would need to do is make sure those accounts are covered by another CAP to ensure that MFA is always used.</p><h3>Scenario 3: Role Activation During an Offensive Engagement</h3><p>For offensive engagements, this can become relevant when looking for avenues for escalation. If you find a user who can get around CAPs and is role eligible, CAPs could cause you to lose access when the role is activated.</p><p>As we saw in the previous examples, role activation can cause additional conditions to be evaluated which may match settings in a CAP and change the access decision. If you are conducting an offensive engagement, policies which apply to a role should be evaluated prior to activation of the role to ensure activation will not cause access loss.</p><p><strong><em>NOTE</em></strong>: Although not discussed here in depth, it is a good idea to look at role policies as well. In addition to CAPs, role policy settings for the specific role should be reviewed prior to activation. By default, there are no additional requirements published to a role, but these can be added for roles individually. These can require multi-factor authentication (MFA), approval, or send notifications to others.</p><h3>What is the Solution?</h3><p>The solution is not to avoid using CAPs and PIM together. These features do provide protection when implemented properly, but it is important to understand how they work and the purpose they serve. CAPs are an additional layer of protection which deal with authentication. PIM is for JIT access to privileged roles. To use an analogy, we can compare these to a gate guard and a camera respectively. CAPs are the equivalent of a guard sitting at a gate with a list of conditions to determine if someone is allowed on the campus but does not check which building they go to after they get to the gate. Each building should have a list of who is allowed to enter or not, but the gate guard does not see those lists. PIM is similar to installing a camera outside of the door to a secure area. Functionally for access, the camera records what happened but does nothing to prevent someone from entering the door. It may deter some people, but the camera is in no way a barrier for entry when someone can simply open the door. Similarly, PIM without additional configuration will provide you a record of what happened during the intrusion, but the actual activation of a role is as simple as clicking a button.</p><p>This does not mean there is nothing for us to do. Sticking with the analogy, we can provide a more robust list of rules to our gate guard to ensure more coverage for access scenarios. For CAPs, this would look like creating additional policies to account for changes in roles and ensuring coverage of authentication scenarios. For our camera, additional actions such as alerting on motion or requiring biometric information to prove identity can be included. For PIM, this would be setting notifications for role activation and requiring MFA for role activation.</p><p>Since there are many settings for both CAPs and PIM this blogpost did not cover, I will suggest a couple of resources to help in securing a tenant with PIM and CAPs. First is <a href=\"https://permiso.io/blog/privileged-identity-management-pim-for-many-a-false-sense-of-security\">this blog</a> which takes a critical look at PIM and how it is commonly implemented and provides recommendations for securing it further. Second is <a href=\"https://blog.admindroid.com/conditional-access-in-privileged-identity-management-for-groups/\">this resource</a>, which discusses how PIM and CAPs can be used together, though it does focus on PIM for groups. Lastly, <a href=\"https://codyburkard.com/blog/jitprivilegeescalation/\">this blog </a>provides attacker insight into how attackers can circumvent PIM restrictions.</p><h3>Conclusion</h3><p>The main take away from the blog should be that role eligibility with PIM is not taken into account for CAP evaluation. It is not until a role is activated which is specified in a CAP that the policy is applied to an authentication attempt. This is both when a role is included and excluded from a policy. Additional configuration can help reduce the oversights this creates.</p><p>One last note, Microsoft makes changes to these features, so it is best to not treat PIM and CAPs as “set it and forget it” security features. These should be reevaluated regularly to ensure new configuration settings do not create new gaps or problems for access.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=03371d06cfe3\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/how-privileged-identity-management-affects-conditional-access-policies-03371d06cfe3\">How Privileged Identity Management Affects Conditional Access Policies</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "Introduction\nWhen administrators use directory roles (aka Entra ID roles) when configuring Conditional Access Policies (CAPs), users are not included in the enforcement of that CAP until after that user’s role assignment is activated. If administrators use Privileged Identity Management (PIM) for role assignments, this adds complexity because role eligibility is not considered for roles in CAPs. This has implications for offensive testing, defensive coverage, and even disaster recovery.\nWhat are CAPs?\nTo put it very simply, CAPs are if-then statements for determining access. There are several conditions which can be set for evaluation and Microsoft is adding more regularly. Conditions for access to resources are set in the CAPs and authentication attempts are evaluated against the policies at the time of authentication. This evaluation occurs for all authentication attempts and principals to see if they match the conditions for a policy. The parameters evaluated can include details such as the device used, the location or IP address, the authentication context, and several other factors which can be configured.\nCAPs can be used to provide an additional layer of protection for resources in Entra and Azure Resource Manager (Azure RM) on top of other access control. They allow administrators to more granularly specify how a principal is allowed to access resources. This is a quick explanation of CAPs and if you are unfamiliar with the concepts, it would be best to review the linked information.\nSpecifically, for this blog, we will focus on the conditions in a policy which apply to directory roles. Entra allows built-in roles to be specified in a policy by including directory roles in the policy for under “Users” as shown below. Directory roles can be included or excluded in a policy, and it is common to find roles used for both. Below, we can see what a directory role included in a CAP looks like.\n\nWhat is PIM?\nPIM is Microsoft’s solution for providing just-in-time (JIT) access to roles or groups. PIM can currently be used with Entra roles, certain types of groups for membership, and Azure RM if configured. For this blog, our focus is specifically on PIM for Entra roles. In this context, PIM is used to assign eligibility to principals for roles in Entra. These can be the built-in roles or custom roles in the tenant. In the image below, we can see the list of roles and the users who are eligible for those roles under the “Eligible assignments” in the PIM blade.\n\nWhen a user is eligible for a role, that eligibility allows for users to activate their roles when needed, and the roles remain inactive when unneeded the privileges. When a user activates a role, they are reauthenticated automatically with the context of the role they activate.\nRole policies can be configured with additional requirements to use or assign the role. This is important to note because additional requirements or notifications can be added to a role which can have a further impact on how the roles must be activated. A user must be eligible for a role in order to activate it for use with PIM. After activation, the user will have the same privileges as a user with a permanently active role assignment for the duration of the activation.\nWhat is the Problem?\nThe issue with using PIM and CAPs together is that CAPs look at the current state of the account when it is authenticating. PIM eligibility for a role is not the same as having the role active for the account when it comes to evaluation in CAPs. Currently, CAPs do not consider role eligibility as a factor in authentication.\nIf a user is eligible for a role but the role is not activated, then the CAPs are not applied to the user. After the role is activated, the user will reauthenticate so the active Entra ID role is reflected in their tokens for use. Activation is the point at which CAPs which apply to the role will be evaluated for conditional access.\nTo demonstrate this, let us look at a simple example. In this scenario, we have the following three elements configured:\n\nPIMUser1 — Test user account with role eligibility\nOrganizational Messages Approver — Built-in role in the tenant with PIMUser1 assigned eligibility\nPIMCAPTest — Conditional access policy which requires users with the PIMTestRole assignment to authenticate from a VPN\n\nCAPs are only applicable to built-in roles; there is no significance to the role choice here\n\nTo start, we can authenticate with the PIMUser1 user account because the role is not activated and so the CAP is not applied to the user’s logon attempt.\nhttps://medium.com/media/f7766ba5f26d7d9a285f93bdd0e57d8a/href\nNext, if we open the PIM blade and activate the role, the user will automatically attempt to authenticate again with the new role applied. However, this time the user will be blocked because they now meet the conditions specified in the CAP.\nhttps://medium.com/media/81b87aa43e611c9a058b15326a5beb9b/href\nCAPs will reevaluate access as soon as the role is activated because a new token must be issued when the role is activated. When that happens a new authentication request is sent by Entra automatically and CAPs will match for our PIMUser1 because the role is now activated for the user.\nWhat is the Impact?\nSince CAPs evaluate the current state of the account and there is a reevaluation when the role activates, this can cause some issues if not considered when configuring CAPs and PIM in a tenant. To get a better understanding of this impact, we can look at some common scenarios in which CAPs and PIM are used.\nScenario 1: Loss of Access During Disaster Recovery\nOne example of a potential issue is when a role is excluded from CAPs. Certain roles are often excluded from CAPs, such as Global Administrator, so those users can gain access into the environment in case of a lockout. It is recommended that break-glass accounts be created and CAPs exclude these accounts from policies to allow for access. To simplify this, some tenants I have encountered will simply exclude their Global Administrators by role instead of having dedicated break-glass accounts. Additionally, Microsoft recommends using PIM for roles and it is not uncommon for a tenant to use PIM instead of having permanent assignments for highly privileged roles.\n\nIn this scenario, if the tenant is using PIM for all Global Administrator roles and at the time of lockout, the role is not activated for any users, the administrators are in for a long day trying to regain access. The role eligible Global Administrator users will not be allowed to authenticate because they do not meet the requirements for access without the active role. This is part of the reason why dedicated break glass accounts with permanent Global Administrator role assignments are recommended. You should not find yourself in this situation if you are setting these up correctly, but I have seen this type of setup in environments before unfortunately.\nScenario 2: Unforeseen Gaps in Coverage\nIn cases where roles are included in CAPs as a condition, a similar issue can arise. Roles included in a CAPs will only be applied when a role is activated so those users who are role eligible are not covered in the CAP until the role is activated. For example, let us say an administrator is attempting to secure the environment and instantiates a CAP which covers the directory roles in use. The administrator also uses PIM for all role assignments so people will have JIT access to those roles instead of them being permanently active. The image below shows an example of how this policy would look.\n\nIndependently, these decisions seem to adhere to best practices. However, without additional configuration for the users who are role eligible, the CAP does not cover them until the time of activation. What an administrator would need to do is make sure those accounts are covered by another CAP to ensure that MFA is always used.\nScenario 3: Role Activation During an Offensive Engagement\nFor offensive engagements, this can become relevant when looking for avenues for escalation. If you find a user who can get around CAPs and is role eligible, CAPs could cause you to lose access when the role is activated.\nAs we saw in the previous examples, role activation can cause additional conditions to be evaluated which may match settings in a CAP and change the access decision. If you are conducting an offensive engagement, policies which apply to a role should be evaluated prior to activation of the role to ensure activation will not cause access loss.\nNOTE: Although not discussed here in depth, it is a good idea to look at role policies as well. In addition to CAPs, role policy settings for the specific role should be reviewed prior to activation. By default, there are no additional requirements published to a role, but these can be added for roles individually. These can require multi-factor authentication (MFA), approval, or send notifications to others.\nWhat is the Solution?\nThe solution is not to avoid using CAPs and PIM together. These features do provide protection when implemented properly, but it is important to understand how they work and the purpose they serve. CAPs are an additional layer of protection which deal with authentication. PIM is for JIT access to privileged roles. To use an analogy, we can compare these to a gate guard and a camera respectively. CAPs are the equivalent of a guard sitting at a gate with a list of conditions to determine if someone is allowed on the campus but does not check which building they go to after they get to the gate. Each building should have a list of who is allowed to enter or not, but the gate guard does not see those lists. PIM is similar to installing a camera outside of the door to a secure area. Functionally for access, the camera records what happened but does nothing to prevent someone from entering the door. It may deter some people, but the camera is in no way a barrier for entry when someone can simply open the door. Similarly, PIM without additional configuration will provide you a record of what happened during the intrusion, but the actual activation of a role is as simple as clicking a button.\nThis does not mean there is nothing for us to do. Sticking with the analogy, we can provide a more robust list of rules to our gate guard to ensure more coverage for access scenarios. For CAPs, this would look like creating additional policies to account for changes in roles and ensuring coverage of authentication scenarios. For our camera, additional actions such as alerting on motion or requiring biometric information to prove identity can be included. For PIM, this would be setting notifications for role activation and requiring MFA for role activation.\nSince there are many settings for both CAPs and PIM this blogpost did not cover, I will suggest a couple of resources to help in securing a tenant with PIM and CAPs. First is this blog which takes a critical look at PIM and how it is commonly implemented and provides recommendations for securing it further. Second is this resource, which discusses how PIM and CAPs can be used together, though it does focus on PIM for groups. Lastly, this blog provides attacker insight into how attackers can circumvent PIM restrictions.\nConclusion\nThe main take away from the blog should be that role eligibility with PIM is not taken into account for CAP evaluation. It is not until a role is activated which is specified in a CAP that the policy is applied to an authentication attempt. This is both when a role is included and excluded from a policy. Additional configuration can help reduce the oversights this creates.\nOne last note, Microsoft makes changes to these features, so it is best to not treat PIM and CAPs as “set it and forget it” security features. These should be reevaluated regularly to ensure new configuration settings do not create new gaps or problems for access.\n\nHow Privileged Identity Management Affects Conditional Access Policies was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Hope Walker",
      "guid": "https://medium.com/p/03371d06cfe3",
      "categories": [
        "entra",
        "azure"
      ],
      "isoDate": "2024-06-20T15:19:36.000Z"
    },
    {
      "creator": "Forrest Kasler",
      "title": "Feeding the Phishes",
      "link": "https://posts.specterops.io/feeding-the-phishes-276c3579bba7?source=rss----f05f8696e3cc---4",
      "pubDate": "Tue, 18 Jun 2024 13:21:36 GMT",
      "content:encoded": "<h4>PHISHING SCHOOL</h4><h4>Bypassing Phishing Link Filters</h4><p>You could have a solid pretext that slips right by your target secure email gateway (SEG); however, if your link looks too sketchy (or, you know, “smells phishy”), your phish could go belly-up before it even gets a bite. That’s why I tend to think of link filters as their own separate control. Let’s talk briefly about how these link filters work and then explore some ways we might be able to bypass them.</p><h3>What the Filter? (WTF)</h3><p>Over the past few years, I’ve noticed a growing interest in detecting phishing based on the links themselves–or, at least, there are several very popular SEGs that place a very high weight on the presence of a link in an email. I’ve seen so much of this that I have made this type of detection one of my first troubleshooting steps when a SEG blocks me. I’ll simply remove all links from an email and check if the message content gets through.</p><p>In at least one case, I encountered a SEG that blocked ANY email that contained a link to ANY unrecognized domain, no matter what the wording or subject line said. In this case, I believe my client was curating a list of allowed domains and instructed the SEG to block everything else. It’s an extreme measure, but I think it is a very valid concern. Emails with links are inherently riskier than emails that do not contain links; therefore, most modern SEGs will increase the SPAM score of any message that contains a link and often will apply additional scrutiny to the links themselves.</p><h3><strong>How Link Filters Work — Finding the Links</strong></h3><p>If a SEG filters links in an email, it will first need to detect/parse each link in the content. To do this, almost any experienced software engineer will directly go to using Regular Expressions (“regex” for short):</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/600/0*nXbHJwwj-uXLnu3o\" /><figcaption>Stand back! I know regular expressions</figcaption></figure><p>To which, any other experienced software engineer will be quick to remind us that while regex is extremely powerful, it is also easy to screw up:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/548/0*adVO6GvQ4v55r8ly\" /><figcaption>99 problems (and regex is one)</figcaption></figure><p>As an example, here are just a few of the top regex filters I found for parsing links on <a href=\"https://stackoverflow.com/questions/6038061/regular-expression-to-find-urls-within-a-string\">stackoverflow</a>:</p><p><em>(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&amp;:\\/~+#-]*[\\w@?^=%&amp;\\/~+#-])</em></p><p><em>(?:(?:https?|ftp|file):\\/\\/|www\\.|ftp\\.)(?:\\([-A-Z0–9+&amp;@#\\/%=~_|$?!:,.]*\\)|[-A-Z0–9+&amp;@#\\/%=~_|$?!:,.])*(?:\\([-A-Z0–9+&amp;@#\\/%=~_|$?!:,.]*\\)|[A-Z0–9+&amp;@#\\/%=~_|$])</em></p><p><em>(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&amp;?=%.]+</em></p><p><em>([\\w+]+\\:\\/\\/)?([\\w\\d-]+\\.)*[\\w-]+[\\.\\:]\\w+([\\/\\?\\=\\&amp;\\#\\.]?[\\w-]+)*\\/?</em></p><p><em>(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0–9%])|www\\d{0,3}[.]|[a-z0–9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()&lt;&gt;]+|\\(([^\\s()&lt;&gt;]+|(\\([^\\s()&lt;&gt;]+\\)))*\\))+(?:\\(([^\\s()&lt;&gt;]+|(\\([^\\s()&lt;&gt;]+\\)))*\\)|[^\\s`!()\\[\\]{};:’”.,&lt;&gt;?«»“”‘’]))</em></p><p>Don’t worry if you don’t know what any of these mean. I consider myself to be well versed in regex and even I have no opinion on which of these options would be better than the others. <strong>However, there are a couple things I would like to note from these examples</strong>:</p><ol><li>There is no “right” answer; URLs can be very complex</li><li>Most (but not all) are looking for strings that start with “http” or something similar</li></ol><p>These are also some of the most popular (think “smart people”) answers to this problem of parsing links. I could also imagine that some software engineers would take a more naive approach of searching for all anchor (“&lt;a&gt;”) HTML tags or looking for “href=” to indicate the start of a link. No matter which solution the software engineer chooses, there are likely going to be at least some valid URLs that their parser doesn’t catch and might leave room for a categorical bypass. We might also be able to evade parsers if we can avoid the common indicators like “http” or break up our link into multiple sections.</p><p><strong>Side Note:</strong> Did you see that some of these popular URL parsers account for FTP and some don’t? Did you know that most browsers can connect to FTP shares? Have you ever tried to deliver a phishing payload over an anonymous FTP link?</p><h3><strong>How Link Filters Work — Filtering the Links</strong></h3><p>Once a SEG has parsed out all the links in an email, how should it determine which ones look legitimate and which ones don’t? Most SEGs these days look at two major factors for each link:</p><ol><li>The reputation of the domain</li><li>How the link “looks”</li></ol><p>Checking the domain reputation is pretty straightforward; you just split the link to see what’s between the first two forward slashes (“//”) and the next forward slash (“/”) and look up the resulting domain or subdomain on Virustotal or similar. Many SEGs will share intelligence on known bad domains with other security products and vice versa. If your domain has been flagged as malicious, the SEG will either block the email or remove the link.</p><p>As far as checking how the link “looks”, most SEGs these days use artificial intelligence or machine learning (i.e., AI/ML) to categorize links as malicious or benign. These AI models have been trained on a large volume of known-bad links and can detect themes and patterns commonly used by SPAM authors. As phishers, I think it’s important for us to focus on the “known-bad” part of that statement.</p><p>I’ve seen one researcher’s talk who claimed their AI model was able to detect over 98% of malicious links from their training data. At first glance, this seems like a very impressive number; however, we need to keep in mind that in order to have a training set of malicious links in the first place, humans had to detect 100% of the training set as malicious. Therefore, the AI model was only 98% as good as a human at detecting phishing links solely on the “look” of the link. I would imagine that it would do much worse on a set of unknown-bad links, if there was a way to hypothetically attain such a set. To slip through the cracks, we should aim to put our links in that unknown-bad category.</p><p>Even though we are up against AI models, I like to remind myself that these models can only be trained on human-curated data and therefore can only theoretically approach the competence of a human, but not surpass humans at this task. If we can make our links look convincing enough for a human, the AI should not give us any trouble.</p><h3><strong>Bypassing Link Filters</strong></h3><p>Given what we now know about how link filters work, we should have two main tactics available to us for bypassing the filter:</p><ol><li>Format our link so that it slips through the link parsing phase</li><li>Make our link “look” more legitimate</li></ol><p>If the parser doesn’t register our link as a link, then it can’t apply any additional scrutiny to the location. If we can make our link location look like some legitimate link, then even if we can’t bypass the parser, we might get the green light anyway. Please note that these approaches are not mutually exclusive and you might have greater success mixing techniques.</p><h3><strong>Bypassing the Parser</strong></h3><h4><strong>Don’t use an anchor tag</strong></h4><p>One of the most basic parser bypasses I have found for some SEGs is to simply leave the link URL in plaintext by removing the hyperlink in Outlook. Normally, link URLs are placed in the “hypertext reference” (href) attribute of an HTML anchor tag (&lt;a&gt;). As I mentioned earlier, one naive but surprisingly common solution for parsing links is to use an HTML parsing library like BeautifulSoup in Python. For example:</p><pre>soup = BeautifulSoup(email.content, &#39;html.parser&#39;)<br>links = soup.find_all(&quot;a&quot;) # Find all elements with the tag &lt;a&gt;<br>for link in links:<br>  print(&quot;Link:&quot;, link.get(&quot;href&quot;), &quot;Text:&quot;, link.string)</pre><p>Any SEG that uses this approach to parse links won’t see a URL outside of an anchor tag. While a URL that is not a clickable link might look a little odd to the end user, it’s generally worth the tradeoff when this bypass works. In many cases, mail clients will parse and display URLs as hyperlinks even if they are not in an anchor tag; therefore, there is usually little to no downside of using this technique.</p><h4><strong>Use a Base Tag (a.k.a BaseStriker Attack)</strong></h4><p>One interesting method of bypassing some link filters is to use a little-known HTML tag called “base”. This tag allows you to set the base domain for any links that use relative references (i.e., links with hrefs that start with “/something” instead of direct references like “https://example.com/something”). In this case, the “https://example.com” would be considered the “base” of the URL. By defining the base using the HTML base tag in the header of the HTML content, you can then use just relative references in the body of the message. While HTML headers frequently contain URLs for things like CSS or XML schemas, the header is usually not expected to contain anything malicious and may be overlooked by a link parser. This technique is known as the “BaseStriker” attack and has been known to work against some very popular SEGs:</p><p><a href=\"https://www.cyberdefensemagazine.com/basestriker-attack-technique-allow-to-bypass-microsoft-office-365-anti-phishing-filter/\">https://www.cyberdefensemagazine.com/basestriker-attack-technique-allow-to-bypass-microsoft-office-365-anti-phishing-filter/</a></p><p>The reason why this technique works is because you essentially break your link into two pieces: the domain is in the HTML headers, and the rest of the URL is in your anchor tags in the body. Because the hrefs for the anchor tags don’t start with “https://” they aren’t detected as links.</p><h4><strong>Scheming Little Bypasses</strong></h4><p>The first part of a URL, before the colon and forward slashes, is what’s known as the “scheme”:</p><pre>URI = scheme &quot;:&quot; [&quot;//&quot; authority] path [&quot;?&quot; query] [&quot;#&quot; fragment]</pre><p>As mentioned earlier, some of the more robust ways to detect URLs is by looking for anything that looks like a scheme (e.g. “http://”, or “https://”), followed by a sequence of characters that would be allowed in a URL. If we simply leave off the scheme, many link parsers will not be able to detect our URL, but it will still look like a URL to a human:</p><p>accounts.goooogle.com/login?id=34567</p><p>A human might easily be convinced to simply copy and paste this link into their browser for us. In addition, there are quite a few legitimate schemes that could open a program on our target user’s system and potentially slip through a URL parser that is only looking for web links:</p><p><a href=\"https://en.wikipedia.org/wiki/List_of_URI_schemes\">https://en.wikipedia.org/wiki/List_of_URI_schemes</a></p><p>There are at least a few that could be very useful as phishing links ;)</p><h4>QR Phishing</h4><p>What if there isn’t a link in the email at all? What if it’s an image instead? You can use a tool like SquarePhish to automate phishing with QR codes instead of traditional links:</p><p><a href=\"https://github.com/secureworks/squarephish\">GitHub - secureworks/squarephish</a></p><p>I haven’t played with this yet, but have heard good things from friends that have used similar techniques. If you want to play with automating this attack yourself, NodeJS has a simple library for generating QRs:</p><p><a href=\"https://www.npmjs.com/package/qrcode\">qrcode</a></p><h3><strong>Bypassing the Filter</strong></h3><h4><strong>Don’t Mask</strong></h4><p>(Hold on. I need to get on my soapbox…) I can’t count how many times I’ve been blocked because of a masked link only to find that unmasking the link would get the same pretext through. I think this is because spammers have thoroughly abused this feature of anchor tags in the past and average email users seldom use masked links. Link filters tend to see masked links as far more dangerous than regular links; therefore, just use a regular link. It seems like everyone these days knows how to hover a link and check its real location anyway, so masked links are even bad at tricking humans now. <strong>Don’t be cliche. Don’t use masked links.</strong></p><h4><strong>Use Categorized Domains</strong></h4><p>Many link filters block or remove links to domains that are either uncategorized, categorized as malicious, or were recently registered. Therefore, it’s generally a good idea to use domains that have been parked long enough to be categorized. We’ve already touched on this in “<a href=\"https://medium.com/p/1a2f02010ed7\">One Phish Two Phish, Red Teams Spew Phish</a>”, so I’ll skip the process of getting a good domain; however, just know that the same rules apply here.</p><h4><strong>Use “Legitimate” Domains</strong></h4><p>If you don’t want to go through all the trouble of maintaining categorized domains for phishing links, there are some generally trustworthy domains you can leverage instead. One example I recently saw “in-the-wild” was a spammer using a sites.google.com link. They just hosted their phishing page on Google! I thought this was brilliant because I would expect most link filters to allow Google, and even most end users would think anything on google.com must be legit. Some other similar examples would be hosting your phishing sites as static pages on GitHub, in an S3 bucket, other common content delivery networks (CDNs), or on SharePoint, etc. There are tons of seemingly “legitimate” sites that allow users to host pages of arbitrary HTML content.</p><h4><strong>Arbitrary Redirects</strong></h4><p>Along the same lines as hosting your phishing site on a trusted domain is using trusted domains to redirect to your phishing site. One classic example of this would be link shorteners like TinyURL. While TinyURL has been abused for SPAM to the point that I would expect most SEGs to block TinyURL links, it does demonstrate the usefulness of arbitrary redirects.</p><p>A more useful form of arbitrary redirect for bypassing link filters are URLs with either cross-site scripting (XSS) vulnerabilities that allow us to specify a ‘window.location’ change or URLs that take an HTTP GET parameter specifying where the page should redirect to. As part of my reconnaissance phase, I like to spend at least a few minutes on the main website of my target to look for these types of vulnerabilities. These vulnerabilities are surprisingly common and while an arbitrary redirect might be considered a low-risk finding on a web application penetration test report, they can be extremely useful when combined with phishing. Your links will point to a URL on your target organization’s main website. It is extremely unlikely that a link filter or even a human will see the danger. In some cases, you may find that your target organization has configured an explicit allow list in the SEG for links that point to their domains.</p><h4><strong>Link to an Attachment</strong></h4><p>Did you know that links in an email can also point to an email attachment? Instead of providing a URL in the href of your anchor tag, you can specify the content identifier (CID) of the attachment (e.g. href=“cid:mycontentidentifier@content.net”). One way I have used this trick to bypass link filters is to link to an HTML attachment and use obfuscated JavaScript to redirect the user to the phishing site. Because our href does not look like a URL, most SEGs will think our link is benign. You could also link to a PDF, DOCX, or several other usually allowed file types that then contain the real phishing link. This might require a little more setup in your pretext to instruct the user, or just hope that they will click the link after opening the document. In this case, I think it makes the most sense to add any additional instructions inside the document where the contents are less likely to be scrutinized by the SEG’s content filter.</p><h4><strong>Pick Up The Phone</strong></h4><p>This blog rounds out our “message inbound” controls that we have to bypass for social engineering pretexts. It would not be complete without mentioning one of the simplest bypasses of them all:</p><p><strong>Not using email!</strong></p><p>If you pick up the phone and talk directly to your target, your pretext travels from your mouth, through the phone, then directly into their ear, and hits their brain without ever passing through a content or reputation filter.</p><p>Along the same lines, Zoom calls, Teams chats, LinkedIn messaging, and just about any other common business communication channel will likely be subject to far fewer controls than email. I’ve trained quite a few red teamers who prefer phone calls over emails because it greatly simplifies their workflow. Just a few awkward calls is usually all it takes to cede access to a target environment.</p><p>More interactive forms of communication, like phone calls, also allow you to gauge how the target is feeling about your pretext in real time. It’s usually obvious within seconds whether someone believes you and wants to help or if they think you’re full of it and it’s time to cut your losses, hang up the phone, and try someone else. You can also use phone calls as a way to prime a target for a follow-up email to add perceived legitimacy. Getting our message to the user is half the battle, and social engineering phone calls can be a powerful shortcut.</p><h3>In Summary</h3><p>If you need to bypass a link filter, either:</p><ol><li>Make your link look like it’s not a link</li><li>Make your link look like a “legitimate” link</li></ol><p>People still use links in emails all the time. You just need to blend in with the “real” ones and you can trick the filter. If you are really in a pinch, just call your targets instead. It feels more personal, but it gets the job done quickly.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=276c3579bba7\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/feeding-the-phishes-276c3579bba7\">Feeding the Phishes</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "PHISHING SCHOOL\nBypassing Phishing Link Filters\nYou could have a solid pretext that slips right by your target secure email gateway (SEG); however, if your link looks too sketchy (or, you know, “smells phishy”), your phish could go belly-up before it even gets a bite. That’s why I tend to think of link filters as their own separate control. Let’s talk briefly about how these link filters work and then explore some ways we might be able to bypass them.\nWhat the Filter? (WTF)\nOver the past few years, I’ve noticed a growing interest in detecting phishing based on the links themselves–or, at least, there are several very popular SEGs that place a very high weight on the presence of a link in an email. I’ve seen so much of this that I have made this type of detection one of my first troubleshooting steps when a SEG blocks me. I’ll simply remove all links from an email and check if the message content gets through.\nIn at least one case, I encountered a SEG that blocked ANY email that contained a link to ANY unrecognized domain, no matter what the wording or subject line said. In this case, I believe my client was curating a list of allowed domains and instructed the SEG to block everything else. It’s an extreme measure, but I think it is a very valid concern. Emails with links are inherently riskier than emails that do not contain links; therefore, most modern SEGs will increase the SPAM score of any message that contains a link and often will apply additional scrutiny to the links themselves.\nHow Link Filters Work — Finding the Links\nIf a SEG filters links in an email, it will first need to detect/parse each link in the content. To do this, almost any experienced software engineer will directly go to using Regular Expressions (“regex” for short):\nStand back! I know regular expressions\nTo which, any other experienced software engineer will be quick to remind us that while regex is extremely powerful, it is also easy to screw up:\n99 problems (and regex is one)\nAs an example, here are just a few of the top regex filters I found for parsing links on stackoverflow:\n(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\n(?:(?:https?|ftp|file):\\/\\/|www\\.|ftp\\.)(?:\\([-A-Z0–9+&@#\\/%=~_|$?!:,.]*\\)|[-A-Z0–9+&@#\\/%=~_|$?!:,.])*(?:\\([-A-Z0–9+&@#\\/%=~_|$?!:,.]*\\)|[A-Z0–9+&@#\\/%=~_|$])\n(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+\n([\\w+]+\\:\\/\\/)?([\\w\\d-]+\\.)*[\\w-]+[\\.\\:]\\w+([\\/\\?\\=\\&\\#\\.]?[\\w-]+)*\\/?\n(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0–9%])|www\\d{0,3}[.]|[a-z0–9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:’”.,<>?«»“”‘’]))\nDon’t worry if you don’t know what any of these mean. I consider myself to be well versed in regex and even I have no opinion on which of these options would be better than the others. However, there are a couple things I would like to note from these examples:\n\nThere is no “right” answer; URLs can be very complex\nMost (but not all) are looking for strings that start with “http” or something similar\n\nThese are also some of the most popular (think “smart people”) answers to this problem of parsing links. I could also imagine that some software engineers would take a more naive approach of searching for all anchor (“<a>”) HTML tags or looking for “href=” to indicate the start of a link. No matter which solution the software engineer chooses, there are likely going to be at least some valid URLs that their parser doesn’t catch and might leave room for a categorical bypass. We might also be able to evade parsers if we can avoid the common indicators like “http” or break up our link into multiple sections.\nSide Note: Did you see that some of these popular URL parsers account for FTP and some don’t? Did you know that most browsers can connect to FTP shares? Have you ever tried to deliver a phishing payload over an anonymous FTP link?\nHow Link Filters Work — Filtering the Links\nOnce a SEG has parsed out all the links in an email, how should it determine which ones look legitimate and which ones don’t? Most SEGs these days look at two major factors for each link:\n\nThe reputation of the domain\nHow the link “looks”\n\nChecking the domain reputation is pretty straightforward; you just split the link to see what’s between the first two forward slashes (“//”) and the next forward slash (“/”) and look up the resulting domain or subdomain on Virustotal or similar. Many SEGs will share intelligence on known bad domains with other security products and vice versa. If your domain has been flagged as malicious, the SEG will either block the email or remove the link.\nAs far as checking how the link “looks”, most SEGs these days use artificial intelligence or machine learning (i.e., AI/ML) to categorize links as malicious or benign. These AI models have been trained on a large volume of known-bad links and can detect themes and patterns commonly used by SPAM authors. As phishers, I think it’s important for us to focus on the “known-bad” part of that statement.\nI’ve seen one researcher’s talk who claimed their AI model was able to detect over 98% of malicious links from their training data. At first glance, this seems like a very impressive number; however, we need to keep in mind that in order to have a training set of malicious links in the first place, humans had to detect 100% of the training set as malicious. Therefore, the AI model was only 98% as good as a human at detecting phishing links solely on the “look” of the link. I would imagine that it would do much worse on a set of unknown-bad links, if there was a way to hypothetically attain such a set. To slip through the cracks, we should aim to put our links in that unknown-bad category.\nEven though we are up against AI models, I like to remind myself that these models can only be trained on human-curated data and therefore can only theoretically approach the competence of a human, but not surpass humans at this task. If we can make our links look convincing enough for a human, the AI should not give us any trouble.\nBypassing Link Filters\nGiven what we now know about how link filters work, we should have two main tactics available to us for bypassing the filter:\n\nFormat our link so that it slips through the link parsing phase\nMake our link “look” more legitimate\n\nIf the parser doesn’t register our link as a link, then it can’t apply any additional scrutiny to the location. If we can make our link location look like some legitimate link, then even if we can’t bypass the parser, we might get the green light anyway. Please note that these approaches are not mutually exclusive and you might have greater success mixing techniques.\nBypassing the Parser\nDon’t use an anchor tag\nOne of the most basic parser bypasses I have found for some SEGs is to simply leave the link URL in plaintext by removing the hyperlink in Outlook. Normally, link URLs are placed in the “hypertext reference” (href) attribute of an HTML anchor tag (<a>). As I mentioned earlier, one naive but surprisingly common solution for parsing links is to use an HTML parsing library like BeautifulSoup in Python. For example:\nsoup = BeautifulSoup(email.content, 'html.parser')\nlinks = soup.find_all(\"a\") # Find all elements with the tag <a>\nfor link in links:\n  print(\"Link:\", link.get(\"href\"), \"Text:\", link.string)\nAny SEG that uses this approach to parse links won’t see a URL outside of an anchor tag. While a URL that is not a clickable link might look a little odd to the end user, it’s generally worth the tradeoff when this bypass works. In many cases, mail clients will parse and display URLs as hyperlinks even if they are not in an anchor tag; therefore, there is usually little to no downside of using this technique.\nUse a Base Tag (a.k.a BaseStriker Attack)\nOne interesting method of bypassing some link filters is to use a little-known HTML tag called “base”. This tag allows you to set the base domain for any links that use relative references (i.e., links with hrefs that start with “/something” instead of direct references like “https://example.com/something”). In this case, the “https://example.com” would be considered the “base” of the URL. By defining the base using the HTML base tag in the header of the HTML content, you can then use just relative references in the body of the message. While HTML headers frequently contain URLs for things like CSS or XML schemas, the header is usually not expected to contain anything malicious and may be overlooked by a link parser. This technique is known as the “BaseStriker” attack and has been known to work against some very popular SEGs:\nhttps://www.cyberdefensemagazine.com/basestriker-attack-technique-allow-to-bypass-microsoft-office-365-anti-phishing-filter/\nThe reason why this technique works is because you essentially break your link into two pieces: the domain is in the HTML headers, and the rest of the URL is in your anchor tags in the body. Because the hrefs for the anchor tags don’t start with “https://” they aren’t detected as links.\nScheming Little Bypasses\nThe first part of a URL, before the colon and forward slashes, is what’s known as the “scheme”:\nURI = scheme \":\" [\"//\" authority] path [\"?\" query] [\"#\" fragment]\nAs mentioned earlier, some of the more robust ways to detect URLs is by looking for anything that looks like a scheme (e.g. “http://”, or “https://”), followed by a sequence of characters that would be allowed in a URL. If we simply leave off the scheme, many link parsers will not be able to detect our URL, but it will still look like a URL to a human:\naccounts.goooogle.com/login?id=34567\nA human might easily be convinced to simply copy and paste this link into their browser for us. In addition, there are quite a few legitimate schemes that could open a program on our target user’s system and potentially slip through a URL parser that is only looking for web links:\nhttps://en.wikipedia.org/wiki/List_of_URI_schemes\nThere are at least a few that could be very useful as phishing links ;)\nQR Phishing\nWhat if there isn’t a link in the email at all? What if it’s an image instead? You can use a tool like SquarePhish to automate phishing with QR codes instead of traditional links:\nGitHub - secureworks/squarephish\nI haven’t played with this yet, but have heard good things from friends that have used similar techniques. If you want to play with automating this attack yourself, NodeJS has a simple library for generating QRs:\nqrcode\nBypassing the Filter\nDon’t Mask\n(Hold on. I need to get on my soapbox…) I can’t count how many times I’ve been blocked because of a masked link only to find that unmasking the link would get the same pretext through. I think this is because spammers have thoroughly abused this feature of anchor tags in the past and average email users seldom use masked links. Link filters tend to see masked links as far more dangerous than regular links; therefore, just use a regular link. It seems like everyone these days knows how to hover a link and check its real location anyway, so masked links are even bad at tricking humans now. Don’t be cliche. Don’t use masked links.\nUse Categorized Domains\nMany link filters block or remove links to domains that are either uncategorized, categorized as malicious, or were recently registered. Therefore, it’s generally a good idea to use domains that have been parked long enough to be categorized. We’ve already touched on this in “One Phish Two Phish, Red Teams Spew Phish”, so I’ll skip the process of getting a good domain; however, just know that the same rules apply here.\nUse “Legitimate” Domains\nIf you don’t want to go through all the trouble of maintaining categorized domains for phishing links, there are some generally trustworthy domains you can leverage instead. One example I recently saw “in-the-wild” was a spammer using a sites.google.com link. They just hosted their phishing page on Google! I thought this was brilliant because I would expect most link filters to allow Google, and even most end users would think anything on google.com must be legit. Some other similar examples would be hosting your phishing sites as static pages on GitHub, in an S3 bucket, other common content delivery networks (CDNs), or on SharePoint, etc. There are tons of seemingly “legitimate” sites that allow users to host pages of arbitrary HTML content.\nArbitrary Redirects\nAlong the same lines as hosting your phishing site on a trusted domain is using trusted domains to redirect to your phishing site. One classic example of this would be link shorteners like TinyURL. While TinyURL has been abused for SPAM to the point that I would expect most SEGs to block TinyURL links, it does demonstrate the usefulness of arbitrary redirects.\nA more useful form of arbitrary redirect for bypassing link filters are URLs with either cross-site scripting (XSS) vulnerabilities that allow us to specify a ‘window.location’ change or URLs that take an HTTP GET parameter specifying where the page should redirect to. As part of my reconnaissance phase, I like to spend at least a few minutes on the main website of my target to look for these types of vulnerabilities. These vulnerabilities are surprisingly common and while an arbitrary redirect might be considered a low-risk finding on a web application penetration test report, they can be extremely useful when combined with phishing. Your links will point to a URL on your target organization’s main website. It is extremely unlikely that a link filter or even a human will see the danger. In some cases, you may find that your target organization has configured an explicit allow list in the SEG for links that point to their domains.\nLink to an Attachment\nDid you know that links in an email can also point to an email attachment? Instead of providing a URL in the href of your anchor tag, you can specify the content identifier (CID) of the attachment (e.g. href=“cid:mycontentidentifier@content.net”). One way I have used this trick to bypass link filters is to link to an HTML attachment and use obfuscated JavaScript to redirect the user to the phishing site. Because our href does not look like a URL, most SEGs will think our link is benign. You could also link to a PDF, DOCX, or several other usually allowed file types that then contain the real phishing link. This might require a little more setup in your pretext to instruct the user, or just hope that they will click the link after opening the document. In this case, I think it makes the most sense to add any additional instructions inside the document where the contents are less likely to be scrutinized by the SEG’s content filter.\nPick Up The Phone\nThis blog rounds out our “message inbound” controls that we have to bypass for social engineering pretexts. It would not be complete without mentioning one of the simplest bypasses of them all:\nNot using email!\nIf you pick up the phone and talk directly to your target, your pretext travels from your mouth, through the phone, then directly into their ear, and hits their brain without ever passing through a content or reputation filter.\nAlong the same lines, Zoom calls, Teams chats, LinkedIn messaging, and just about any other common business communication channel will likely be subject to far fewer controls than email. I’ve trained quite a few red teamers who prefer phone calls over emails because it greatly simplifies their workflow. Just a few awkward calls is usually all it takes to cede access to a target environment.\nMore interactive forms of communication, like phone calls, also allow you to gauge how the target is feeling about your pretext in real time. It’s usually obvious within seconds whether someone believes you and wants to help or if they think you’re full of it and it’s time to cut your losses, hang up the phone, and try someone else. You can also use phone calls as a way to prime a target for a follow-up email to add perceived legitimacy. Getting our message to the user is half the battle, and social engineering phone calls can be a powerful shortcut.\nIn Summary\nIf you need to bypass a link filter, either:\n\nMake your link look like it’s not a link\nMake your link look like a “legitimate” link\n\nPeople still use links in emails all the time. You just need to blend in with the “real” ones and you can trick the filter. If you are really in a pinch, just call your targets instead. It feels more personal, but it gets the job done quickly.\n\nFeeding the Phishes was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Forrest Kasler",
      "guid": "https://medium.com/p/276c3579bba7",
      "categories": [
        "phishing",
        "red-team",
        "penetration-testing",
        "cybersecurity",
        "social-engineering"
      ],
      "isoDate": "2024-06-18T13:21:36.000Z"
    },
    {
      "creator": "Jared Atkinson",
      "title": "Mapping Snowflake’s Access Landscape",
      "link": "https://posts.specterops.io/mapping-snowflakes-access-landscape-3bf232251945?source=rss----f05f8696e3cc---4",
      "pubDate": "Thu, 13 Jun 2024 16:02:36 GMT",
      "content:encoded": "<h4>Attack Path Management</h4><h4>Because Every Snowflake (Graph) is Unique</h4><h3>Introduction</h3><p>On June 2nd, 2024, Snowflake released a <a href=\"https://community.snowflake.com/s/question/0D5VI00000Emyl00AB/detecting-and-preventing-unauthorized-user-access\">joint statement</a> with Crowdstrike and Mandiant addressing reports of “[an] ongoing investigation involving a targeted threat campaign against some Snowflake customer accounts.” A SpecterOps customer contacted me about their organization’s response to this campaign and mentioned that there seems to be very little security-based information related to Snowflake. In their initial statement, Snowflake recommended the following steps for organizations that may be affected (or that want to avoid being affected, for that matter!):</p><ol><li>Enforce Multi-Factor Authentication on all accounts;</li><li>Set up Network Policy Rules to only allow authorized users or only allow traffic from trusted locations (VPN, Cloud workload NAT, etc.); and</li><li>Impacted organizations should reset and rotate Snowflake credentials.</li></ol><p>While these recommendations are a good first step, I wondered if there was anything else we could do once we better grasped Snowflake’s Access Control Model (and its associated Attack Paths) and better understood the details of the attacker’s activity on the compromised accounts. In this post, I will describe the high-level Snowflake Access Control Model, analyze the incident reporting released by Mandiant, and provide instructions on graphing the “access model” of your Snowflake deployment.</p><p>These recommendations address how organizations might address initial access to their Snowflake instance. However, I was curious about “post-exploitation” in a Snowflake environment. After a quick Google search, I realized there is very little threat research on Snowflake. My next thought was to check out Snowflake’s access control model to better understand the access landscape. I hoped that if I could understand how users are granted access to resources in a Snowflake account, I could start to understand what attackers might do once they are authenticated. I also thought we could analyze the existing attack paths to make recommendations to reduce the blast radius of a breach of the type Crowdstrike and Mandiant reported.</p><p>While we have not yet integrated Snowflake into BloodHound Community Edition (BHCE) or Enterprise (BHE), we believe there is value in taking a graph-centric approach to analyzing your deployment, as it can help you understand the impact of a campaign similar to the one described in the intro to this post.</p><h3>Snowflake Access Control Model</h3><p>My first step was to search for any documentation on Snowflake’s access control model. I was pleased to find a <a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-overview\">page</a> providing a relatively comprehensive and simple-to-understand model description. They describe their model as a mix of Discretionary Access Control, where “each object has an owner, who can in turn grant access to that object,” and Role-based Access Control, where “privileges are assigned to roles, which are in turn assigned to users.” These relationships are shown in the image below:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*a1Bqio7G_gqN7gkC.png\" /><figcaption><a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-overview#access-control-framework\">https://docs.snowflake.com/en/user-guide/security-access-control-overview#access-control-framework</a></figcaption></figure><p>Notice that Role 1 “owns” Objects 1 and 2. Then, notice that two different privileges are granted from Object 1 to Role 2 and that Role 2 is granted to Users 1 and 2. Also, notice that Roles can be granted to other Roles, which means there is a nested hierarchy similar to groups in Active Directory. One thing that I found helpful was to flip the relationship of some of these “edges.” In this graphic, they are pointing toward the grant, but the direction of access is the opposite. Imagine that you are User 1, and you are granted Role 2, which has two Privileges on Object 1. Therefore, you have two Privileges on Object 1 through transitivity.</p><p>We have a general idea of how privileges on objects are granted, but what types of objects does Snowflake implement? They provide a graphic to show the relationship between these objects, which they describe as “hierarchical.”</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*fdaoqBsg9ybP8dry.png\" /><figcaption><a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-overview#securable-objects\">https://docs.snowflake.com/en/user-guide/security-access-control-overview#securable-objects</a></figcaption></figure><p>Notice that at the top of the hierarchy, there is an organization. Each organization can have one or many accounts. For example, the trial I created to do this research has only one Account, but the client that contacted me has ~10. The Account is generally considered to be the nexus of everything. It is helpful to think of an Account as the equivalent of an Active Directory Domain. Within the Account are Users, Roles (Groups), Databases, Warehouses (virtual compute resources), and many other objects, such as Security Integrations. Within the Database context is a Schema, and within the Schema context are Tables, Views, Stages (temporary stores for loading/unloading data), etc.</p><p>As I began understanding the implications of each object and the types of privileges each affords, I started to build a model showing their possible relationships. In doing so, I found it helpful to start at the top of the hierarchy (the account) and work my way down with respect to integrating entity types into the model. This is useful because access to entities often depends on access to their parent. For example, a user can only interact with a schema if the user also has access to the schema’s parent database. This allows us to abstract away details and make educated inferences about lower-level access. Below, I will describe the primary objects that I consider in my model.</p><h4>Account (think Domain)</h4><p>The account is the equivalent to the domain. All objects exist within the context of the account. When you log into Snowflake, you log in as a user within a specific account. Most administrative privileges are privileges to operate on the account, such as CREATE USER, MANAGE GRANTS, CREATE ROLE, CREATE DATABASE, EXECUTE TASK, etc.</p><h4>Users (precisely what you think they are)</h4><p>Users are your identity in the Snowflake ecosystem. When you log into the system, you do so as a particular user, and you have access to resources based on your granted roles and the role’s granted privileges.</p><h4>Roles (think Groups)</h4><p>Roles are the primary object to which privileges are assigned. Users can be granted “USAGE” of a role, similar to being added as group members. Roles can also be granted to other roles, which creates a nested structure that facilitates granular control of privileges. There are ~ five default admin accounts. The first is ACCOUNTADMIN, which is the Snowflake equivalent of Domain Admin. The remaining four are ORGADMIN, SYSADMIN, SECURITYADMIN, and USERADMIN.</p><h4><a href=\"https://docs.snowflake.com/en/user-guide/warehouses\">Warehouses</a></h4><p>A Warehouse is “a cluster of computer resources… such as CPU, memory, and temporary storage” used to perform database-related operations in a Snowflake session. Operations such as retrieving rows from tables, updating rows in tables, and loading/unloading data from tables all require a warehouse.</p><h4><a href=\"https://docs.snowflake.com/en/guides-overview-db\">Databases</a></h4><p>A database is defined as “a logical grouping of schemas.” It is the container for information that we would expect attackers to target. While the database object itself does not contain any data, a user must have access to the database to access its subordinate objects (Schemas, Tables, etc.).</p><h4><a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-privileges\">Privileges</a> (think Access Rights)</h4><p>Privileges define who can perform which operation on which resources. In our context, privileges are primarily assigned to roles. Snowflake supports many privileges, some of which apply in a global or account context (e.g., CREATE USER), while others are specific to an object type (e.g., CREATE SCHEMA on a Database). Users accumulate privileges through the Roles that they have been granted recursively.</p><h3>Access Graph</h3><p>With this basic understanding of Snowflake’s access control model, we can create a graph model that describes the relationships between entities via privileges. For instance, we know that a user can be granted the USAGE privilege of a role. This is the equivalent of an Active Directory user being a MemberOf a group. Additionally, we find that a role can be granted USAGE of another role, similar to group nesting in AD. Eventually, we can produce this relatively complete initial model for the Snowflake “access graph.”</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*AH0A81FV1Mu-kgOdGOXnpQ.png\" /></figure><p>This model can help us better understand what likely happened during the incident. It can also help us better understand the access landscape of our Snowflake deployment, which can help us reduce the blast radius should an attacker gain access.</p><h3>About the Incident</h3><p>As more details have emerged, it has become clear that this campaign targeted customer credentials rather than Snowflake’s production environment. Later, on June 10th, Mandiant released a more <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/unc5537-snowflake-data-theft-extortion\">detailed report</a> describing some of the threat group’s activity discovered during the investigation.</p><p>Mandiant describes a typical scenario where threat actors compromise the computers of contractors that companies hire to build, manage, or administer their Snowflake deployment. In many cases, these contractors already have administrative privileges, so any compromise of their credentials can lead to detrimental effects. The existing administrative privileges indicate that the threat actor had no need to escalate privilege via an attack path or compromise alternative identities during this activity.</p><p>Mandiant describes the types of activity the attackers were observed to have implemented. They appear interested in enumerating database tables to find interesting information for exfiltration. An important observation is that, based on the reported activity, the compromised user seems to have admin or admin-adjacent privileges on the Snowflake account.</p><p>In this section, we will talk about each of these commands, what they do and how we can understand them in the context of our graph.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/891/1*vKj3fRQVcMeCN_uGxPMZUQ.png\" /></figure><p>As Mandiant describes, the first command is a Discovery command meant to list all the tables available. According to the documentation, a user requires at least the USAGE privilege on the Schema object that contains the table to execute this command directly. It is common for a production Snowflake deployment to have many databases, each with many schemas, so access to tables will likely be limited to most non-admins. We can validate this in the graph, though!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/875/1*XTaPRxRiqJRViZQEEi5CgA.png\" /><figcaption><a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-privileges#schema-privileges\">https://docs.snowflake.com/en/user-guide/security-access-control-privileges#schema-privileges</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/891/1*cxFBfrBEQs0BHuSjxpBCrg.png\" /></figure><p>Next, we see that they run the SELECT command. This indicates that they must have found one or more tables from the previous command that interested them. This command works similarly to the SQL query and returns the rows in the table. In this case, they are dumping the entire table. The <a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-privileges#table-privileges\">privilege documentation</a> states that a user must have the SELECT privilege on the specified table (&lt;Target Table&gt;) to execute this command. Additionally, the user must have the USAGE privilege on the parent database (&lt;Target Database&gt;) and schema (&lt;Target Schema&gt;).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/875/1*C4syLY3dCtgN2M9-k9-7aQ.png\" /><figcaption><a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-privileges#table-privileges\">https://docs.snowflake.com/en/user-guide/security-access-control-privileges#table-privileges</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/891/1*sATNTUCLZqi0Vf3I5M5xvw.png\" /></figure><p>Like tables, stages exist within the schema context; thus, the requisite privilege, CREATE STAGE, exists at the schema level (aka &lt;Redacted Schema&gt;). The user would also require the USAGE privilege on the database (&lt;Redacted Database&gt;). Therefore, a user can have the ability to create a stage for one schema but not another. In general, this is a privilege that can be granted to a limited set of individuals, especially when it comes to sensitive databases/schemas.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/875/1*L4b_ByXCpWOuwUDaSjmTXA.png\" /><figcaption><a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-privileges#schema-privileges\">https://docs.snowflake.com/en/user-guide/security-access-control-privileges#schema-privileges</a></figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/891/1*VHGkaCKW6tonR9RRGcQsQA.png\" /></figure><p>Finally, the attackers call the <a href=\"https://docs.snowflake.com/en/sql-reference/sql/copy-into-location\">COPY INTO</a> command, which is a way to extract data from the Snowflake database. Obviously, Mandiant redacted the path, but one possible example would be to use the temporary stage to copy the data to an Amazon S3 bucket. In this case, the attacker uses the COPY INTO &lt;location&gt; variant, which requires the WRITE privilege. Of course, the attacker created the stage resource in the previous command, so they would likely have OWNERSHIP of the stage, granting them full control of the object.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/875/1*O1aIFaOXdhHqH1KSfxrm1A.png\" /><figcaption><a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-privileges#stage-privileges\">https://docs.snowflake.com/en/user-guide/security-access-control-privileges#stage-privileges</a></figcaption></figure><h3>Build Your Own Graph</h3><p>At this point, some of you might be interested in checking out your Snowflake Access Graph. This section walks through how to gather the necessary Snowflake data, stand up Neo4j, and build the graph. It also provides some sample Cypher queries relevant to Snowflake’s recommendations.</p><h4>Collecting Data</h4><p>The first step is to collect the graph-relevant data from Snowflake. The cool thing is that this is actually a relatively simple process. I’ve found that Snowflake’s default web client, <a href=\"https://docs.snowflake.com/en/user-guide/ui-snowsight\">Snowsight</a>, does a fine job gathering this information. You can navigate to Snowsight once you’ve logged in by clicking on the Query data button at the top of the Home page.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*3b2gyNqj_hlRQJeRJapObg.png\" /></figure><p>Once there, you will have the opportunity to execute commands. This section will describe the commands that collect the data necessary to build the graph. My parsing script is built for CSV files that follow a specific naming convention. Once your command has returned results, click the download button (downward pointing arrow) and select the “Download as .csv” option.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*GlqGXc3YbEykkLtyl49RPQ.png\" /></figure><p>The model supports Accounts, Applications, Databases, Roles, Users, and Warehouses. This means we will have to query those entities, which will serve as the nodes in our graph. This will download the file with a name related to your account. My parsing script expects the output of certain commands to be named in a specific way. The expected name will be shared in the corresponding sections below.</p><p>I’ve found that I can query Applications, Databases, Roles, and Users as an unprivileged user. However, this is different for Accounts, which require ORGADMIN, and Warehouses, which require instance-specific access (e.g., <a href=\"https://docs.snowflake.com/en/user-guide/warehouses-tasks#delegating-warehouse-management\">ACCOUNTADMIN</a>).</p><p><strong>Applications</strong></p><ul><li>Command: <a href=\"https://docs.snowflake.com/en/sql-reference/sql/show-applications\">SHOW APPLICATIONS;</a></li><li>File Name: application.csv</li></ul><p><strong>Databases</strong></p><ul><li>Command: <a href=\"https://docs.snowflake.com/en/sql-reference/sql/show-databases\">SHOW DATABASES;</a></li><li>File Name: database.csv</li></ul><p><strong>Integrations</strong></p><ul><li>Command: <a href=\"https://docs.snowflake.com/en/sql-reference/sql/show-integrations\">SHOW INTEGRATIONS;</a></li><li>File Name: integration.csv</li></ul><p><strong>Roles</strong></p><ul><li>Command: <a href=\"https://docs.snowflake.com/en/sql-reference/sql/show-roles\">SHOW ROLES;</a></li><li>File Name: role.csv</li></ul><p><strong>Users</strong></p><ul><li>Command: <a href=\"https://docs.snowflake.com/en/sql-reference/sql/show-users\">SHOW USERS;</a></li><li>File Name: user.csv</li></ul><p><strong>Warehouses</strong></p><ul><li>Command: <a href=\"https://docs.snowflake.com/en/sql-reference/sql/show-warehouses\">SHOW WAREHOUSES;</a></li><li>File Name: warehouse.csv</li></ul><blockquote><strong>Note: </strong>As mentioned above, users can only enumerate warehouses for which they have been granted privileges. One way to grant a non-ACCOUNTADMIN user visibility of all warehouses is to grant the <a href=\"https://docs.snowflake.com/en/user-guide/warehouses-tasks#delegating-warehouse-management\">MANAGE WAREHOUSES</a>privilege.</blockquote><p><strong>Accounts</strong></p><p>At this point, we have almost all the entity data we need. We have one final query that will allow us to gather details about our Snowflake account. This query can only be done by the ORGADMIN role. Assuming your user has been granted ORGADMIN, go to the top right corner of the browser and click on your current role. This will result in a drop-down that displays all of the roles that are effectively granted to your user. Here, you will select ORGADMIN, allowing you to run commands in the context of the ORGADMIN role.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*HMIaPansBD6jEY2M-1tMXA.png\" /></figure><p>Once complete, run the following command to list the account details.</p><ul><li>Command: <a href=\"https://docs.snowflake.com/en/sql-reference/sql/show-accounts\">SHOW ACCOUNTS;</a></li><li>File Name: account.csv</li></ul><p><strong>Grants</strong></p><p>Finally, we must gather information on privilege grants. These are maintained in the ACCOUNT_USAGE schema of the default SNOWFLAKE database. By default, these views are only available to the ACCOUNTADMIN role. Still, users not granted USAGE of the ACCOUNTADMIN role can be granted the necessary read access via the <a href=\"https://docs.snowflake.com/en/sql-reference/account-usage#account-usage-views-by-database-role\">SECURITY_VIEWER</a> database role. The following command does this (if run as ACCOUNTADMIN):</p><pre>GRANT DATABASE ROLE snowflake.SECURITY_VIEWER TO &lt;Role&gt;</pre><p>Once you have the necessary privilege, you can query the relevant views and export them to a CSV file. The first view is <a href=\"https://docs.snowflake.com/en/sql-reference/account-usage/grants_to_users\">grants_to_users</a>, which maintains a list of which roles have been granted to which users. You can enumerate this list using the following command. Then save it to a CSV file and rename it grants_to_users.csv.</p><pre>SELECT * FROM snowflake.account_usage.grants_to_users;</pre><p>The final view is <a href=\"https://docs.snowflake.com/en/sql-reference/account-usage/grants_to_roles\">grants_to_roles</a>, which maintains a list of all the privileges granted to roles. This glue ultimately allows users to interact with the different Snowflake entities. This view can be enumerated using the following command. The results should be saved as a CSV file named grants_to_roles.csv.</p><pre>SELECT * FROM snowflake.account_usage.grants_to_roles WHERE GRANTED_ON IN (&#39;ACCOUNT&#39;, &#39;APPLICATION&#39;, &#39;DATABASE&#39;, &#39;INTEGRATION&#39;, &#39;ROLE&#39;, &#39;USER&#39;, &#39;WAREHOUSE&#39;); </pre><h4>Setting up Neo4j</h4><p>At this point, we have a Cypher statement that we can use to generate the Snowflake graph, but before we can do that, we need a Neo4j instance. The easiest way that I know of to do this is to use the <a href=\"https://github.com/SpecterOps/BloodHound?tab=readme-ov-file#running-bloodhound-community-edition\">BloodHound Community Edition docker-compose deployment option</a>.</p><blockquote><strong>Note: </strong>While we won’t use BHCE specifically in this demo, the overarching docker-compose setup includes a Neo4j instance configured to support this example.</blockquote><p>To do this, you must first install Docker on your machine. Once complete, download this example <a href=\"https://gist.github.com/jaredcatkinson/b9e6b12c989daea290e49be6410b89b5\">docker-compose yaml file</a> I derived from the <a href=\"https://github.com/SpecterOps/BloodHound\">BHCE GitHub repository</a>. Next, open docker-compose.yaml in a text editor and edit <a href=\"https://gist.github.com/jaredcatkinson/5a843a5ccf7af14e0e9178ec0188eaf3#file-docker-compose-yaml-L51\">Line 51</a> to point to the folder on your host machine (e.g., /Users/jared/snowflake:/var/lib/neo4j/import/) where you wrote the Snowflake data files (e.g., grants_to_roles.csv). This will create a <a href=\"https://docs.docker.com/storage/bind-mounts/\">bind mount</a> between your host and the container. You are now ready to start the container by executing the following command:</p><pre>docker-compose -f /path/to/docker-composer.yaml up -d</pre><p>This will cause Docker to download and run the relevant Docker containers. For this Snowflake graph, we will interact directly with Neo4j as this model has not been integrated into BloodHound. You can access the Neo4j web interface by browsing to <a href=\"https://github.com/SpecterOps/BloodHound/blob/main/examples/docker-compose/docker-compose.yml#L48\">127.0.0.1:7474</a> and logging in using the default credentials (<a href=\"https://github.com/SpecterOps/BloodHound/blob/main/examples/docker-compose/docker-compose.yml#L68\">neo4j:bloodhoundcommunityedition</a>).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*1usNvpVh6iUDBgPOycJ-sQ.png\" /></figure><h4>Data Ingest</h4><p>Once you’ve authenticated to Neo4j, it is time for data ingest. I originally wrote a PowerShell script that would parse the CSV files and handcraft Cypher queries to create the corresponding nodes and edges, but <a href=\"https://medium.com/u/6a4f60e8881f\">SadProcessor</a> showed me a better way to approach ingestion. He suggested using the <a href=\"https://neo4j.com/docs/cypher-manual/current/clauses/load-csv/\">LOAD CSV</a> clause. According to Neo4j, “LOAD CSV is used to import data from CSV files into a Neo4j database.” This dramatically simplifies ingesting your Snowflake data AND is much more efficient than my initial PowerShell script. This section describes the Cypher queries that I use to import Snowflake data. Before you begin, knowing that each command must be run individually is essential. Additionally, these commands assume that you’ve named your files as suggested. Therefore, the file listing of the folder you specified in the Docker Volume (e.g., /Users/jared/snowflake) should look this:</p><pre>-rwx------@ 1 cobbler  staff    677 Jun 12 20:17 account.csv<br>-rwx------@ 1 cobbler  staff    227 Jun 12 20:17 application.csv<br>-rwx------@ 1 cobbler  staff    409 Jun 12 20:17 database.csv<br>-rwx------@ 1 cobbler  staff   8362 Jun 12 20:17 grants_to_roles.csv<br>-rwx------@ 1 cobbler  staff    344 Jun 12 20:17 grants_to_users.csv<br>-rwx------@ 1 cobbler  staff    114 Jun 12 20:17 integration.csv<br>-rwx------@ 1 cobbler  staff    895 Jun 12 20:17 role.csv<br>-rwx------@ 1 cobbler  staff  12350 Jun 12 20:17 table.csv<br>-rwx------@ 1 cobbler  staff    917 Jun 12 20:17 user.csv<br>-rwx------@ 1 cobbler  staff    436 Jun 12 20:17 warehouse.csv</pre><blockquote><strong>Note: </strong>If you don’t have a Snowflake environment, but still want to check out the graph, you can use my sample data set by replacing file:/// with https://gist.githubusercontent.com/jaredcatkinson/c5e560f7d3d0003d6e446da534a89e79/raw/c9288f20e606d236e3775b11ac60a29875b72dbc/ in each query.</blockquote><p><strong>Ingest Accounts</strong></p><pre>LOAD CSV WITH HEADERS FROM &#39;file:///account.csv&#39; AS line<br>CREATE (:Account {name: line.account_locator, created_on: line.created_on, organization_name: line.organization_name, account_name: line.account_name, snowflake_region: line.snowflake_region, account_url: line.account_url, account_locator: line.account_locator, account_locator_url: line.account_locator_url})</pre><p><strong>Ingest Applications</strong></p><pre>LOAD CSV WITH HEADERS FROM &#39;file:///application.csv&#39; AS line<br>CREATE (:Application {name: line.name, created_on: line.created_on, source_type: line.source_type, source: line.source})</pre><p><strong>Ingest Databases</strong></p><pre>LOAD CSV WITH HEADERS FROM &#39;file:///database.csv&#39; AS line<br>CREATE (:Database {name: line.name, created_on: line.created_on, retention_time: line.retention_time, kind: line.kind})</pre><p><strong>Ingest Integrations</strong></p><pre>LOAD CSV WITH HEADERS FROM &#39;file:///integration.csv&#39; AS line<br>CREATE (:Integration {name: line.name, created_on: line.created_on, type: line.type, category: line.category, enabled: line.enabled})</pre><p><strong>Ingest Roles</strong></p><pre>LOAD CSV WITH HEADERS FROM &#39;file:///role.csv&#39; AS line<br>CREATE (:Role {name: line.name, created_on: line.created_on, assigned_to_users: line.assigned_to_users, granted_to_roles: line.granted_to_roles})</pre><p><strong>Ingest Users</strong></p><pre>LOAD CSV WITH HEADERS FROM &#39;file:///user.csv&#39; AS line<br>CREATE (:User {name: line.name, created_on: line.created_on, login_name: line.login_name, first_name: line.first_name, last_name: line.last_name, email: line.email, disabled: line.disabled, ext_authn_duo: line.ext_authn_duo, last_success_login: line.last_success_login, has_password: line.has_password, has_rsa_public_key: line.has_rsa_public_key})</pre><p><strong>Ingest Warehouses</strong></p><pre>LOAD CSV WITH HEADERS FROM &#39;file:///warehouse.csv&#39; AS line<br>CREATE (:Warehouse {name: line.name, created_on: line.created_on, state: line.state, size: line.size})</pre><p><strong>Ingest Grants to Users</strong></p><pre>LOAD CSV WITH HEADERS FROM &#39;file:///grants_to_users.csv&#39; AS usergrant<br>CALL {<br>    WITH usergrant<br>    MATCH (u:User) WHERE u.name = usergrant.GRANTEE_NAME<br>    MATCH (r:Role) WHERE r.name = usergrant.ROLE<br>    MERGE (u)-[:USAGE]-&gt;(r)<br>}</pre><p><strong>Ingest Grants to Roles</strong></p><pre>:auto LOAD CSV WITH HEADERS FROM &#39;file:///grants_to_roles.csv&#39; AS grant<br>CALL {<br>    WITH grant<br>    MATCH (src) WHERE grant.GRANTED_TO = toUpper(labels(src)[0]) AND src.name = grant.GRANTEE_NAME<br>    MATCH (dst) WHERE grant.GRANTED_ON = toUpper(labels(dst)[0]) AND dst.name = grant.NAME<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;USAGE&#39; THEN [1] ELSE [] END | MERGE (src)-[:USAGE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;OWNERSHIP&#39; THEN [1] ELSE [] END | MERGE (src)-[:OWNERSHIP]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLYBUDGET&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLYBUDGET]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;AUDIT&#39; THEN [1] ELSE [] END | MERGE (src)-[:AUDIT]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;MODIFY&#39; THEN [1] ELSE [] END | MERGE (src)-[:MODIFY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;MONITOR&#39; THEN [1] ELSE [] END | MERGE (src)-[:MONITOR]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;OPERATE&#39; THEN [1] ELSE [] END | MERGE (src)-[:OPERATE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLY AGGREGATION POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLY_AGGREGATION_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLY AUTHENTICATION POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLY_AUTHENTICATION_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLY MASKING POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLY_MASKING_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLY PACKAGES POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLY_PACKAGES_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLY PASSWORD POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLY_PASSWORD_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLY PROTECTION POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLY_PROTECTION_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLY ROW ACCESS POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLY_ROW_ACCESS_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;APPLY SESSION POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:APPLY_SESSION_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;ATTACH POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:ATTACH_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;BIND SERVICE ENDPOINT&#39; THEN [1] ELSE [] END | MERGE (src)-[:BIND_SERVICE_ENDPOINT]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CANCEL QUERY&#39; THEN [1] ELSE [] END | MERGE (src)-[:CANCEL_QUERY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE ACCOUNT&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_ACCOUNT]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE API INTEGRATION&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_API_INTEGRATION]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE APPLICATION&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_APPLICATION]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE APPLICATION PACKAGE&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_APPLICATION_PACKAGE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE COMPUTE POOL&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_COMPUTE_POOL]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE CREDENTIAL&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_CREDENTIAL]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE DATA EXCHANGE LISTING&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_DATA_EXCHANGE_LISTING]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE DATABASE&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_DATABASE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE DATABASE ROLE&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_DATABASE_ROLE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE EXTERNAL VOLUME&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_EXTERNAL_VOLUME]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE INTEGRATION&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_INTEGRATION]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE NETWORK POLICY&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_NETWORK_POLICY]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE REPLICATION GROUP&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_REPLICATION_GROUP]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE ROLE&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_ROLE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE SCHEMA&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_SCHEMA]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE SHARE&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_SHARE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE USER&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_USER]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;CREATE WAREHOUSE&#39; THEN [1] ELSE [] END | MERGE (src)-[:CREATE_WAREHOUSE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;EXECUTE DATA METRIC FUNCTION&#39; THEN [1] ELSE [] END | MERGE (src)-[:EXECUTE_DATA_METRIC_FUNCTION]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;EXECUTE MANAGED ALERT&#39; THEN [1] ELSE [] END | MERGE (src)-[:EXECUTE_MANAGED_ALERT]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;EXECUTE MANAGED TASK&#39; THEN [1] ELSE [] END | MERGE (src)-[:EXECUTE_MANAGED_TASK]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;EXECUTE TASK&#39; THEN [1] ELSE [] END | MERGE (src)-[:EXECUTE_TASK]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;IMPORT SHARE&#39; THEN [1] ELSE [] END | MERGE (src)-[:IMPORT_SHARE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;MANAGE GRANTS&#39; THEN [1] ELSE [] END | MERGE (src)-[:MANAGE_GRANTS]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;MANAGE WAREHOUSES&#39; THEN [1] ELSE [] END | MERGE (src)-[:MANAGE_WAREHOUSES]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;MANAGEMENT SHARING&#39; THEN [1] ELSE [] END | MERGE (src)-[:MANAGEMENT_SHARING]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;MONITOR EXECUTION&#39; THEN [1] ELSE [] END | MERGE (src)-[:MONITOR_EXECUTION]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;OVERRIDE SHARE RESTRICTIONS&#39; THEN [1] ELSE [] END | MERGE (src)-[:OVERRIDE_SHARE_RESTRICTIONS]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;PURCHASE DATA EXCHANGE LISTING&#39; THEN [1] ELSE [] END | MERGE (src)-[:PURCHASE_DATA_EXCHANGE_LISTING]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;REFERENCE USAGE&#39; THEN [1] ELSE [] END | MERGE (src)-[:REFERENCE_USAGE]-&gt;(dst))<br>    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = &#39;USE ANY ROLE&#39; THEN [1] ELSE [] END | MERGE (src)-[:USE_ANY_ROLE]-&gt;(dst))<br>} IN TRANSACTIONS</pre><p>Once you finish executing these commands you can validate that the data is in the graph by running a query. The query below returns any entity with a path to the Snowflake account.</p><pre>MATCH p=()-[*1..]-&gt;(a:Account)<br>RETURN p</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*XwbRS6esnC3Zo93c5nS1GQ.png\" /></figure><p>This is a common way to find admin users. While Snowflake has a few default admin Roles, such as ACCOUNTADMIN, ORGADMIN, SECURITYADMIN, SYSADMIN, and USERADMIN, granting administrative privileges to custom roles is possible.</p><h4>Queries</h4><p>Having a graph is great! However, the value is all about the questions you can ask. I’ve only been playing around with this Snowflake graph for a few days. Still, I created a few queries that will hopefully help you gather context around the activity reported in Mandiant’s report and your compliance with Snowflake’s recommendations.</p><p><strong>Admins without MFA</strong></p><p>Snowflake’s primary recommendation to reduce your exposure to this campaign and others like it is to enable MFA on all accounts. While achieving 100% coverage on all accounts may take some time, they also recommend enabling MFA on users who have been granted the ACCOUNTADMIN Role. Based on my reading of the reporting, the attackers likely compromised the credentials of admin users, so it seems reasonable to start with these highly privileged accounts first.</p><p>There are two approaches to determining which users have admin privileges. The first is to assume that admins will be granted one of the default admins roles, as shown below:</p><pre>MATCH p=((n:User WHERE n.ext_authn_duo = &quot;false&quot;)-[:USAGE*1..]-&gt;(r:Role WHERE r.name CONTAINS &quot;ADMIN&quot;))<br>RETURN p</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*4sGQTvq9kznG_SEmP4nM_A.png\" /></figure><p>Here, we see seven users who have been granted USAGE of a role with the string “ADMIN” in its name. While this is a good start, the string “ADMIN” does not necessarily mean that the role has administrative privileges, and its absence does not mean that the role does not have administrative privileges. Instead, I recommend searching for admins based on their effective privileges.</p><p>This second query considers that admin privileges can be granted to custom roles. For example, the MANAGE_GRANTS privilege, shown below, “grants the ability to grant or revoke privileges on any object as if the invoking role were the owner of the object.” This means that if a user has this privilege, they can grant themselves or anyone access to any object they want.</p><pre>MATCH p=((n:User WHERE n.ext_authn_duo = &quot;false&quot;)-[:USAGE*1..]-&gt;(r:Role)-[:MANAGE_GRANTS]-&gt;(a:Account))<br>RETURN p</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*oAlQYHzAxEKXXD2VCj7fyw.png\" /></figure><p>Here, we see five users not registered for MFA who have MANAGE_GRANTS over the Snowflake Account. Two users are granted USAGE of the ACCOUNTADMINS role, and the other three are granted USAGE of a custom role. Both ACCOUNTADMINS and the custom role are granted USAGE of the SECURITYADMINS role, which is granted MANAGE_GRANTS on the account.</p><p>Restated in familiar terms, two users are members of the ACCOUNTADMINS group, which is nested inside the SECURITYADMINS group, which has SetDACL right on the Domain Head.</p><p><strong>User Access to a Database</strong></p><p>According to Mandiant, most of the attacker’s actions focused on data contained within database tables. While my graph does not currently support schema or table entities, it is important to point out that the <a href=\"https://docs.snowflake.com/en/user-guide/security-access-control-privileges#table-privileges\">documentation</a> states that “operating on a table also requires the USAGE privilege on the parent database and schema.” This means that we can use the graph to understand which users have access to which database and then infer that they likely have access to the schema and tables within the database.</p><pre>MATCH p=((u:User)-[:USAGE*1..]-&gt;(r:Role)-[:OWNERSHIP]-&gt;(d:Database WHERE d.name = &quot;&lt;DATABASE NAME GOES HERE&gt;&quot;))<br>RETURN p</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*vYsskeEmhwLKnuhsQI5zww.png\" /></figure><p>Here, the Jared and SNOWFLAKE users have OWNERSHIP of the SNOWFLAKE_SAMPLE_DATA database via the ACCOUNTADMIN role.</p><p>This query shows all users that have access to a specified databases. If you would like to check access to all databases you can run this query:</p><pre>MATCH p=((u:User)-[:USAGE*1..]-&gt;(r:Role)-[]-&gt;(d:Database))<br>RETURN p</pre><p><strong>Stale User Accounts</strong></p><p>Another simple example is identifying users that have never been used (logged in to). Pruning unused users might reduce the overall attack surface area.</p><pre>MATCH (n:User WHERE n.last_success_login = &quot;&quot;)<br>RETURN n</pre><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*eePq6ah-VBUq5tjiV-aenA.png\" /></figure><h3>Conclusion</h3><p>I hope you found this overview and will find this graph capability useful. I’m looking forward to your feedback regarding the graph! If you write a useful query, please share it, and I will put it in the post with credit. Additionally, if you think of extending the graph, please let me know, and I’ll do my best to facilitate it.</p><p>Before I go, I want to comment on Snowflake’s recommendations in the aftermath of this campaign. As I mentioned, Snowflake’s primary recommendation is to enable MFA on all accounts. It is worth mentioning, in their defense, that <a href=\"https://docs.snowflake.com/en/user-guide/security-mfa\">Snowflake has always (at least since before this incident) recommended</a> that MFA be enabled on any user granted the ACCOUNTADMIN role (the equivalent of Domain Admin).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/877/1*AaQoJBEd6c6sDuEXpIsc_A.png\" /></figure><p>That being said, the nature of web-based platforms means that if an attacker compromises a system with a Snowflake session, they likely can steal the session token and reuse it even if the user has MFA enabled. Austin Baker, who goes by <a href=\"https://twitter.com/BakedSec\">@BakedSec</a> on Twitter, pointed this out.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/597/1*-Sp24FOUUvB82mwUoFCeLw.png\" /></figure><p>This indicates that we must look beyond how we stop attackers from getting access. We must understand the access landscape within our information systems. Ask yourself, “Can you answer which users can use the DATASCIENCE Database in your Snowflake deployment?” With this graph, that question is trivial to answer, but without one, we find that most organizations cannot answer these questions accurately. When nested groups (roles in this case) are involved, it is very easy for there to be a divergence between intended access and effective access. This only gets worse over time. I think of it as entropy.</p><p>We must use a similar approach for cloud accounts as on-prem administration. You don’t browse the web with your Domain Administrator account. No, you have two accounts, one for administration and one for day-to-day usage. You might even have a <a href=\"https://learn.microsoft.com/en-us/security/privileged-access-workstations/privileged-access-devices\">system that is dedicated to administrative tasks</a>. These same ideas should apply to cloud solutions like Snowflake. Are you analyzing the data in a table? Great, use your Database Reader account. Now you need to grant Luke a role so he can access a warehouse? Okay, hop on your Privileged Access Workstation and use your SECURITYADMIN account. The same Tier 0 concept applies in this context. I look forward to hearing your feedback!</p><p>UPDATE: Luke Jennings from <a href=\"https://pushsecurity.com/\">Push Security</a> added a new technique to the <a href=\"https://github.com/pushsecurity/saas-attacks\">SaaS Attack Matrix</a> called <a href=\"https://github.com/pushsecurity/saas-attacks/blob/main/techniques/session_cookie_theft/description.md\">Session Cookie Theft</a>. This technique shows one way that attackers, specifically if they have access to the SaaS user’s workstation, can steal relevant browser cookies in order to bypass MFA. This does not mean that organizations should not strive to enable MFA on their users, especially admin accounts, however it does demonstrate the importance of reducing attack paths within the SaaS application’s access control model. One way to think of it is that MFA is meant to make it more difficult for attackers to get in, but once they’re in it is all about Attack Paths. The graph approach I demonstrate in this post is the first step to getting a handle of these Attack Paths to reduce the blast radius of a compromise.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3bf232251945\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/mapping-snowflakes-access-landscape-3bf232251945\">Mapping Snowflake’s Access Landscape</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "Attack Path Management\nBecause Every Snowflake (Graph) is Unique\nIntroduction\nOn June 2nd, 2024, Snowflake released a joint statement with Crowdstrike and Mandiant addressing reports of “[an] ongoing investigation involving a targeted threat campaign against some Snowflake customer accounts.” A SpecterOps customer contacted me about their organization’s response to this campaign and mentioned that there seems to be very little security-based information related to Snowflake. In their initial statement, Snowflake recommended the following steps for organizations that may be affected (or that want to avoid being affected, for that matter!):\n\nEnforce Multi-Factor Authentication on all accounts;\nSet up Network Policy Rules to only allow authorized users or only allow traffic from trusted locations (VPN, Cloud workload NAT, etc.); and\nImpacted organizations should reset and rotate Snowflake credentials.\n\nWhile these recommendations are a good first step, I wondered if there was anything else we could do once we better grasped Snowflake’s Access Control Model (and its associated Attack Paths) and better understood the details of the attacker’s activity on the compromised accounts. In this post, I will describe the high-level Snowflake Access Control Model, analyze the incident reporting released by Mandiant, and provide instructions on graphing the “access model” of your Snowflake deployment.\nThese recommendations address how organizations might address initial access to their Snowflake instance. However, I was curious about “post-exploitation” in a Snowflake environment. After a quick Google search, I realized there is very little threat research on Snowflake. My next thought was to check out Snowflake’s access control model to better understand the access landscape. I hoped that if I could understand how users are granted access to resources in a Snowflake account, I could start to understand what attackers might do once they are authenticated. I also thought we could analyze the existing attack paths to make recommendations to reduce the blast radius of a breach of the type Crowdstrike and Mandiant reported.\nWhile we have not yet integrated Snowflake into BloodHound Community Edition (BHCE) or Enterprise (BHE), we believe there is value in taking a graph-centric approach to analyzing your deployment, as it can help you understand the impact of a campaign similar to the one described in the intro to this post.\nSnowflake Access Control Model\nMy first step was to search for any documentation on Snowflake’s access control model. I was pleased to find a page providing a relatively comprehensive and simple-to-understand model description. They describe their model as a mix of Discretionary Access Control, where “each object has an owner, who can in turn grant access to that object,” and Role-based Access Control, where “privileges are assigned to roles, which are in turn assigned to users.” These relationships are shown in the image below:\nhttps://docs.snowflake.com/en/user-guide/security-access-control-overview#access-control-framework\nNotice that Role 1 “owns” Objects 1 and 2. Then, notice that two different privileges are granted from Object 1 to Role 2 and that Role 2 is granted to Users 1 and 2. Also, notice that Roles can be granted to other Roles, which means there is a nested hierarchy similar to groups in Active Directory. One thing that I found helpful was to flip the relationship of some of these “edges.” In this graphic, they are pointing toward the grant, but the direction of access is the opposite. Imagine that you are User 1, and you are granted Role 2, which has two Privileges on Object 1. Therefore, you have two Privileges on Object 1 through transitivity.\nWe have a general idea of how privileges on objects are granted, but what types of objects does Snowflake implement? They provide a graphic to show the relationship between these objects, which they describe as “hierarchical.”\nhttps://docs.snowflake.com/en/user-guide/security-access-control-overview#securable-objects\nNotice that at the top of the hierarchy, there is an organization. Each organization can have one or many accounts. For example, the trial I created to do this research has only one Account, but the client that contacted me has ~10. The Account is generally considered to be the nexus of everything. It is helpful to think of an Account as the equivalent of an Active Directory Domain. Within the Account are Users, Roles (Groups), Databases, Warehouses (virtual compute resources), and many other objects, such as Security Integrations. Within the Database context is a Schema, and within the Schema context are Tables, Views, Stages (temporary stores for loading/unloading data), etc.\nAs I began understanding the implications of each object and the types of privileges each affords, I started to build a model showing their possible relationships. In doing so, I found it helpful to start at the top of the hierarchy (the account) and work my way down with respect to integrating entity types into the model. This is useful because access to entities often depends on access to their parent. For example, a user can only interact with a schema if the user also has access to the schema’s parent database. This allows us to abstract away details and make educated inferences about lower-level access. Below, I will describe the primary objects that I consider in my model.\nAccount (think Domain)\nThe account is the equivalent to the domain. All objects exist within the context of the account. When you log into Snowflake, you log in as a user within a specific account. Most administrative privileges are privileges to operate on the account, such as CREATE USER, MANAGE GRANTS, CREATE ROLE, CREATE DATABASE, EXECUTE TASK, etc.\nUsers (precisely what you think they are)\nUsers are your identity in the Snowflake ecosystem. When you log into the system, you do so as a particular user, and you have access to resources based on your granted roles and the role’s granted privileges.\nRoles (think Groups)\nRoles are the primary object to which privileges are assigned. Users can be granted “USAGE” of a role, similar to being added as group members. Roles can also be granted to other roles, which creates a nested structure that facilitates granular control of privileges. There are ~ five default admin accounts. The first is ACCOUNTADMIN, which is the Snowflake equivalent of Domain Admin. The remaining four are ORGADMIN, SYSADMIN, SECURITYADMIN, and USERADMIN.\nWarehouses\nA Warehouse is “a cluster of computer resources… such as CPU, memory, and temporary storage” used to perform database-related operations in a Snowflake session. Operations such as retrieving rows from tables, updating rows in tables, and loading/unloading data from tables all require a warehouse.\nDatabases\nA database is defined as “a logical grouping of schemas.” It is the container for information that we would expect attackers to target. While the database object itself does not contain any data, a user must have access to the database to access its subordinate objects (Schemas, Tables, etc.).\nPrivileges (think Access Rights)\nPrivileges define who can perform which operation on which resources. In our context, privileges are primarily assigned to roles. Snowflake supports many privileges, some of which apply in a global or account context (e.g., CREATE USER), while others are specific to an object type (e.g., CREATE SCHEMA on a Database). Users accumulate privileges through the Roles that they have been granted recursively.\nAccess Graph\nWith this basic understanding of Snowflake’s access control model, we can create a graph model that describes the relationships between entities via privileges. For instance, we know that a user can be granted the USAGE privilege of a role. This is the equivalent of an Active Directory user being a MemberOf a group. Additionally, we find that a role can be granted USAGE of another role, similar to group nesting in AD. Eventually, we can produce this relatively complete initial model for the Snowflake “access graph.”\n\nThis model can help us better understand what likely happened during the incident. It can also help us better understand the access landscape of our Snowflake deployment, which can help us reduce the blast radius should an attacker gain access.\nAbout the Incident\nAs more details have emerged, it has become clear that this campaign targeted customer credentials rather than Snowflake’s production environment. Later, on June 10th, Mandiant released a more detailed report describing some of the threat group’s activity discovered during the investigation.\nMandiant describes a typical scenario where threat actors compromise the computers of contractors that companies hire to build, manage, or administer their Snowflake deployment. In many cases, these contractors already have administrative privileges, so any compromise of their credentials can lead to detrimental effects. The existing administrative privileges indicate that the threat actor had no need to escalate privilege via an attack path or compromise alternative identities during this activity.\nMandiant describes the types of activity the attackers were observed to have implemented. They appear interested in enumerating database tables to find interesting information for exfiltration. An important observation is that, based on the reported activity, the compromised user seems to have admin or admin-adjacent privileges on the Snowflake account.\nIn this section, we will talk about each of these commands, what they do and how we can understand them in the context of our graph.\n\nAs Mandiant describes, the first command is a Discovery command meant to list all the tables available. According to the documentation, a user requires at least the USAGE privilege on the Schema object that contains the table to execute this command directly. It is common for a production Snowflake deployment to have many databases, each with many schemas, so access to tables will likely be limited to most non-admins. We can validate this in the graph, though!\nhttps://docs.snowflake.com/en/user-guide/security-access-control-privileges#schema-privileges\nNext, we see that they run the SELECT command. This indicates that they must have found one or more tables from the previous command that interested them. This command works similarly to the SQL query and returns the rows in the table. In this case, they are dumping the entire table. The privilege documentation states that a user must have the SELECT privilege on the specified table (<Target Table>) to execute this command. Additionally, the user must have the USAGE privilege on the parent database (<Target Database>) and schema (<Target Schema>).\nhttps://docs.snowflake.com/en/user-guide/security-access-control-privileges#table-privileges\nLike tables, stages exist within the schema context; thus, the requisite privilege, CREATE STAGE, exists at the schema level (aka <Redacted Schema>). The user would also require the USAGE privilege on the database (<Redacted Database>). Therefore, a user can have the ability to create a stage for one schema but not another. In general, this is a privilege that can be granted to a limited set of individuals, especially when it comes to sensitive databases/schemas.\nhttps://docs.snowflake.com/en/user-guide/security-access-control-privileges#schema-privileges\nFinally, the attackers call the COPY INTO command, which is a way to extract data from the Snowflake database. Obviously, Mandiant redacted the path, but one possible example would be to use the temporary stage to copy the data to an Amazon S3 bucket. In this case, the attacker uses the COPY INTO <location> variant, which requires the WRITE privilege. Of course, the attacker created the stage resource in the previous command, so they would likely have OWNERSHIP of the stage, granting them full control of the object.\nhttps://docs.snowflake.com/en/user-guide/security-access-control-privileges#stage-privileges\nBuild Your Own Graph\nAt this point, some of you might be interested in checking out your Snowflake Access Graph. This section walks through how to gather the necessary Snowflake data, stand up Neo4j, and build the graph. It also provides some sample Cypher queries relevant to Snowflake’s recommendations.\nCollecting Data\nThe first step is to collect the graph-relevant data from Snowflake. The cool thing is that this is actually a relatively simple process. I’ve found that Snowflake’s default web client, Snowsight, does a fine job gathering this information. You can navigate to Snowsight once you’ve logged in by clicking on the Query data button at the top of the Home page.\n\nOnce there, you will have the opportunity to execute commands. This section will describe the commands that collect the data necessary to build the graph. My parsing script is built for CSV files that follow a specific naming convention. Once your command has returned results, click the download button (downward pointing arrow) and select the “Download as .csv” option.\n\nThe model supports Accounts, Applications, Databases, Roles, Users, and Warehouses. This means we will have to query those entities, which will serve as the nodes in our graph. This will download the file with a name related to your account. My parsing script expects the output of certain commands to be named in a specific way. The expected name will be shared in the corresponding sections below.\nI’ve found that I can query Applications, Databases, Roles, and Users as an unprivileged user. However, this is different for Accounts, which require ORGADMIN, and Warehouses, which require instance-specific access (e.g., ACCOUNTADMIN).\nApplications\n\nCommand: SHOW APPLICATIONS;\nFile Name: application.csv\n\nDatabases\n\nCommand: SHOW DATABASES;\nFile Name: database.csv\n\nIntegrations\n\nCommand: SHOW INTEGRATIONS;\nFile Name: integration.csv\n\nRoles\n\nCommand: SHOW ROLES;\nFile Name: role.csv\n\nUsers\n\nCommand: SHOW USERS;\nFile Name: user.csv\n\nWarehouses\n\nCommand: SHOW WAREHOUSES;\nFile Name: warehouse.csv\n\nNote: As mentioned above, users can only enumerate warehouses for which they have been granted privileges. One way to grant a non-ACCOUNTADMIN user visibility of all warehouses is to grant the MANAGE WAREHOUSESprivilege.\nAccounts\nAt this point, we have almost all the entity data we need. We have one final query that will allow us to gather details about our Snowflake account. This query can only be done by the ORGADMIN role. Assuming your user has been granted ORGADMIN, go to the top right corner of the browser and click on your current role. This will result in a drop-down that displays all of the roles that are effectively granted to your user. Here, you will select ORGADMIN, allowing you to run commands in the context of the ORGADMIN role.\n\nOnce complete, run the following command to list the account details.\n\nCommand: SHOW ACCOUNTS;\nFile Name: account.csv\n\nGrants\nFinally, we must gather information on privilege grants. These are maintained in the ACCOUNT_USAGE schema of the default SNOWFLAKE database. By default, these views are only available to the ACCOUNTADMIN role. Still, users not granted USAGE of the ACCOUNTADMIN role can be granted the necessary read access via the SECURITY_VIEWER database role. The following command does this (if run as ACCOUNTADMIN):\nGRANT DATABASE ROLE snowflake.SECURITY_VIEWER TO <Role>\nOnce you have the necessary privilege, you can query the relevant views and export them to a CSV file. The first view is grants_to_users, which maintains a list of which roles have been granted to which users. You can enumerate this list using the following command. Then save it to a CSV file and rename it grants_to_users.csv.\nSELECT * FROM snowflake.account_usage.grants_to_users;\nThe final view is grants_to_roles, which maintains a list of all the privileges granted to roles. This glue ultimately allows users to interact with the different Snowflake entities. This view can be enumerated using the following command. The results should be saved as a CSV file named grants_to_roles.csv.\nSELECT * FROM snowflake.account_usage.grants_to_roles WHERE GRANTED_ON IN ('ACCOUNT', 'APPLICATION', 'DATABASE', 'INTEGRATION', 'ROLE', 'USER', 'WAREHOUSE'); \nSetting up Neo4j\nAt this point, we have a Cypher statement that we can use to generate the Snowflake graph, but before we can do that, we need a Neo4j instance. The easiest way that I know of to do this is to use the BloodHound Community Edition docker-compose deployment option.\nNote: While we won’t use BHCE specifically in this demo, the overarching docker-compose setup includes a Neo4j instance configured to support this example.\nTo do this, you must first install Docker on your machine. Once complete, download this example docker-compose yaml file I derived from the BHCE GitHub repository. Next, open docker-compose.yaml in a text editor and edit Line 51 to point to the folder on your host machine (e.g., /Users/jared/snowflake:/var/lib/neo4j/import/) where you wrote the Snowflake data files (e.g., grants_to_roles.csv). This will create a bind mount between your host and the container. You are now ready to start the container by executing the following command:\ndocker-compose -f /path/to/docker-composer.yaml up -d\nThis will cause Docker to download and run the relevant Docker containers. For this Snowflake graph, we will interact directly with Neo4j as this model has not been integrated into BloodHound. You can access the Neo4j web interface by browsing to 127.0.0.1:7474 and logging in using the default credentials (neo4j:bloodhoundcommunityedition).\n\nData Ingest\nOnce you’ve authenticated to Neo4j, it is time for data ingest. I originally wrote a PowerShell script that would parse the CSV files and handcraft Cypher queries to create the corresponding nodes and edges, but SadProcessor showed me a better way to approach ingestion. He suggested using the LOAD CSV clause. According to Neo4j, “LOAD CSV is used to import data from CSV files into a Neo4j database.” This dramatically simplifies ingesting your Snowflake data AND is much more efficient than my initial PowerShell script. This section describes the Cypher queries that I use to import Snowflake data. Before you begin, knowing that each command must be run individually is essential. Additionally, these commands assume that you’ve named your files as suggested. Therefore, the file listing of the folder you specified in the Docker Volume (e.g., /Users/jared/snowflake) should look this:\n-rwx------@ 1 cobbler  staff    677 Jun 12 20:17 account.csv\n-rwx------@ 1 cobbler  staff    227 Jun 12 20:17 application.csv\n-rwx------@ 1 cobbler  staff    409 Jun 12 20:17 database.csv\n-rwx------@ 1 cobbler  staff   8362 Jun 12 20:17 grants_to_roles.csv\n-rwx------@ 1 cobbler  staff    344 Jun 12 20:17 grants_to_users.csv\n-rwx------@ 1 cobbler  staff    114 Jun 12 20:17 integration.csv\n-rwx------@ 1 cobbler  staff    895 Jun 12 20:17 role.csv\n-rwx------@ 1 cobbler  staff  12350 Jun 12 20:17 table.csv\n-rwx------@ 1 cobbler  staff    917 Jun 12 20:17 user.csv\n-rwx------@ 1 cobbler  staff    436 Jun 12 20:17 warehouse.csv\nNote: If you don’t have a Snowflake environment, but still want to check out the graph, you can use my sample data set by replacing file:/// with https://gist.githubusercontent.com/jaredcatkinson/c5e560f7d3d0003d6e446da534a89e79/raw/c9288f20e606d236e3775b11ac60a29875b72dbc/ in each query.\nIngest Accounts\nLOAD CSV WITH HEADERS FROM 'file:///account.csv' AS line\nCREATE (:Account {name: line.account_locator, created_on: line.created_on, organization_name: line.organization_name, account_name: line.account_name, snowflake_region: line.snowflake_region, account_url: line.account_url, account_locator: line.account_locator, account_locator_url: line.account_locator_url})\nIngest Applications\nLOAD CSV WITH HEADERS FROM 'file:///application.csv' AS line\nCREATE (:Application {name: line.name, created_on: line.created_on, source_type: line.source_type, source: line.source})\nIngest Databases\nLOAD CSV WITH HEADERS FROM 'file:///database.csv' AS line\nCREATE (:Database {name: line.name, created_on: line.created_on, retention_time: line.retention_time, kind: line.kind})\nIngest Integrations\nLOAD CSV WITH HEADERS FROM 'file:///integration.csv' AS line\nCREATE (:Integration {name: line.name, created_on: line.created_on, type: line.type, category: line.category, enabled: line.enabled})\nIngest Roles\nLOAD CSV WITH HEADERS FROM 'file:///role.csv' AS line\nCREATE (:Role {name: line.name, created_on: line.created_on, assigned_to_users: line.assigned_to_users, granted_to_roles: line.granted_to_roles})\nIngest Users\nLOAD CSV WITH HEADERS FROM 'file:///user.csv' AS line\nCREATE (:User {name: line.name, created_on: line.created_on, login_name: line.login_name, first_name: line.first_name, last_name: line.last_name, email: line.email, disabled: line.disabled, ext_authn_duo: line.ext_authn_duo, last_success_login: line.last_success_login, has_password: line.has_password, has_rsa_public_key: line.has_rsa_public_key})\nIngest Warehouses\nLOAD CSV WITH HEADERS FROM 'file:///warehouse.csv' AS line\nCREATE (:Warehouse {name: line.name, created_on: line.created_on, state: line.state, size: line.size})\nIngest Grants to Users\nLOAD CSV WITH HEADERS FROM 'file:///grants_to_users.csv' AS usergrant\nCALL {\n    WITH usergrant\n    MATCH (u:User) WHERE u.name = usergrant.GRANTEE_NAME\n    MATCH (r:Role) WHERE r.name = usergrant.ROLE\n    MERGE (u)-[:USAGE]->(r)\n}\nIngest Grants to Roles\n:auto LOAD CSV WITH HEADERS FROM 'file:///grants_to_roles.csv' AS grant\nCALL {\n    WITH grant\n    MATCH (src) WHERE grant.GRANTED_TO = toUpper(labels(src)[0]) AND src.name = grant.GRANTEE_NAME\n    MATCH (dst) WHERE grant.GRANTED_ON = toUpper(labels(dst)[0]) AND dst.name = grant.NAME\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'USAGE' THEN [1] ELSE [] END | MERGE (src)-[:USAGE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'OWNERSHIP' THEN [1] ELSE [] END | MERGE (src)-[:OWNERSHIP]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLYBUDGET' THEN [1] ELSE [] END | MERGE (src)-[:APPLYBUDGET]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'AUDIT' THEN [1] ELSE [] END | MERGE (src)-[:AUDIT]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'MODIFY' THEN [1] ELSE [] END | MERGE (src)-[:MODIFY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'MONITOR' THEN [1] ELSE [] END | MERGE (src)-[:MONITOR]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'OPERATE' THEN [1] ELSE [] END | MERGE (src)-[:OPERATE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLY AGGREGATION POLICY' THEN [1] ELSE [] END | MERGE (src)-[:APPLY_AGGREGATION_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLY AUTHENTICATION POLICY' THEN [1] ELSE [] END | MERGE (src)-[:APPLY_AUTHENTICATION_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLY MASKING POLICY' THEN [1] ELSE [] END | MERGE (src)-[:APPLY_MASKING_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLY PACKAGES POLICY' THEN [1] ELSE [] END | MERGE (src)-[:APPLY_PACKAGES_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLY PASSWORD POLICY' THEN [1] ELSE [] END | MERGE (src)-[:APPLY_PASSWORD_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLY PROTECTION POLICY' THEN [1] ELSE [] END | MERGE (src)-[:APPLY_PROTECTION_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLY ROW ACCESS POLICY' THEN [1] ELSE [] END | MERGE (src)-[:APPLY_ROW_ACCESS_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'APPLY SESSION POLICY' THEN [1] ELSE [] END | MERGE (src)-[:APPLY_SESSION_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'ATTACH POLICY' THEN [1] ELSE [] END | MERGE (src)-[:ATTACH_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'BIND SERVICE ENDPOINT' THEN [1] ELSE [] END | MERGE (src)-[:BIND_SERVICE_ENDPOINT]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CANCEL QUERY' THEN [1] ELSE [] END | MERGE (src)-[:CANCEL_QUERY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE ACCOUNT' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_ACCOUNT]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE API INTEGRATION' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_API_INTEGRATION]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE APPLICATION' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_APPLICATION]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE APPLICATION PACKAGE' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_APPLICATION_PACKAGE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE COMPUTE POOL' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_COMPUTE_POOL]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE CREDENTIAL' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_CREDENTIAL]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE DATA EXCHANGE LISTING' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_DATA_EXCHANGE_LISTING]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE DATABASE' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_DATABASE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE DATABASE ROLE' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_DATABASE_ROLE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE EXTERNAL VOLUME' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_EXTERNAL_VOLUME]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE INTEGRATION' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_INTEGRATION]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE NETWORK POLICY' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_NETWORK_POLICY]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE REPLICATION GROUP' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_REPLICATION_GROUP]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE ROLE' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_ROLE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE SCHEMA' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_SCHEMA]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE SHARE' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_SHARE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE USER' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_USER]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'CREATE WAREHOUSE' THEN [1] ELSE [] END | MERGE (src)-[:CREATE_WAREHOUSE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'EXECUTE DATA METRIC FUNCTION' THEN [1] ELSE [] END | MERGE (src)-[:EXECUTE_DATA_METRIC_FUNCTION]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'EXECUTE MANAGED ALERT' THEN [1] ELSE [] END | MERGE (src)-[:EXECUTE_MANAGED_ALERT]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'EXECUTE MANAGED TASK' THEN [1] ELSE [] END | MERGE (src)-[:EXECUTE_MANAGED_TASK]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'EXECUTE TASK' THEN [1] ELSE [] END | MERGE (src)-[:EXECUTE_TASK]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'IMPORT SHARE' THEN [1] ELSE [] END | MERGE (src)-[:IMPORT_SHARE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'MANAGE GRANTS' THEN [1] ELSE [] END | MERGE (src)-[:MANAGE_GRANTS]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'MANAGE WAREHOUSES' THEN [1] ELSE [] END | MERGE (src)-[:MANAGE_WAREHOUSES]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'MANAGEMENT SHARING' THEN [1] ELSE [] END | MERGE (src)-[:MANAGEMENT_SHARING]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'MONITOR EXECUTION' THEN [1] ELSE [] END | MERGE (src)-[:MONITOR_EXECUTION]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'OVERRIDE SHARE RESTRICTIONS' THEN [1] ELSE [] END | MERGE (src)-[:OVERRIDE_SHARE_RESTRICTIONS]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'PURCHASE DATA EXCHANGE LISTING' THEN [1] ELSE [] END | MERGE (src)-[:PURCHASE_DATA_EXCHANGE_LISTING]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'REFERENCE USAGE' THEN [1] ELSE [] END | MERGE (src)-[:REFERENCE_USAGE]->(dst))\n    FOREACH (_ IN CASE WHEN grant.PRIVILEGE = 'USE ANY ROLE' THEN [1] ELSE [] END | MERGE (src)-[:USE_ANY_ROLE]->(dst))\n} IN TRANSACTIONS\nOnce you finish executing these commands you can validate that the data is in the graph by running a query. The query below returns any entity with a path to the Snowflake account.\nMATCH p=()-[*1..]->(a:Account)\nRETURN p\n\nThis is a common way to find admin users. While Snowflake has a few default admin Roles, such as ACCOUNTADMIN, ORGADMIN, SECURITYADMIN, SYSADMIN, and USERADMIN, granting administrative privileges to custom roles is possible.\nQueries\nHaving a graph is great! However, the value is all about the questions you can ask. I’ve only been playing around with this Snowflake graph for a few days. Still, I created a few queries that will hopefully help you gather context around the activity reported in Mandiant’s report and your compliance with Snowflake’s recommendations.\nAdmins without MFA\nSnowflake’s primary recommendation to reduce your exposure to this campaign and others like it is to enable MFA on all accounts. While achieving 100% coverage on all accounts may take some time, they also recommend enabling MFA on users who have been granted the ACCOUNTADMIN Role. Based on my reading of the reporting, the attackers likely compromised the credentials of admin users, so it seems reasonable to start with these highly privileged accounts first.\nThere are two approaches to determining which users have admin privileges. The first is to assume that admins will be granted one of the default admins roles, as shown below:\nMATCH p=((n:User WHERE n.ext_authn_duo = \"false\")-[:USAGE*1..]->(r:Role WHERE r.name CONTAINS \"ADMIN\"))\nRETURN p\n\nHere, we see seven users who have been granted USAGE of a role with the string “ADMIN” in its name. While this is a good start, the string “ADMIN” does not necessarily mean that the role has administrative privileges, and its absence does not mean that the role does not have administrative privileges. Instead, I recommend searching for admins based on their effective privileges.\nThis second query considers that admin privileges can be granted to custom roles. For example, the MANAGE_GRANTS privilege, shown below, “grants the ability to grant or revoke privileges on any object as if the invoking role were the owner of the object.” This means that if a user has this privilege, they can grant themselves or anyone access to any object they want.\nMATCH p=((n:User WHERE n.ext_authn_duo = \"false\")-[:USAGE*1..]->(r:Role)-[:MANAGE_GRANTS]->(a:Account))\nRETURN p\n\nHere, we see five users not registered for MFA who have MANAGE_GRANTS over the Snowflake Account. Two users are granted USAGE of the ACCOUNTADMINS role, and the other three are granted USAGE of a custom role. Both ACCOUNTADMINS and the custom role are granted USAGE of the SECURITYADMINS role, which is granted MANAGE_GRANTS on the account.\nRestated in familiar terms, two users are members of the ACCOUNTADMINS group, which is nested inside the SECURITYADMINS group, which has SetDACL right on the Domain Head.\nUser Access to a Database\nAccording to Mandiant, most of the attacker’s actions focused on data contained within database tables. While my graph does not currently support schema or table entities, it is important to point out that the documentation states that “operating on a table also requires the USAGE privilege on the parent database and schema.” This means that we can use the graph to understand which users have access to which database and then infer that they likely have access to the schema and tables within the database.\nMATCH p=((u:User)-[:USAGE*1..]->(r:Role)-[:OWNERSHIP]->(d:Database WHERE d.name = \"<DATABASE NAME GOES HERE>\"))\nRETURN p\n\nHere, the Jared and SNOWFLAKE users have OWNERSHIP of the SNOWFLAKE_SAMPLE_DATA database via the ACCOUNTADMIN role.\nThis query shows all users that have access to a specified databases. If you would like to check access to all databases you can run this query:\nMATCH p=((u:User)-[:USAGE*1..]->(r:Role)-[]->(d:Database))\nRETURN p\nStale User Accounts\nAnother simple example is identifying users that have never been used (logged in to). Pruning unused users might reduce the overall attack surface area.\nMATCH (n:User WHERE n.last_success_login = \"\")\nRETURN n\n\nConclusion\nI hope you found this overview and will find this graph capability useful. I’m looking forward to your feedback regarding the graph! If you write a useful query, please share it, and I will put it in the post with credit. Additionally, if you think of extending the graph, please let me know, and I’ll do my best to facilitate it.\nBefore I go, I want to comment on Snowflake’s recommendations in the aftermath of this campaign. As I mentioned, Snowflake’s primary recommendation is to enable MFA on all accounts. It is worth mentioning, in their defense, that Snowflake has always (at least since before this incident) recommended that MFA be enabled on any user granted the ACCOUNTADMIN role (the equivalent of Domain Admin).\n\nThat being said, the nature of web-based platforms means that if an attacker compromises a system with a Snowflake session, they likely can steal the session token and reuse it even if the user has MFA enabled. Austin Baker, who goes by @BakedSec on Twitter, pointed this out.\n\nThis indicates that we must look beyond how we stop attackers from getting access. We must understand the access landscape within our information systems. Ask yourself, “Can you answer which users can use the DATASCIENCE Database in your Snowflake deployment?” With this graph, that question is trivial to answer, but without one, we find that most organizations cannot answer these questions accurately. When nested groups (roles in this case) are involved, it is very easy for there to be a divergence between intended access and effective access. This only gets worse over time. I think of it as entropy.\nWe must use a similar approach for cloud accounts as on-prem administration. You don’t browse the web with your Domain Administrator account. No, you have two accounts, one for administration and one for day-to-day usage. You might even have a system that is dedicated to administrative tasks. These same ideas should apply to cloud solutions like Snowflake. Are you analyzing the data in a table? Great, use your Database Reader account. Now you need to grant Luke a role so he can access a warehouse? Okay, hop on your Privileged Access Workstation and use your SECURITYADMIN account. The same Tier 0 concept applies in this context. I look forward to hearing your feedback!\nUPDATE: Luke Jennings from Push Security added a new technique to the SaaS Attack Matrix called Session Cookie Theft. This technique shows one way that attackers, specifically if they have access to the SaaS user’s workstation, can steal relevant browser cookies in order to bypass MFA. This does not mean that organizations should not strive to enable MFA on their users, especially admin accounts, however it does demonstrate the importance of reducing attack paths within the SaaS application’s access control model. One way to think of it is that MFA is meant to make it more difficult for attackers to get in, but once they’re in it is all about Attack Paths. The graph approach I demonstrate in this post is the first step to getting a handle of these Attack Paths to reduce the blast radius of a compromise.\n\nMapping Snowflake’s Access Landscape was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Jared Atkinson",
      "guid": "https://medium.com/p/3bf232251945",
      "categories": [
        "information-security",
        "snowflake",
        "research",
        "attack-path-management",
        "specterops"
      ],
      "isoDate": "2024-06-13T16:02:36.000Z"
    },
    {
      "creator": "Forrest Kasler",
      "title": "Fly Phishing",
      "link": "https://posts.specterops.io/fly-phishing-7d4fb56ac325?source=rss----f05f8696e3cc---4",
      "pubDate": "Wed, 12 Jun 2024 14:22:50 GMT",
      "content:encoded": "<h4>PHISHING SCHOOL</h4><h4>How to Bypass SPAM Filters</h4><p>If you have ever written the word “<strong>click</strong>” in a phishing email, then trust me; You need my help.</p><p>Be honest with me.</p><p>Have you ever written the word “<strong>click</strong>”, or “<strong>upgrade</strong>”, or “<strong>w-2</strong>” in the body of a phishing email?</p><p>If so, you have committed a cardinal sin in the phishing world, and it’s time to repent. I’m not here to judge you. We all have fallen short at one time or another. I’m here to show you a better way.</p><h3><strong>How SPAM Filters Work</strong></h3><p>Once we convince the mail server that our domain is trustworthy enough to send emails to users the next opportunity the secure email gateway (SEG) has to recognize a phish is based on the content of the message. We will have to find some way to bypass this content check if we are ever going to deliver our emails to our targets.</p><p><strong><em>“The Achilles heel of the spammers is their message. They can circumvent any other barrier you set up. They have so far, at least. But they have to deliver their message, whatever it is. If we can write software that recognizes their messages, there is no way they can get around that.”</em></strong><em> —</em><strong><em> </em></strong><em>Paul Graham, 2002</em></p><p>As much as I respect Mr. Graham and his ideas, I think that time has proven him wrong on this particular viewpoint. It’s been over two decades since this claim that content is the Achilles heel of SPAM and yet some SPAM and phishing emails still slip through even the most sophisticated SEGs. The task of writing software to recognize fraudulent emails has turned out to be a lot harder than it looks at first glance.</p><p>Most SEGs work in a similar way as early anti-virus software. They look for known bad words, phrases, sentences, and even whole emails and block content that has a high ‘SPAM score’. A SPAM score is a general measurement of how SPAMy a message looks. For instance, if you use a potentially bad word like ‘Nigerian’, your content will take a hit in the form of additional SPAM score points. This may not mean your message is blocked outright, but it’s now on thin ice. If you then use the word ‘prince’ in the same message, your SPAM score jumps to an unacceptable level and your message is blocked.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/656/0*0S63doWW1vL6oR4A\" /><figcaption>Nigerian Prince Money</figcaption></figure><p>There are more advanced SEGs that leverage AI to analyze message content and sort messages into ‘normal’ and ‘fraudulent’ buckets, but the general principle is still the same. These models can only be trained on known phishing emails, and therefore can only be trained on messages that are obviously fraudulent to a human. These filters do a great job of identifying generic SPAM, but there is still plenty of gray area to play in that would actually fool many humans. We just need to avoid SPAM cliches and we should be just fine :)</p><p>Now that we know that content filters are just over-hyped word counters, let’s look at some general bypass strategies.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/468/1*ccmNzDc-1CG0WVRjZoXz7g.png\" /><figcaption>Chucking data into the abyss</figcaption></figure><h4><strong>Use Existing/Real Emails</strong></h4><p>One of my favorite tricks for bypassing content filters is to simply copy legitimate emails that have hit my inbox in the past. If you’ve ever received a legitimate message that made you pause and think about whether it was real or a phish, then you have a prime candidate. I tend to stash these emails away in a special ‘phishing ideas’ folder for when I need a quick campaign. If a message bypasses your company’s SEG, it will likely bypass your target’s. Just capture the message content with a tool like <a href=\"https://github.com/fkasler/phishmonger\">Phishmonger</a>, tweak the pretext, and swap out the link.</p><h4><strong>Target Specific Users</strong></h4><p>In general, you are going to have a much higher success rate bypassing content filters when you avoid generic mass pretexts. While you really just need to avoid the super cliche overdone pretexts, I find it easiest to avoid common pretexts when I am crafting more individualized messages. Keep a personal tone and make the request very specific. These types of messages tend to blend in with normal email conversations and lack the obvious cues that might cause a SEG to categorize them as phishing.</p><h3><strong>Watch your Language</strong></h3><p>Because email content filters are relying solely on the words of the message to make a determination about the SPAMiness of a message, they tend to place a high weight on a few individual words that are common for SPAM and phishing pretexts. These ‘dirty’ words include some things you might expect on a dirty word list like ‘sex’, ‘viagra’, and ‘porn’. In addition, mail filters also tend to include other words like ‘urgent’, ‘free’, ‘Microsoft’, ‘install’, ‘W-2’, ‘Outlook’, ‘click’, ‘patch’, ‘account’, and ‘upgrade’ on the dirty list as well. Some of these, like any blue pill references, will likely land an email in the SPAM bucket immediately. Others, like ‘patch’ might depend on additional context, or may just cause a generally high SPAM score without necessarily pushing it over the acceptable limit. Obviously, if we are going to deliver our phishing pretexts, we will want to avoid or otherwise obfuscate our use of any dirty words. Here’s a few dirty tricks that can help:</p><h4><strong>Don’t Say “Click”</strong></h4><p>Here’s another excellent Paul Graham quote from his 2002 essay on SPAM:</p><p><em>A few simple rules will take a big bite out of your incoming spam. Merely looking for the word “click” will catch 79.7% of the emails in my spam corpus, with only 1.2% false positives.</em></p><p>Full essay: <a href=\"https://paulgraham.com/spam.html\">https://paulgraham.com/spam.html</a></p><p>I know that you really want your targets to click your link, but you will need to refrain from seeming too eager, or else they won’t get to read your email in the first place. Mr. Graham did a bunch of fancy manual statistical analysis to find that “click” was one of the spammiest words, but I’m sure today’s machine learning algorithms are picking up on the same trend. Don’t say it!</p><h4><strong>Use Vague Substitutes</strong></h4><p>Often, you can simply avoid the dirty words altogether by being creative with our phrasing. Instead of saying something like “you will need to <em>install</em> an <em>upgrade</em> to your system”, you could say “you may need to <em>accept</em> some <em>changes</em> with your computer”. The words “accept” and “changes” tend to come up far more often, and under many more varying contexts than the words “install” and “upgrade”, which tend to only be in reference to running software. Yes, your message will be more vague, but the human target will be able to infer what you mean. It is this vagueness that will make it far more difficult for a computer to spot the underlying meaning.</p><h4><strong>Use Character Substitutions</strong></h4><p>On more than one occasion, I have had messages blocked by content filters because I used too many instances of words like ‘Outlook’, but by making the simple substitution of a zero in place of capital ‘o’, (e.g. ‘0utlook’) the messages were then allowed through. The same technique can be applied to other character groups like ‘I’,’L’, and ‘1’ by playing with the casing and using sans-serif fonts to reduce visual context that might help a human properly distinguish which is which. You could also play around with lookalike Unicode characters if you want to get fancy (thanks <a href=\"https://medium.com/u/74ad66811b78\">Will Schroeder</a> for the suggestion!). You might just have to specify the character set in the ‘Content-Type’ header. It’s a simple trick, but can be extremely effective because the words ‘look’ completely different to the computer but not the end reader.</p><h4><strong>Other Insertions and Substitutions</strong></h4><p>Most mail clients tend to prefer displaying a rendered HTML version of an email if an HTML section is available. Therefore, we can use a little HTML trickery to create other scenarios where the rendered result looks the same to a human, but the underlying message content is different. For instance, HTML ‘span’ tags can be used in emails, but don’t actually have any visual effect on the rendered message. In some cases, we can use span tags to break up dirty words by literally shoving a span tag in the middle of the word. Some SEGs will not be able to tell that it is still a single word and may not flag it. You can also use CSS to add entire words or even sections of content that will be processed by the SEG but never visible to the end reader. This can be useful for breaking up potentially cliche or phishy phrases. You can also get creative with using images for substitutions. This can be done to substitute individual letters, whole words, or even the entire message body.</p><h4><strong>Play with Encodings</strong></h4><p>SMTP is a purely text-based protocol. However, because emails sometimes need to contain special characters (e.g. accent marks) and arbitrary binary content (e.g. attached images), there are multiple ways to encode email data. In normal use, encoding schemes like “Quoted-Printable” (QP) are only applied to special characters that require them. However, there is no technical limitation preventing you from using QP to encode every character in a message, or even encode only a portion of a word. While the end message will look exactly the same to our human targets when rendered by the mail client, the message will look very different to a computer while in transit. In some cases, we can use this to our advantage to break up ‘dirty’ words that we know might increase our SPAM score.</p><p><strong>Pro Tip</strong>: Quoted-Printable is only one of several ways you can encode email data. There are several more absolute gems hiding in the specs that define the SMTP protocol. A great place to start for purposes of this discussion would be rfc2045 <a href=\"https://datatracker.ietf.org/doc/html/rfc2045\">https://datatracker.ietf.org/doc/html/rfc2045</a>. It’s actually a short read and not super technical. I repeat! SMTP is a text-based protocol! This stuff was just written in plain English back in 1996. Do yourself a favor and take an interactive tour of some Internet history that holds up the foundation of modern corporate communication.</p><h4><strong>Weighing Your Phish</strong></h4><p>Or rather, “weighting” your phish with benign content can help with bypassing AI-based content filters. With language learning models in the mainstream these days, most decent SEGs use some form of AI based detections, and many of the top SEGs rely almost exclusively on AI as email gatekeepers. As a result, some common and well known attacks against AI models can be very effective at bypassing modern email filters. One simple but effective attack is simply to add ‘known good’ content to a message to increase its overall ‘goodness’. Rather than over-explain the technique, I think a couple examples are more useful in this case:</p><h4>Case 1: Bypassing Cylance’s AI</h4><p>In 2019, some researchers found a categorical bypass for Cylance’s AI-based threat detection engine and released an excellent blog detailing the bypass called “Cylance I Kill You”. They found that one popular game called Rocket League used a lot of <em>hacky</em> memory manipulation techniques that are commonly also abused by malware, but that Cylance would allow this particular game to run without issue. While the use of these memory ‘optimizations’ would look very much like malware to many security products, it seemed Cylance’s AI model had been trained to ignore these warning signs in the case of this very popular game. The researchers then found that by simply adding a bunch of strings, found in the Rocket League binary, to any malware sample, they could achieve a detection bypass of “100% of the top 10 Malware for May 2019, and close to 90% for a larger sample of 384 malware.” according to their article.</p><h4><strong>Case 2: Bypassing O365 AI</strong></h4><p>A few years back, circa 2020, I was struggling to deliver phishing emails to a target organization that was using Office365’s email filter. At the time, my employer was also using O365 for email filtering and I was already in the habit of collecting odd and sketchy looking emails that hit my inbox as potential templates to run against other SEGs. I had recently heard about the Cylance AI bypass and wanted to know if the same technique would work against email filters.</p><p>One “legitimate” email that had recently crossed my inbox that I thought was particularly interesting was a mass phishing… oops I mean “marketing” campaign from Adobe Pro. The email looked about as SPAMy as possible to me, but somehow O365 had let it directly through to my inbox. It seemed that either the Adobe marketing team had found the secret sauce to bypass O365’s filter with just the right wording, or that they skipped the hard part and just paid Microsoft to let it through. In either case, the O365 model was trained to believe that no matter how SPAMy it looked, the Adobe Pro message was definitely not SPAM. As a test, I copied the footer from the “legitimate” Adobe message and appended it to my previously blocked content. To my jaw-dropping surprise, the messages finally got through… every time! I added a bunch of carriage returns just before the footer to make sure that end users never saw the additional content and shared this template with co-workers who used it for several months as a categorical bypass when facing O365.</p><h3><strong>Fly Phishing: Both a Craft and a Sport</strong></h3><p>Yes, any old lure <em>might </em>do, but a well crafted lure will do much better! Embrace the idea that you are in control of every intricate detail of your message, and use that to your advantage. Be crafty. Be skillful. When done well, you should have a sense of pride in the little masterpieces you conjure up.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/679/0*l_-yFVMz8ChmiVD-\" /><figcaption>Yes… This one will do nicely</figcaption></figure><p>Here’s just a few tricks from the old tackle box…</p><h4><strong>Don’t Miss Easy Wins</strong></h4><p>In the last blog, we covered a few easy wins to bypass SPF. When it comes to content filtering there is one main bypass that you should be aware of and look for: whenever possible, don’t traverse the filter! There are two pretty common scenarios that I’ve seen that might allow you to completely bypass a content filter. The first is when your target organization hosts their own mail server, with port 25 open, but does not host their own content filter for this server. Usually, when I’ve seen this at a client, it is an old on-prem mail server that they used before moving to a cloud email provider, but has not been decommissioned yet. Similarly, I have also seen multiple cases of on-prem SPAM filters that have port 25 open to the Internet, and have the ability to deliver mail to end users, but are out-of-date on their license and therefore completely useless at blocking malicious emails.</p><p>The other common bypass I’ve seen is organizations that use a mail provider like Office365 and automatically have a tenant mail server set up, but don’t publish the “targetdomain-com.mail.protection.outlook.com” endpoint to their MX records. By default, this email gateway will be set up for “targetdomain.com” and allow inbound messages from any source. Organizations that utilize O365 for email services, but some other provider for content filtering should ensure that their O365 gateway only accepts messages from the content filter provider, otherwise we can completely bypass the content filter and send directly to the O365 gateway instead.</p><h4><strong>Use a Real Mail Client and Server</strong></h4><p>The tools we use to phish can often add dead giveaways to our message content without our knowledge. Have you ever sent yourself an email with Gophish, SET, Phishing Frenzy, etc. and compared the ‘source’ to a real email? One thing you’ll notice right away is that the email structure is very different. There will be a lot of common headers missing, the section and content nesting will not look like a real email, and the content delimiters will look funky and generally look similar based on the phishing tool used. The problem is that these common phishing frameworks simply leverage common open-source SMTP libraries to meet the minimum requirements to form a syntactically correct message. In contrast, legitimate emails are crafted by users in their mail clients, which are very feature rich, complex, and generate very different looking SMTP data.</p><p>To make our messages look as legitimate as possible, the best approach is to simply craft our messages in a mail client and then copy out the source. To do this manually, you would craft your phishing message in Outlook or similar, send it to yourself, click ‘view source’, and copy out the content. However, this approach will not work well if you want to use popular frameworks like Gophish. You can copy out the HTML content of the message, but you will still be at the mercy of the phishing tool’s default settings for other message elements like alternate content, content nesting, headers, and content delimiters. It’s for this reason that I decided to write Phishmonger.</p><p><a href=\"https://github.com/fkasler/phishmonger\">https://github.com/fkasler/phishmonger</a></p><p>Phishmonger is a phishing framework that allows you to both send AND receive emails just like a real mail server. The biggest benefit of this approach is that we can craft phishing emails in a mail client, and send them to your Phishmonger server to capture the raw content of the SMTP DATA section. You can then send out the exact same content, with only minor substitutions for things like per-target phishing links, and you will guarantee that the message will look the same when it hits the target’s inbox as when you crafted it in Outlook. And, of course, the message content will ‘look’ like it originated from a real mail client, because it did.</p><h3><strong>Building Confidence</strong></h3><p>I hope the previous sections have opened your eyes to just how many ways we can manipulate content to potentially slip past content filters. Though I can already anticipate one big complaint from my readers…</p><p>Question: “All this theory about content filter bypasses is great to talk about, but I’m still up against a complete black box when I try to apply these techniques against a SEG on a real campaign. How do I know what’s going to work?”</p><p>Answer: You are (almost) correct. Yes, SEGs are black boxes. That is, UNTIL we test them!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*W2CKqvPNY7A-7Zcm\" /><figcaption>Got’em on the phish finder</figcaption></figure><p>If you want to build confidence that your content filter bypass is going to work, you will need to test a range of bypass techniques against the SEG used by your target organization. Given that most SEGs are cloud-based SAAS providers, and most customers leave the majority of settings in their default state, you can be reasonably assured that if you can bypass the filter in a test environment, that you will likely be successful using the same pretext against your target. To do this, our options are either to register a test account with the SEG provider, or to use bounce messages to infer spam scores using misconfigured SEGs that we can find on the internet.</p><h4><strong>But First… What SEG is my Target Using?</strong></h4><p>Again, most popular SEGs utilize a SAAS business model to protect their secret sauce. This means that you actually send emails to servers owned by the SEG provider. This means that their clients must set an MX record that points to a SEG asset. In most cases, they instruct clients to set an FQDN for this record and the top level clearly indicates the SEG provider. In more rare cases, they instruct clients to set an IP as the MX record, but we can often use either the WHOIS record for the IP or the ASN to determine which SEG owns the IP. In VERY rare cases these days, you might find a target org that hosts an on-prem SPAM filter appliance. In these cases, your best bet might be to just call some employees and social engineer them to see if any know what the spam filter is.</p><h3><strong>Setting Goals</strong></h3><p>Before we talk about SEG testing, I think it makes sense to define an objective to give us some direction. For instance, if we use a trial account for testing, we will only have a limited window of time to run tests before we have to pay for the service. How should we maximize our time?</p><p>A <strong>naive approach</strong> would be to simply test the pretext that we are about to send to our current target organization and make tweaks to the content until it slips through.</p><p>A <strong>slightly better</strong> approach might be to come up with a big list of pretexts and alternative wordings that you might want to send, and see which ones get through and which ones get blocked.</p><p>An <strong>even better</strong> approach is to come up with lots of potential bypass techniques, and attempt to<strong> </strong>find a categorical bypass for the target SEG.<strong> This is typically my end goal when testing a given SEG</strong>. I will send a variety of intentionally SPAMy messages, to make sure they are blocked by the filter, and then apply iterations of potential bypasses and obfuscations to see if I can force an arbitrary ‘bad’ message to slip through anyway. If I’m successful, it means I can use the same bypass technique to deliver messages against the same SEG for some amount of time with a relatively high confidence interval of success.</p><p>If you wanted to take this approach even further, you could also use your trial account to quickly test hundreds or even thousands of test messages and collect telemetry on which emails made it through to build an AI model that mimics the target SEG. In many cases, SEGs apply an SMTP header that contains the calculated SPAM score of each message. In these cases, it is possible to build an AI model that is a very close approximation of the model used by the target SEG. Back in 2019, Will Pearce and Nick Landers demonstrated an attack against Proofpoint using this technique:</p><p><a href=\"https://github.com/moohax/Proof-Pudding\">https://github.com/moohax/Proof-Pudding</a></p><p>You can then apply potential obfuscation techniques against your own model offline to rapidly prototype bypass techniques and still maintain a reasonable assurance that any discovered categorical bypasses will also work against the target SEG. If you are interested in using this technique, I would highly recommend looking at the methodologies and obfuscation techniques used by some of the MLSec competition winners from the last few years:</p><p><a href=\"https://cujo.com/blog/mlsec-2022-the-winners-and-some-closing-comments/\">https://cujo.com/blog/mlsec-2022-the-winners-and-some-closing-comments/</a></p><h4><strong>Dev Environment Testing</strong></h4><p>The most straightforward way to test content against a particular SEG is to register a trial account. Most trials work on the basis of a trial period that is entirely time based. Therefore, it makes sense to collect as much data as possible within the trial period as possible. If you are going for categorical bypasses, you should have a list of potential message transforms ready to go before registering your test account. Ideally, you will want to leverage some obfuscation scripts to print test messages for you. This will allow you to iterate quickly and keep the bypass techniques consistent between test messages. If you are going with the AI model replication approach, you will want to make sure you have a large set of test messages ready to go and a sending script that can accommodate matching individual messages to their resulting SPAM score. In this case, you may want to do a dry run against a test mail server you set up yourself to make sure all of the moving parts are working correctly.</p><h4><strong>Crowdsourcing Bypasses</strong></h4><p>Imagine you set up a domain to look like a legitimate business. You stand up a website, some marketing content, a few social media profiles, and a mail server. You then shove fake email addresses for your fake business all over the internet on LinkedIn, Twitter, Github, WHOIS records, message boards, newsletter subscriptions, Youtube comments, etc. You should expect that pretty soon your mail server will be flooded with unsolicited emails from all sorts of untrustworthy sources. But, what if we just let all of the SPAMers think they had a successful delivery with a “250 OK” message? You might quickly have a domain that is essentially a SPAM magnet. Now, what could you do with a SPAM magnet? How about crowdsourcing bypass techniques?</p><p>SPAM and phishing is still a thing because it works. The “real” SPAMers might be annoying, but they aren’t stupid. They know that it’s worth the effort to come up with SPAM filter bypasses and often find some unique tricks to ensure their messages get delivered to end users. At a minimum, we can create a SPAM magnet domain to collect a large corpus of potentially good training data to test and identify various bypass techniques. With a thriving SPAM magnet (receiving hundreds of messages a day) we can also just swap the SPAM magnet’s MX record to automatically attack our trial SEG account and see what makes it through. Inevitably, some of these messages will bypass the target SEG and give us valuable telemetry about which messages and message features are able to defeat the SEG. It’s sort of like getting a big list of trick plays that your opponent’s defense has completely failed to stop in the recent past. You can then either completely copy the pretext of emails that you think might work against your target organization, or identify common themes in the messages that got through to apply the same styles/bypasses to your own pretexts.</p><h4><strong>Free Testing</strong></h4><p>Most SEGs will receive and process each email, assign it a SPAM score, stamp the score in an additional SMTP header on the message, and then deliver the message to their client’s mail server. Their client’s mail server then reads the SPAM score from the message’s SMTP header, along with some other metadata like the SPF pass/fail status, to determine whether to drop the message or deliver it to the end user.</p><p>In some cases, when a message cannot be delivered to the intended MAIL TO address, the mail server will send back a bounce message in a thread and include the SPAM score header from the SEG in the message source. Most SEGs don’t keep a list of valid MAIL TO addresses for their clients, and therefore will accept and process messages with any MAIL TO as long as it is for the domain of one of their customers. Therefore, we can intentionally send emails to bad addresses like “bouncybounce@mytargetorg.com” to coerce the SEG to assign a SPAM score to the message, forward it to mytargetorg.com’s mail server, and get a bounce back to our MAIL FROM address and potentially see the SPAM score to know whether it would have been delivered to a real mailbox. Obviously, if our target organization has a mail server configuration that exposes this type of vulnerability, it’s an extremely useful preflight check for any pretext we would like to send.</p><p>Even if your target organization is not vulnerable to leaking SPAM scores in bounce messages, we can still find other organizations that are vulnerable and utilize the same SEG and use them as a good approximation of how SPAMy the SEG thinks our message is. In 2020, Sebastian Salla published an excellent blog post, BSides presentation, and tool called Phishious for automating this technique. I would highly recommend watching his presentation and checking out the tool:</p><p><a href=\"https://github.com/CanIPhish/Phishious\">https://github.com/CanIPhish/Phishious</a></p><p><strong>Warning</strong>: this technique is in a bit of a gray area. While you are not actually delivering phishing messages to any employees at the test domains, you are using their email infrastructure in a way that might be frowned upon. It’s for this reason that Sebastian intentionally avoided publishing his process for finding good target domains. Though, if you know what you’re looking for, you can pretty quickly set up an automated scanner to find useful targets.</p><h3><strong>In Summary</strong></h3><p>Modern Secure Email Gateways (SEGs) tend to rely heavily on machine learning to filter messages based on content. These models tend to automatically assign a high weight to certain words and phrases that are commonly included in phishing messages. By simply avoiding these ‘dirty’ words, we can often tweak our pretexts to slip past the filter. We can also take this process to the next level by using obfuscation techniques, paired with testing to provide a feedback loop that can help us identify categorical bypasses for our target SEG. If we find a categorical bypass, we can then have reasonable assurance that we will be able to deliver arbitrary messages to our phishing targets’ inboxes.</p><p>In the next post, we will tackle (…hehe) the next obstacle of actually convincing our target users to click on our link or open our attachment!</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=7d4fb56ac325\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/fly-phishing-7d4fb56ac325\">Fly Phishing</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "PHISHING SCHOOL\nHow to Bypass SPAM Filters\nIf you have ever written the word “click” in a phishing email, then trust me; You need my help.\nBe honest with me.\nHave you ever written the word “click”, or “upgrade”, or “w-2” in the body of a phishing email?\nIf so, you have committed a cardinal sin in the phishing world, and it’s time to repent. I’m not here to judge you. We all have fallen short at one time or another. I’m here to show you a better way.\nHow SPAM Filters Work\nOnce we convince the mail server that our domain is trustworthy enough to send emails to users the next opportunity the secure email gateway (SEG) has to recognize a phish is based on the content of the message. We will have to find some way to bypass this content check if we are ever going to deliver our emails to our targets.\n“The Achilles heel of the spammers is their message. They can circumvent any other barrier you set up. They have so far, at least. But they have to deliver their message, whatever it is. If we can write software that recognizes their messages, there is no way they can get around that.” — Paul Graham, 2002\nAs much as I respect Mr. Graham and his ideas, I think that time has proven him wrong on this particular viewpoint. It’s been over two decades since this claim that content is the Achilles heel of SPAM and yet some SPAM and phishing emails still slip through even the most sophisticated SEGs. The task of writing software to recognize fraudulent emails has turned out to be a lot harder than it looks at first glance.\nMost SEGs work in a similar way as early anti-virus software. They look for known bad words, phrases, sentences, and even whole emails and block content that has a high ‘SPAM score’. A SPAM score is a general measurement of how SPAMy a message looks. For instance, if you use a potentially bad word like ‘Nigerian’, your content will take a hit in the form of additional SPAM score points. This may not mean your message is blocked outright, but it’s now on thin ice. If you then use the word ‘prince’ in the same message, your SPAM score jumps to an unacceptable level and your message is blocked.\nNigerian Prince Money\nThere are more advanced SEGs that leverage AI to analyze message content and sort messages into ‘normal’ and ‘fraudulent’ buckets, but the general principle is still the same. These models can only be trained on known phishing emails, and therefore can only be trained on messages that are obviously fraudulent to a human. These filters do a great job of identifying generic SPAM, but there is still plenty of gray area to play in that would actually fool many humans. We just need to avoid SPAM cliches and we should be just fine :)\nNow that we know that content filters are just over-hyped word counters, let’s look at some general bypass strategies.\nChucking data into the abyss\nUse Existing/Real Emails\nOne of my favorite tricks for bypassing content filters is to simply copy legitimate emails that have hit my inbox in the past. If you’ve ever received a legitimate message that made you pause and think about whether it was real or a phish, then you have a prime candidate. I tend to stash these emails away in a special ‘phishing ideas’ folder for when I need a quick campaign. If a message bypasses your company’s SEG, it will likely bypass your target’s. Just capture the message content with a tool like Phishmonger, tweak the pretext, and swap out the link.\nTarget Specific Users\nIn general, you are going to have a much higher success rate bypassing content filters when you avoid generic mass pretexts. While you really just need to avoid the super cliche overdone pretexts, I find it easiest to avoid common pretexts when I am crafting more individualized messages. Keep a personal tone and make the request very specific. These types of messages tend to blend in with normal email conversations and lack the obvious cues that might cause a SEG to categorize them as phishing.\nWatch your Language\nBecause email content filters are relying solely on the words of the message to make a determination about the SPAMiness of a message, they tend to place a high weight on a few individual words that are common for SPAM and phishing pretexts. These ‘dirty’ words include some things you might expect on a dirty word list like ‘sex’, ‘viagra’, and ‘porn’. In addition, mail filters also tend to include other words like ‘urgent’, ‘free’, ‘Microsoft’, ‘install’, ‘W-2’, ‘Outlook’, ‘click’, ‘patch’, ‘account’, and ‘upgrade’ on the dirty list as well. Some of these, like any blue pill references, will likely land an email in the SPAM bucket immediately. Others, like ‘patch’ might depend on additional context, or may just cause a generally high SPAM score without necessarily pushing it over the acceptable limit. Obviously, if we are going to deliver our phishing pretexts, we will want to avoid or otherwise obfuscate our use of any dirty words. Here’s a few dirty tricks that can help:\nDon’t Say “Click”\nHere’s another excellent Paul Graham quote from his 2002 essay on SPAM:\nA few simple rules will take a big bite out of your incoming spam. Merely looking for the word “click” will catch 79.7% of the emails in my spam corpus, with only 1.2% false positives.\nFull essay: https://paulgraham.com/spam.html\nI know that you really want your targets to click your link, but you will need to refrain from seeming too eager, or else they won’t get to read your email in the first place. Mr. Graham did a bunch of fancy manual statistical analysis to find that “click” was one of the spammiest words, but I’m sure today’s machine learning algorithms are picking up on the same trend. Don’t say it!\nUse Vague Substitutes\nOften, you can simply avoid the dirty words altogether by being creative with our phrasing. Instead of saying something like “you will need to install an upgrade to your system”, you could say “you may need to accept some changes with your computer”. The words “accept” and “changes” tend to come up far more often, and under many more varying contexts than the words “install” and “upgrade”, which tend to only be in reference to running software. Yes, your message will be more vague, but the human target will be able to infer what you mean. It is this vagueness that will make it far more difficult for a computer to spot the underlying meaning.\nUse Character Substitutions\nOn more than one occasion, I have had messages blocked by content filters because I used too many instances of words like ‘Outlook’, but by making the simple substitution of a zero in place of capital ‘o’, (e.g. ‘0utlook’) the messages were then allowed through. The same technique can be applied to other character groups like ‘I’,’L’, and ‘1’ by playing with the casing and using sans-serif fonts to reduce visual context that might help a human properly distinguish which is which. You could also play around with lookalike Unicode characters if you want to get fancy (thanks Will Schroeder for the suggestion!). You might just have to specify the character set in the ‘Content-Type’ header. It’s a simple trick, but can be extremely effective because the words ‘look’ completely different to the computer but not the end reader.\nOther Insertions and Substitutions\nMost mail clients tend to prefer displaying a rendered HTML version of an email if an HTML section is available. Therefore, we can use a little HTML trickery to create other scenarios where the rendered result looks the same to a human, but the underlying message content is different. For instance, HTML ‘span’ tags can be used in emails, but don’t actually have any visual effect on the rendered message. In some cases, we can use span tags to break up dirty words by literally shoving a span tag in the middle of the word. Some SEGs will not be able to tell that it is still a single word and may not flag it. You can also use CSS to add entire words or even sections of content that will be processed by the SEG but never visible to the end reader. This can be useful for breaking up potentially cliche or phishy phrases. You can also get creative with using images for substitutions. This can be done to substitute individual letters, whole words, or even the entire message body.\nPlay with Encodings\nSMTP is a purely text-based protocol. However, because emails sometimes need to contain special characters (e.g. accent marks) and arbitrary binary content (e.g. attached images), there are multiple ways to encode email data. In normal use, encoding schemes like “Quoted-Printable” (QP) are only applied to special characters that require them. However, there is no technical limitation preventing you from using QP to encode every character in a message, or even encode only a portion of a word. While the end message will look exactly the same to our human targets when rendered by the mail client, the message will look very different to a computer while in transit. In some cases, we can use this to our advantage to break up ‘dirty’ words that we know might increase our SPAM score.\nPro Tip: Quoted-Printable is only one of several ways you can encode email data. There are several more absolute gems hiding in the specs that define the SMTP protocol. A great place to start for purposes of this discussion would be rfc2045 https://datatracker.ietf.org/doc/html/rfc2045. It’s actually a short read and not super technical. I repeat! SMTP is a text-based protocol! This stuff was just written in plain English back in 1996. Do yourself a favor and take an interactive tour of some Internet history that holds up the foundation of modern corporate communication.\nWeighing Your Phish\nOr rather, “weighting” your phish with benign content can help with bypassing AI-based content filters. With language learning models in the mainstream these days, most decent SEGs use some form of AI based detections, and many of the top SEGs rely almost exclusively on AI as email gatekeepers. As a result, some common and well known attacks against AI models can be very effective at bypassing modern email filters. One simple but effective attack is simply to add ‘known good’ content to a message to increase its overall ‘goodness’. Rather than over-explain the technique, I think a couple examples are more useful in this case:\nCase 1: Bypassing Cylance’s AI\nIn 2019, some researchers found a categorical bypass for Cylance’s AI-based threat detection engine and released an excellent blog detailing the bypass called “Cylance I Kill You”. They found that one popular game called Rocket League used a lot of hacky memory manipulation techniques that are commonly also abused by malware, but that Cylance would allow this particular game to run without issue. While the use of these memory ‘optimizations’ would look very much like malware to many security products, it seemed Cylance’s AI model had been trained to ignore these warning signs in the case of this very popular game. The researchers then found that by simply adding a bunch of strings, found in the Rocket League binary, to any malware sample, they could achieve a detection bypass of “100% of the top 10 Malware for May 2019, and close to 90% for a larger sample of 384 malware.” according to their article.\nCase 2: Bypassing O365 AI\nA few years back, circa 2020, I was struggling to deliver phishing emails to a target organization that was using Office365’s email filter. At the time, my employer was also using O365 for email filtering and I was already in the habit of collecting odd and sketchy looking emails that hit my inbox as potential templates to run against other SEGs. I had recently heard about the Cylance AI bypass and wanted to know if the same technique would work against email filters.\nOne “legitimate” email that had recently crossed my inbox that I thought was particularly interesting was a mass phishing… oops I mean “marketing” campaign from Adobe Pro. The email looked about as SPAMy as possible to me, but somehow O365 had let it directly through to my inbox. It seemed that either the Adobe marketing team had found the secret sauce to bypass O365’s filter with just the right wording, or that they skipped the hard part and just paid Microsoft to let it through. In either case, the O365 model was trained to believe that no matter how SPAMy it looked, the Adobe Pro message was definitely not SPAM. As a test, I copied the footer from the “legitimate” Adobe message and appended it to my previously blocked content. To my jaw-dropping surprise, the messages finally got through… every time! I added a bunch of carriage returns just before the footer to make sure that end users never saw the additional content and shared this template with co-workers who used it for several months as a categorical bypass when facing O365.\nFly Phishing: Both a Craft and a Sport\nYes, any old lure might do, but a well crafted lure will do much better! Embrace the idea that you are in control of every intricate detail of your message, and use that to your advantage. Be crafty. Be skillful. When done well, you should have a sense of pride in the little masterpieces you conjure up.\nYes… This one will do nicely\nHere’s just a few tricks from the old tackle box…\nDon’t Miss Easy Wins\nIn the last blog, we covered a few easy wins to bypass SPF. When it comes to content filtering there is one main bypass that you should be aware of and look for: whenever possible, don’t traverse the filter! There are two pretty common scenarios that I’ve seen that might allow you to completely bypass a content filter. The first is when your target organization hosts their own mail server, with port 25 open, but does not host their own content filter for this server. Usually, when I’ve seen this at a client, it is an old on-prem mail server that they used before moving to a cloud email provider, but has not been decommissioned yet. Similarly, I have also seen multiple cases of on-prem SPAM filters that have port 25 open to the Internet, and have the ability to deliver mail to end users, but are out-of-date on their license and therefore completely useless at blocking malicious emails.\nThe other common bypass I’ve seen is organizations that use a mail provider like Office365 and automatically have a tenant mail server set up, but don’t publish the “targetdomain-com.mail.protection.outlook.com” endpoint to their MX records. By default, this email gateway will be set up for “targetdomain.com” and allow inbound messages from any source. Organizations that utilize O365 for email services, but some other provider for content filtering should ensure that their O365 gateway only accepts messages from the content filter provider, otherwise we can completely bypass the content filter and send directly to the O365 gateway instead.\nUse a Real Mail Client and Server\nThe tools we use to phish can often add dead giveaways to our message content without our knowledge. Have you ever sent yourself an email with Gophish, SET, Phishing Frenzy, etc. and compared the ‘source’ to a real email? One thing you’ll notice right away is that the email structure is very different. There will be a lot of common headers missing, the section and content nesting will not look like a real email, and the content delimiters will look funky and generally look similar based on the phishing tool used. The problem is that these common phishing frameworks simply leverage common open-source SMTP libraries to meet the minimum requirements to form a syntactically correct message. In contrast, legitimate emails are crafted by users in their mail clients, which are very feature rich, complex, and generate very different looking SMTP data.\nTo make our messages look as legitimate as possible, the best approach is to simply craft our messages in a mail client and then copy out the source. To do this manually, you would craft your phishing message in Outlook or similar, send it to yourself, click ‘view source’, and copy out the content. However, this approach will not work well if you want to use popular frameworks like Gophish. You can copy out the HTML content of the message, but you will still be at the mercy of the phishing tool’s default settings for other message elements like alternate content, content nesting, headers, and content delimiters. It’s for this reason that I decided to write Phishmonger.\nhttps://github.com/fkasler/phishmonger\nPhishmonger is a phishing framework that allows you to both send AND receive emails just like a real mail server. The biggest benefit of this approach is that we can craft phishing emails in a mail client, and send them to your Phishmonger server to capture the raw content of the SMTP DATA section. You can then send out the exact same content, with only minor substitutions for things like per-target phishing links, and you will guarantee that the message will look the same when it hits the target’s inbox as when you crafted it in Outlook. And, of course, the message content will ‘look’ like it originated from a real mail client, because it did.\nBuilding Confidence\nI hope the previous sections have opened your eyes to just how many ways we can manipulate content to potentially slip past content filters. Though I can already anticipate one big complaint from my readers…\nQuestion: “All this theory about content filter bypasses is great to talk about, but I’m still up against a complete black box when I try to apply these techniques against a SEG on a real campaign. How do I know what’s going to work?”\nAnswer: You are (almost) correct. Yes, SEGs are black boxes. That is, UNTIL we test them!\nGot’em on the phish finder\nIf you want to build confidence that your content filter bypass is going to work, you will need to test a range of bypass techniques against the SEG used by your target organization. Given that most SEGs are cloud-based SAAS providers, and most customers leave the majority of settings in their default state, you can be reasonably assured that if you can bypass the filter in a test environment, that you will likely be successful using the same pretext against your target. To do this, our options are either to register a test account with the SEG provider, or to use bounce messages to infer spam scores using misconfigured SEGs that we can find on the internet.\nBut First… What SEG is my Target Using?\nAgain, most popular SEGs utilize a SAAS business model to protect their secret sauce. This means that you actually send emails to servers owned by the SEG provider. This means that their clients must set an MX record that points to a SEG asset. In most cases, they instruct clients to set an FQDN for this record and the top level clearly indicates the SEG provider. In more rare cases, they instruct clients to set an IP as the MX record, but we can often use either the WHOIS record for the IP or the ASN to determine which SEG owns the IP. In VERY rare cases these days, you might find a target org that hosts an on-prem SPAM filter appliance. In these cases, your best bet might be to just call some employees and social engineer them to see if any know what the spam filter is.\nSetting Goals\nBefore we talk about SEG testing, I think it makes sense to define an objective to give us some direction. For instance, if we use a trial account for testing, we will only have a limited window of time to run tests before we have to pay for the service. How should we maximize our time?\nA naive approach would be to simply test the pretext that we are about to send to our current target organization and make tweaks to the content until it slips through.\nA slightly better approach might be to come up with a big list of pretexts and alternative wordings that you might want to send, and see which ones get through and which ones get blocked.\nAn even better approach is to come up with lots of potential bypass techniques, and attempt to find a categorical bypass for the target SEG. This is typically my end goal when testing a given SEG. I will send a variety of intentionally SPAMy messages, to make sure they are blocked by the filter, and then apply iterations of potential bypasses and obfuscations to see if I can force an arbitrary ‘bad’ message to slip through anyway. If I’m successful, it means I can use the same bypass technique to deliver messages against the same SEG for some amount of time with a relatively high confidence interval of success.\nIf you wanted to take this approach even further, you could also use your trial account to quickly test hundreds or even thousands of test messages and collect telemetry on which emails made it through to build an AI model that mimics the target SEG. In many cases, SEGs apply an SMTP header that contains the calculated SPAM score of each message. In these cases, it is possible to build an AI model that is a very close approximation of the model used by the target SEG. Back in 2019, Will Pearce and Nick Landers demonstrated an attack against Proofpoint using this technique:\nhttps://github.com/moohax/Proof-Pudding\nYou can then apply potential obfuscation techniques against your own model offline to rapidly prototype bypass techniques and still maintain a reasonable assurance that any discovered categorical bypasses will also work against the target SEG. If you are interested in using this technique, I would highly recommend looking at the methodologies and obfuscation techniques used by some of the MLSec competition winners from the last few years:\nhttps://cujo.com/blog/mlsec-2022-the-winners-and-some-closing-comments/\nDev Environment Testing\nThe most straightforward way to test content against a particular SEG is to register a trial account. Most trials work on the basis of a trial period that is entirely time based. Therefore, it makes sense to collect as much data as possible within the trial period as possible. If you are going for categorical bypasses, you should have a list of potential message transforms ready to go before registering your test account. Ideally, you will want to leverage some obfuscation scripts to print test messages for you. This will allow you to iterate quickly and keep the bypass techniques consistent between test messages. If you are going with the AI model replication approach, you will want to make sure you have a large set of test messages ready to go and a sending script that can accommodate matching individual messages to their resulting SPAM score. In this case, you may want to do a dry run against a test mail server you set up yourself to make sure all of the moving parts are working correctly.\nCrowdsourcing Bypasses\nImagine you set up a domain to look like a legitimate business. You stand up a website, some marketing content, a few social media profiles, and a mail server. You then shove fake email addresses for your fake business all over the internet on LinkedIn, Twitter, Github, WHOIS records, message boards, newsletter subscriptions, Youtube comments, etc. You should expect that pretty soon your mail server will be flooded with unsolicited emails from all sorts of untrustworthy sources. But, what if we just let all of the SPAMers think they had a successful delivery with a “250 OK” message? You might quickly have a domain that is essentially a SPAM magnet. Now, what could you do with a SPAM magnet? How about crowdsourcing bypass techniques?\nSPAM and phishing is still a thing because it works. The “real” SPAMers might be annoying, but they aren’t stupid. They know that it’s worth the effort to come up with SPAM filter bypasses and often find some unique tricks to ensure their messages get delivered to end users. At a minimum, we can create a SPAM magnet domain to collect a large corpus of potentially good training data to test and identify various bypass techniques. With a thriving SPAM magnet (receiving hundreds of messages a day) we can also just swap the SPAM magnet’s MX record to automatically attack our trial SEG account and see what makes it through. Inevitably, some of these messages will bypass the target SEG and give us valuable telemetry about which messages and message features are able to defeat the SEG. It’s sort of like getting a big list of trick plays that your opponent’s defense has completely failed to stop in the recent past. You can then either completely copy the pretext of emails that you think might work against your target organization, or identify common themes in the messages that got through to apply the same styles/bypasses to your own pretexts.\nFree Testing\nMost SEGs will receive and process each email, assign it a SPAM score, stamp the score in an additional SMTP header on the message, and then deliver the message to their client’s mail server. Their client’s mail server then reads the SPAM score from the message’s SMTP header, along with some other metadata like the SPF pass/fail status, to determine whether to drop the message or deliver it to the end user.\nIn some cases, when a message cannot be delivered to the intended MAIL TO address, the mail server will send back a bounce message in a thread and include the SPAM score header from the SEG in the message source. Most SEGs don’t keep a list of valid MAIL TO addresses for their clients, and therefore will accept and process messages with any MAIL TO as long as it is for the domain of one of their customers. Therefore, we can intentionally send emails to bad addresses like “bouncybounce@mytargetorg.com” to coerce the SEG to assign a SPAM score to the message, forward it to mytargetorg.com’s mail server, and get a bounce back to our MAIL FROM address and potentially see the SPAM score to know whether it would have been delivered to a real mailbox. Obviously, if our target organization has a mail server configuration that exposes this type of vulnerability, it’s an extremely useful preflight check for any pretext we would like to send.\nEven if your target organization is not vulnerable to leaking SPAM scores in bounce messages, we can still find other organizations that are vulnerable and utilize the same SEG and use them as a good approximation of how SPAMy the SEG thinks our message is. In 2020, Sebastian Salla published an excellent blog post, BSides presentation, and tool called Phishious for automating this technique. I would highly recommend watching his presentation and checking out the tool:\nhttps://github.com/CanIPhish/Phishious\nWarning: this technique is in a bit of a gray area. While you are not actually delivering phishing messages to any employees at the test domains, you are using their email infrastructure in a way that might be frowned upon. It’s for this reason that Sebastian intentionally avoided publishing his process for finding good target domains. Though, if you know what you’re looking for, you can pretty quickly set up an automated scanner to find useful targets.\nIn Summary\nModern Secure Email Gateways (SEGs) tend to rely heavily on machine learning to filter messages based on content. These models tend to automatically assign a high weight to certain words and phrases that are commonly included in phishing messages. By simply avoiding these ‘dirty’ words, we can often tweak our pretexts to slip past the filter. We can also take this process to the next level by using obfuscation techniques, paired with testing to provide a feedback loop that can help us identify categorical bypasses for our target SEG. If we find a categorical bypass, we can then have reasonable assurance that we will be able to deliver arbitrary messages to our phishing targets’ inboxes.\nIn the next post, we will tackle (…hehe) the next obstacle of actually convincing our target users to click on our link or open our attachment!\n\nFly Phishing was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Forrest Kasler",
      "guid": "https://medium.com/p/7d4fb56ac325",
      "categories": [
        "red-team",
        "phishing",
        "pentesting",
        "cybersecurity",
        "social-engineering"
      ],
      "isoDate": "2024-06-12T14:22:50.000Z"
    },
    {
      "creator": "Daniel Mayer",
      "title": "Lateral Movement with the .NET Profiler",
      "link": "https://posts.specterops.io/lateral-movement-with-the-net-profiler-8772c86f9523?source=rss----f05f8696e3cc---4",
      "pubDate": "Tue, 11 Jun 2024 16:35:52 GMT",
      "content:encoded": "<h3>Lateral Movement with the .NET Profiler</h3><p>The accompanying code for this blogpost can be found <a href=\"https://github.com/MayerDaniel/profiler-lateral-movement\">HERE</a>.</p><h3>Intro</h3><p>I spend a lot of my free time modding Unity games. Since Unity is written in C#, the games are very easy to work with compared to those that compile to unmanaged code. This makes it a perfect hobby project to pick up and set down without getting too sweaty.</p><p>As I got deeper into modding C# games, I realized that hooking functions is actually slightly more complicated than it is in unmanaged programs, which is counterintuitive because just about everything else is much, much easier.</p><p>For unmanaged code, hooking functions is relatively straightforward. The basic steps are:</p><ul><li>Allocate some memory to house the code you want to run when a function is called and write your instructions there</li><li>Overwrite the beginning of the original function’s instructions to jump to your new code</li><li>Handle all the fiddly details necessary to ensure that the program’s execution gets back to the original function and that the stack isn’t sloppy joe meat by the end of it</li></ul><p>With .NET and Mono, it isn’t as simple. .NET assemblies’ functions are made up of a binary instruction set known as the Common Intermediate Language (CIL) that gets just-in-time (JIT) compiled to machine instructions at runtime by the Common Language Runtime (CLR).</p><p>The main issue with attempting to hook managed code is that by the time you inject into the process you want to hook a function in, the target function may have already been JIT’ed and if so, the CLR the has cached the x86 instructions that it gets translated into. If you modify the CIL bytecode and the function gets called again, the CLR may just execute the cached x86 instructions that were compiled before your modifications. In addition to this issue, there are myriad little corner cases that make this a big headache. (Although in reality, this is a solved problem. There have been many great solutions and frameworks built to make this easy for developers, such as <a href=\"https://harmony.pardeike.net/articles/intro.html\">Harmony </a>and <a href=\"https://github.com/MonoMod/MonoMod/blob/master/README.md\">MonoMod</a>, but I was still curious to learn more about it.)</p><h3>.NET Profilers</h3><p>In my googling for hooking solutions, I came across <a href=\"https://learn.microsoft.com/en-us/dotnet/framework/unmanaged-api/profiling/profiling-overview\">Microsoft’s .NET profiling API</a>, which wasn’t that helpful for my modding needs, but it did seem to have some handy primitives for red teaming! It is designed to allow for instrumentation of .NET processes by implementing a callback interface in an unmanaged COM server DLL that gets loaded into a given .NET process.</p><p>The CLR then calls functions from the interface when different events happen during execution. For pretty much anything that goes on in the CLR, you can implement a callback that gets called to inspect and manipulate behavior at runtime, such as when assemblies and modules are loaded, when functions are JIT compiled, and much more. Just look at all these callbacks, and this isn’t even all of them!</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ItDuxnzw5lEskkG_rW9bVQ.png\" /><figcaption>.NET Profiling API Callbacks</figcaption></figure><p>For more information about the basics of how these profilers work, I recommend watching this talk by Pavel Yosifovich. It was far and away the most valuable resource I found:</p><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2FTqS4OEWn6hQ%3Ffeature%3Doembed&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DTqS4OEWn6hQ&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2FTqS4OEWn6hQ%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube\" width=\"854\" height=\"480\" frameborder=\"0\" scrolling=\"no\"><a href=\"https://medium.com/media/78a9180af2b2ea4398572c48ce6ffdd6/href\">https://medium.com/media/78a9180af2b2ea4398572c48ce6ffdd6/href</a></iframe><h3>The Offensive Value of the .NET Profiler</h3><p><strong>Execution and Persistence:</strong></p><p>Upon execution, the CLR for a given process examines the environment variables for three specific variables that cause a profiling DLL to be loaded:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2if_8wK2j2PRyBO-mT0SdQ.png\" /><figcaption>Profiler-Specific Environment Variables</figcaption></figure><ul><li>COR_ENABLE_PROFILING — This is a flag that enables profiling for the given process if set to 1, meaning the profiler DLL will be loaded into the process</li><li>COR_PROFILER — This is the CLSID that will be handed to the profiler DLL to see if it is the correct COM server. The profiler DLL can choose not to check this though and load no matter what this CLSID is</li><li>COR_PROFILER_PATH — The path to the profiler DLL that will be loaded</li></ul><p>If all of these variables are present, profiling is enabled, and the DLL exists on disk, the profiler DLL will be loaded into the process at the start of execution. This gives us a pretty nice code execution primitive to load a DLL into an arbitrary .NET process.</p><p>This has been documented for some time and observed used by threat actors in the wild. I ran across <a href=\"https://bohops.com/2023/11/27/abusing-net-core-clr-diagnostic-features-cve-2023-33127/\">this blog by Bohops</a> detailing other interesting abuses of the .NET profiling infrastructure in Windows. It references <a href=\"https://web.archive.org/web/20170720041203/http:/subt0x10.blogspot.com/2017/05/subvert-clr-process-listing-with-net.html\">a blog by Casey Smith from 2017</a> detailing loading a DLL this way, and <a href=\"https://attack.mitre.org/techniques/T1574/012/\">MITRE has a technique for this as well as some in-the-wild examples</a>.</p><p>Since environment variables can be set system-wide, this means that this also works as form of persistence. Whenever a .NET process executes, it will load the specified DLL.</p><p>The minimum viable profiler that can abuse this is a “fake” COM server DLL that exports the function <a href=\"https://learn.microsoft.com/en-us/windows/win32/api/combaseapi/nf-combaseapi-dllgetclassobject\">DllGetClassObject</a>, which is the function that is used to check the CLSID of the COM server DLL. As stated above though, there’s no need to actually implement the logic of the check here, and arbitrary code can be executed instead:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*ts0ExNeG1a6LLfSGWONQZg.png\" /><figcaption>Minimum viable “fake” profiler</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*RZAEa0roFtNMMJm3UZY0rg.png\" /><figcaption>Execution of the “fake” profiler in a .NET process</figcaption></figure><p><strong>Lateral Movement:</strong></p><p>I was talking to Lee Chagolla-Christensen (<a href=\"https://x.com/tifkin_?lang=en\">@tifkin</a>) about ways to set these environment variables on a remote computer to load a DLL via UNC paths, and he let me know that the <a href=\"https://learn.microsoft.com/en-us/windows/win32/cimwin32prov/win32-processstartup\">Win32_ProcessStartup</a> WMI class allows for environment variables to be set for a specific process, meaning that this could be abused with a <a href=\"https://learn.microsoft.com/en-us/windows/win32/cimwin32prov/create-method-in-class-win32-process\">Win32_Process Create</a> call to execute a .NET process remotely and load a .NET profiler DLL! Thanks Lee!</p><p>So I set about creating a BOF and Payload to allow this to be used more easily. There results are <a href=\"https://github.com/MayerDaniel/profiler-lateral-movement\">HERE</a>.</p><p>I modified <a href=\"https://github.com/Yaxser/CobaltStrike-BOF/tree/master/WMI%20Lateral%20Movement\">Yaxser’s WMI Lateral Movement BOF</a> to include a Win32_ProcessStartup class with the appropriate environment variables defined and a user-defined DLL path to enable lateral movement via the .NET profiler.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/952/1*NpkwpSTkoOkgOAtje6L5kg.png\" /><figcaption>Adding environment variables to enable WMI lateral movement</figcaption></figure><p>Additionally, I modified Pavel Yosifovich’s example .NET profiler to be a better payload. I utilized <a href=\"https://www.ired.team/offensive-security/code-injection-process-injection/loading-and-executing-shellcode-from-portable-executable-resources\">this tutorial</a> from ired.team to store a shellcode payload as a resource that can be hot swapped, and I used the function <a href=\"https://learn.microsoft.com/en-us/dotnet/framework/unmanaged-api/profiling/icorprofilerinfo2-setenterleavefunctionhooks2-method\">ICorProfilerInfo2::SetEnterLeaveFunctionHooks2</a> to set an enter hook on all JITed functions. The hook will load and execute the shellcode from the resource, essentially performing process hollowing, because normal functionality of the hooked function will cease indefinitely if the payload is something like a Cobalt Strike beacon.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/962/1*2XL93yHaEzkCgerZy6OPiw.png\" /><figcaption>Setting the hooks during initialization</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*TatFaO1FXER1oy_JGGPc8Q.png\" /><figcaption>Adding the shellcode execution to the function enter hook</figcaption></figure><p>In that same file, <a href=\"https://github.com/MayerDaniel/profiler-lateral-movement/blob/main/DotNextProfilerPayload/DotNext.Profiler.Shared/CoreProfiler.cpp\">CoreProfiler.cpp</a>, you can see all the other handy callbacks that could be used for execution primitives or even more interesting use cases. A neat example that uses the .NET profiler for evasion is Omer Yair’s <a href=\"https://github.com/OmerYa/Invisi-Shell/tree/master\">InvisiShell</a>, which <a href=\"https://github.com/OmerYa/Invisi-Shell/blob/5eb4938a04e7883a9af5ef03959d6eb013da96cf/InvisiShellProfier/InvisiShellProfiler.cpp#L428\">monitors assembly loads in PowerShell processes to then patch out functions to disable AMSI</a>. I believe there’s a lot of fertile ground here for further research regarding all the callbacks exposed by the CLR.</p><p><strong>Putting it all together</strong></p><p>When we use the payload and BOF together, you get lateral movement that looks something like this:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*WkWeoXzjfj9KqviQ7X8Mzw.png\" /><figcaption>.NET Profiler BOF execution</figcaption></figure><p>You might be thinking: “hey Dan! Didn’t you say earlier you wanted to load the payload from a UNC path?” Yes I did, good memory. Sadly since we are using WMI we run into the <a href=\"https://techcommunity.microsoft.com/t5/ask-the-directory-services-team/understanding-kerberos-double-hop/ba-p/395463\">double hop problem</a>, meaning the process we execute on the remote machine can’t authenticate to a remote file share to pull our payload via a UNC path. That’s ok though, because the DLL can instead be loaded from a WebDAV server:</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Xm4G8wKSqeu26rSKZSsxYA.png\" /><figcaption>.NET Profiler BOF execution featuring WebDAV</figcaption></figure><p>You can even set it up to be through the beacon you are executing the BOF with by utilizing <a href=\"https://github.com/mar10/wsgidav\">wsgidav</a>. First execute this command to host your server locally on your workstation:</p><pre>wsgidav --host=0.0.0.0 --port=80 --root=/payload/folder --auth=anonymous</pre><p>and then start a reverse portforward on your beacon:</p><pre>rportfwd 80 localhost 80</pre><p>Now you can execute a .NET process, have your payload pulled over automatically, and executed.</p><h3>Conclusion</h3><p>I found this “feature” of the .NET Profiler to be pretty neat albeit a little unwieldy. You’ll see that the payload is purely for demonstration purposes. No attempts to make it evasive have been made so defender may eat it upon being built. Sorry!</p><p>I hope this gets folks more curious about all the cool stuff you can do with the .NET profiler though, and I’m sure there are other ways out there to remotely set environment variables to make it even more useful. I briefly looked into <a href=\"https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/setx\">setx</a> and other means of setting them via remote registry, but it seemed like the changes didn’t take effect until after a reboot. I bet there is some way to make it work though!</p><p>Many thanks again to Lee, Pavel, Yaxser, and Mantvydas for all the prior research, since the payload and BOF is really just a collage of your work.</p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8772c86f9523\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/lateral-movement-with-the-net-profiler-8772c86f9523\">Lateral Movement with the .NET Profiler</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "Lateral Movement with the .NET Profiler\nThe accompanying code for this blogpost can be found HERE.\nIntro\nI spend a lot of my free time modding Unity games. Since Unity is written in C#, the games are very easy to work with compared to those that compile to unmanaged code. This makes it a perfect hobby project to pick up and set down without getting too sweaty.\nAs I got deeper into modding C# games, I realized that hooking functions is actually slightly more complicated than it is in unmanaged programs, which is counterintuitive because just about everything else is much, much easier.\nFor unmanaged code, hooking functions is relatively straightforward. The basic steps are:\n\nAllocate some memory to house the code you want to run when a function is called and write your instructions there\nOverwrite the beginning of the original function’s instructions to jump to your new code\nHandle all the fiddly details necessary to ensure that the program’s execution gets back to the original function and that the stack isn’t sloppy joe meat by the end of it\n\nWith .NET and Mono, it isn’t as simple. .NET assemblies’ functions are made up of a binary instruction set known as the Common Intermediate Language (CIL) that gets just-in-time (JIT) compiled to machine instructions at runtime by the Common Language Runtime (CLR).\nThe main issue with attempting to hook managed code is that by the time you inject into the process you want to hook a function in, the target function may have already been JIT’ed and if so, the CLR the has cached the x86 instructions that it gets translated into. If you modify the CIL bytecode and the function gets called again, the CLR may just execute the cached x86 instructions that were compiled before your modifications. In addition to this issue, there are myriad little corner cases that make this a big headache. (Although in reality, this is a solved problem. There have been many great solutions and frameworks built to make this easy for developers, such as Harmony and MonoMod, but I was still curious to learn more about it.)\n.NET Profilers\nIn my googling for hooking solutions, I came across Microsoft’s .NET profiling API, which wasn’t that helpful for my modding needs, but it did seem to have some handy primitives for red teaming! It is designed to allow for instrumentation of .NET processes by implementing a callback interface in an unmanaged COM server DLL that gets loaded into a given .NET process.\nThe CLR then calls functions from the interface when different events happen during execution. For pretty much anything that goes on in the CLR, you can implement a callback that gets called to inspect and manipulate behavior at runtime, such as when assemblies and modules are loaded, when functions are JIT compiled, and much more. Just look at all these callbacks, and this isn’t even all of them!\n.NET Profiling API Callbacks\nFor more information about the basics of how these profilers work, I recommend watching this talk by Pavel Yosifovich. It was far and away the most valuable resource I found:\nhttps://medium.com/media/78a9180af2b2ea4398572c48ce6ffdd6/href\nThe Offensive Value of the .NET Profiler\nExecution and Persistence:\nUpon execution, the CLR for a given process examines the environment variables for three specific variables that cause a profiling DLL to be loaded:\nProfiler-Specific Environment Variables\nCOR_ENABLE_PROFILING — This is a flag that enables profiling for the given process if set to 1, meaning the profiler DLL will be loaded into the process\nCOR_PROFILER — This is the CLSID that will be handed to the profiler DLL to see if it is the correct COM server. The profiler DLL can choose not to check this though and load no matter what this CLSID is\nCOR_PROFILER_PATH — The path to the profiler DLL that will be loaded\n\nIf all of these variables are present, profiling is enabled, and the DLL exists on disk, the profiler DLL will be loaded into the process at the start of execution. This gives us a pretty nice code execution primitive to load a DLL into an arbitrary .NET process.\nThis has been documented for some time and observed used by threat actors in the wild. I ran across this blog by Bohops detailing other interesting abuses of the .NET profiling infrastructure in Windows. It references a blog by Casey Smith from 2017 detailing loading a DLL this way, and MITRE has a technique for this as well as some in-the-wild examples.\nSince environment variables can be set system-wide, this means that this also works as form of persistence. Whenever a .NET process executes, it will load the specified DLL.\nThe minimum viable profiler that can abuse this is a “fake” COM server DLL that exports the function DllGetClassObject, which is the function that is used to check the CLSID of the COM server DLL. As stated above though, there’s no need to actually implement the logic of the check here, and arbitrary code can be executed instead:\nMinimum viable “fake” profilerExecution of the “fake” profiler in a .NET process\nLateral Movement:\nI was talking to Lee Chagolla-Christensen (@tifkin) about ways to set these environment variables on a remote computer to load a DLL via UNC paths, and he let me know that the Win32_ProcessStartup WMI class allows for environment variables to be set for a specific process, meaning that this could be abused with a Win32_Process Create call to execute a .NET process remotely and load a .NET profiler DLL! Thanks Lee!\nSo I set about creating a BOF and Payload to allow this to be used more easily. There results are HERE.\nI modified Yaxser’s WMI Lateral Movement BOF to include a Win32_ProcessStartup class with the appropriate environment variables defined and a user-defined DLL path to enable lateral movement via the .NET profiler.\nAdding environment variables to enable WMI lateral movement\nAdditionally, I modified Pavel Yosifovich’s example .NET profiler to be a better payload. I utilized this tutorial from ired.team to store a shellcode payload as a resource that can be hot swapped, and I used the function ICorProfilerInfo2::SetEnterLeaveFunctionHooks2 to set an enter hook on all JITed functions. The hook will load and execute the shellcode from the resource, essentially performing process hollowing, because normal functionality of the hooked function will cease indefinitely if the payload is something like a Cobalt Strike beacon.\nSetting the hooks during initializationAdding the shellcode execution to the function enter hook\nIn that same file, CoreProfiler.cpp, you can see all the other handy callbacks that could be used for execution primitives or even more interesting use cases. A neat example that uses the .NET profiler for evasion is Omer Yair’s InvisiShell, which monitors assembly loads in PowerShell processes to then patch out functions to disable AMSI. I believe there’s a lot of fertile ground here for further research regarding all the callbacks exposed by the CLR.\nPutting it all together\nWhen we use the payload and BOF together, you get lateral movement that looks something like this:\n.NET Profiler BOF execution\nYou might be thinking: “hey Dan! Didn’t you say earlier you wanted to load the payload from a UNC path?” Yes I did, good memory. Sadly since we are using WMI we run into the double hop problem, meaning the process we execute on the remote machine can’t authenticate to a remote file share to pull our payload via a UNC path. That’s ok though, because the DLL can instead be loaded from a WebDAV server:\n.NET Profiler BOF execution featuring WebDAV\nYou can even set it up to be through the beacon you are executing the BOF with by utilizing wsgidav. First execute this command to host your server locally on your workstation:\nwsgidav --host=0.0.0.0 --port=80 --root=/payload/folder --auth=anonymous\nand then start a reverse portforward on your beacon:\nrportfwd 80 localhost 80\nNow you can execute a .NET process, have your payload pulled over automatically, and executed.\nConclusion\nI found this “feature” of the .NET Profiler to be pretty neat albeit a little unwieldy. You’ll see that the payload is purely for demonstration purposes. No attempts to make it evasive have been made so defender may eat it upon being built. Sorry!\nI hope this gets folks more curious about all the cool stuff you can do with the .NET profiler though, and I’m sure there are other ways out there to remotely set environment variables to make it even more useful. I briefly looked into setx and other means of setting them via remote registry, but it seemed like the changes didn’t take effect until after a reboot. I bet there is some way to make it work though!\nMany thanks again to Lee, Pavel, Yaxser, and Mantvydas for all the prior research, since the payload and BOF is really just a collage of your work.\n\nLateral Movement with the .NET Profiler was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Daniel Mayer",
      "guid": "https://medium.com/p/8772c86f9523",
      "categories": [
        "red-team",
        "dotnet",
        "lateral-movement",
        "offensive-security",
        "specterops"
      ],
      "isoDate": "2024-06-11T16:35:52.000Z"
    },
    {
      "creator": "Christopher Maddalena",
      "title": "Ghostwriter v4.2",
      "link": "https://posts.specterops.io/ghostwriter-v4-2-9fc10d77bf19?source=rss----f05f8696e3cc---4",
      "pubDate": "Mon, 10 Jun 2024 20:01:29 GMT",
      "content:encoded": "<h3>Ghostwriter v4.2: Project Documents &amp; Reporting Enhancements</h3><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*2_CxAvHTQJodDVUW\" /></figure><p>After <a href=\"https://posts.specterops.io/ghostwriter-v4-1-the-custom-fields-update-fe07f7dda293\">April’s massive Ghostwriter v4.1 release</a>, we received some great feedback and ideas. We got a little carried away working on these and created a release so big we had to call it v4.2. This release contains some fantastic changes and additions to the features introduced in April’s release. Let’s get to the highlights!</p><h3>Improving Customizable Fields</h3><p>Ghostwriter v4.1 introduced custom fields, and seeing the community use them so creatively was awesome. What we saw gave us some ideas for a few big improvements.</p><p>The rich text fields support the Jinja2 templating language, so loops quickly became a talking point. Looping over project objectives, findings, hosts, and other things to create dynamic lists, table rows, or sections is incredibly powerful, so we had to do it.</p><p>You can now use Jinja2-style expressions with the new <em>li</em>, <em>tr</em>, and <em>p</em> tags to create list items, table rows, and text sections. Here is an example of building a dynamic list inside Ghostwriter’s WYSIWYG editor.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*c8Ox38as_1akBGOe\" /><figcaption>Jinja2-style Loop in the WYSIWYG Editor</figcaption></figure><p>This screenshot includes examples of a few notable features. We’re using the new <em>li</em> tag with a <em>for</em> loop to create a bulleted list of findings. We have access to Jinja2 filters, including Ghostwriter’s custom filters, so we use the <em>filter_severity</em> filter to limit the loop to findings with a severity rating matching critical, high, or medium. The first and last bullets won’t be in the list in the final Word document.</p><p>The middle bullet will repeat for each finding to create our list. It includes the title and severity and uses the <em>regex_search</em> filter to pull the first sentence of the finding’s description. The use of <em>severity_rt</em> here is also worth a call-out. Some community members asked about nesting rich text fields inside of other rich text fields, like the pre-formatted <em>severity_rt</em> text for a finding. Not only can we use <em>severity_rt</em> inside this field, but we can also add formatting, like changing the text to bold.</p><p>Here is the above list rendered in a Word document. The pre-formatted <em>finding.severity_rt</em> appears with the proper color formatting and the bold formatting added in the WYSIWYG editor.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*ipUNCT0J8tyXZr3E\" /><figcaption>Output of the Jinja2 Loop in Microsoft Word</figcaption></figure><p>These additions introduced some complexity. A typo or syntax mistake could break the Jinja2 templating and prevent a report from generating, and the resulting error message wasn’t always helpful for tracking down the offending line of text. To help with this, Ghostwriter v4.2 validates your Jinja2 when you save your work, so you don’t need to worry about accidentally saving any invalid Jinja2 and causing a headache later on.</p><p>Validating the Jinja2 didn’t cover every possible issue, though. Even valid Jinja2 can fail to render if the report data causes an error (e.g., trying to divide by zero or referencing a non-existent value). To help with that, we significantly improved error handling to catch Jinja2 syntax and template errors at render time and surface more helpful information about them. When content prevents a report from generating, error messages point to the report’s section containing the problem.</p><p>In this example, a field called <em>exec_summ</em> contains this Jinja2 statement: <em>{{ 100/0 }}</em>. That’s valid Jinja2, but you can’t actually divide by zero, so rendering will always fail. With Ghostwriter v4.2’s error handling enhancements, the error message will direct us to the field name and include information we can use to track down the problem.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*dyVHfzW5GfAPEySJ\" /><figcaption>New Explicit Error Message for a Failed Report</figcaption></figure><h3>More Reporting Improvements</h3><p>Ghostwriter v4.2 also includes enhancements to the reporting engine. The most significant change is the introduction of project documents. You don’t always need to generate a full report with findings. You may need to generate other project-related documents before or after the assessment is done, like rules of engagement, statement of work, or attestation of testing documents. You could technically do this with older versions of Ghostwriter by generating a report with a different template, but that was not intuitive.</p><p>The project dashboard’s <em>Reports</em> tab is now called <em>Reporting</em> and contains an option to generate JSON, docx, or pptx reports with your project’s data. This works like the reports you’re familiar with but uses only the project data (e.g., no findings or report-specific values).</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*AK58kv5mCuOgLAbC\" /><figcaption>New Project Document Generation Under the Project Dashboard</figcaption></figure><p>We wanted to make it easier to generate project documents like this because custom fields open up many possibilities. For example, at SpecterOps, we provide clients with daily status reports after each day of testing. We can accomplish this task with a <em>Daily Status Report</em> field added to projects and the new project reporting feature. Consultants can now easily collaborate on updates to the daily status and then generate their daily status document from the same dashboard.</p><p>That’s not all, though. We realized one globally configured report filename would never apply to every possible document or report you might want to generate, so we made some changes. The biggest change is that your filename can now be configured using Jinja2-style templating with access to your project data, familiar filters, and a few additional values (e.g., `now` to include the current date and time). That means you can configure a filename like this that dynamically includes information about your project, client, and more:</p><p><em>{{now|format_datetime(“Y-m-d”)}} {{company_name}} — {{client.name}} {{project.project_type}} Report</em></p><p>That template would produce a filename like <em>2024–06–05 Acme Corp — SpecterOps Red Team Report.docx</em>. That’s great for a default, but you’d probably be renaming documents often as you expanded the types of documents generated with Ghostwriter. To help with that, we made it possible to configure separate global defaults for reports and project documents.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*uEng8blQo1lVZGJY\" /><figcaption>Jinja2 Templating for Default Filenames for Report Downloads</figcaption></figure><p>We also added the option to override the filename per template! To revisit the daily status report example, your Word template for such a report can override the global filename template with a filename template like <em>{{now|format_datetime(“Y-m-d”)}} {{company_name}} Daily Status Report</em>.</p><p>Another enhancement for this feature is a third template type, <em>Project DOCX</em>. You can use this to flag Microsoft Word templates that are intended only for project documents. Templates flagged with this type will only appear in the dropdown menu on the project dashboard. This will keep them out of the list of templates for your reports.</p><p>Finally, Ghostwriter v4.2 also includes a feature proposed by community member <a href=\"https://github.com/domwhewell-sage\">Dominic Whewell</a>, support for templating the document properties in your Word templates. If you set values like the document title, author(s), and company, you can now do that in your templates and let Ghostwriter fill in that information for you.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*xMBrrBOrU88qjKz-\" /><figcaption>Jinja2 Templating in Document Properties</figcaption></figure><h3>Background Tasks with Cron</h3><p>Ghostwriter v4.2 also contains various bug fixes and quality-of-life improvements. There are too many details here, but one worth mentioning is support for <em>cron</em> expressions with scheduled background tasks. Previously, you could schedule tasks to run at certain time intervals, but you couldn’t control some of the finer points, like the day of the week.</p><p>You can now use <em>cron</em> to schedule a task on a more refined schedule, like only on a specific day of the week or weekdays. When scheduling a task, select <em>Cron</em> for the <em>Schedule Type</em> and provide a <em>cron</em> expression–e.g., <em>00 12 * * 1–5</em> to run the task every weekday at 12:00.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*BZoGM1pGeIJBzcB8\" /><figcaption>Using Cron to Schedule a Background Task</figcaption></figure><p>Check out the full <a href=\"https://github.com/GhostManager/Ghostwriter/blob/master/CHANGELOG.md\"><em>CHANGELOG</em></a> for all the details on this release.</p><p><a href=\"https://github.com/GhostManager/Ghostwriter/releases/tag/v4.2.0\">Release Ghostwriter v4.2.0 · GhostManager/Ghostwriter</a></p><img src=\"https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=9fc10d77bf19\" width=\"1\" height=\"1\" alt=\"\"><hr><p><a href=\"https://posts.specterops.io/ghostwriter-v4-2-9fc10d77bf19\">Ghostwriter v4.2</a> was originally published in <a href=\"https://posts.specterops.io\">Posts By SpecterOps Team Members</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>",
      "content:encodedSnippet": "Ghostwriter v4.2: Project Documents & Reporting Enhancements\n\nAfter April’s massive Ghostwriter v4.1 release, we received some great feedback and ideas. We got a little carried away working on these and created a release so big we had to call it v4.2. This release contains some fantastic changes and additions to the features introduced in April’s release. Let’s get to the highlights!\nImproving Customizable Fields\nGhostwriter v4.1 introduced custom fields, and seeing the community use them so creatively was awesome. What we saw gave us some ideas for a few big improvements.\nThe rich text fields support the Jinja2 templating language, so loops quickly became a talking point. Looping over project objectives, findings, hosts, and other things to create dynamic lists, table rows, or sections is incredibly powerful, so we had to do it.\nYou can now use Jinja2-style expressions with the new li, tr, and p tags to create list items, table rows, and text sections. Here is an example of building a dynamic list inside Ghostwriter’s WYSIWYG editor.\nJinja2-style Loop in the WYSIWYG Editor\nThis screenshot includes examples of a few notable features. We’re using the new li tag with a for loop to create a bulleted list of findings. We have access to Jinja2 filters, including Ghostwriter’s custom filters, so we use the filter_severity filter to limit the loop to findings with a severity rating matching critical, high, or medium. The first and last bullets won’t be in the list in the final Word document.\nThe middle bullet will repeat for each finding to create our list. It includes the title and severity and uses the regex_search filter to pull the first sentence of the finding’s description. The use of severity_rt here is also worth a call-out. Some community members asked about nesting rich text fields inside of other rich text fields, like the pre-formatted severity_rt text for a finding. Not only can we use severity_rt inside this field, but we can also add formatting, like changing the text to bold.\nHere is the above list rendered in a Word document. The pre-formatted finding.severity_rt appears with the proper color formatting and the bold formatting added in the WYSIWYG editor.\nOutput of the Jinja2 Loop in Microsoft Word\nThese additions introduced some complexity. A typo or syntax mistake could break the Jinja2 templating and prevent a report from generating, and the resulting error message wasn’t always helpful for tracking down the offending line of text. To help with this, Ghostwriter v4.2 validates your Jinja2 when you save your work, so you don’t need to worry about accidentally saving any invalid Jinja2 and causing a headache later on.\nValidating the Jinja2 didn’t cover every possible issue, though. Even valid Jinja2 can fail to render if the report data causes an error (e.g., trying to divide by zero or referencing a non-existent value). To help with that, we significantly improved error handling to catch Jinja2 syntax and template errors at render time and surface more helpful information about them. When content prevents a report from generating, error messages point to the report’s section containing the problem.\nIn this example, a field called exec_summ contains this Jinja2 statement: {{ 100/0 }}. That’s valid Jinja2, but you can’t actually divide by zero, so rendering will always fail. With Ghostwriter v4.2’s error handling enhancements, the error message will direct us to the field name and include information we can use to track down the problem.\nNew Explicit Error Message for a Failed Report\nMore Reporting Improvements\nGhostwriter v4.2 also includes enhancements to the reporting engine. The most significant change is the introduction of project documents. You don’t always need to generate a full report with findings. You may need to generate other project-related documents before or after the assessment is done, like rules of engagement, statement of work, or attestation of testing documents. You could technically do this with older versions of Ghostwriter by generating a report with a different template, but that was not intuitive.\nThe project dashboard’s Reports tab is now called Reporting and contains an option to generate JSON, docx, or pptx reports with your project’s data. This works like the reports you’re familiar with but uses only the project data (e.g., no findings or report-specific values).\nNew Project Document Generation Under the Project Dashboard\nWe wanted to make it easier to generate project documents like this because custom fields open up many possibilities. For example, at SpecterOps, we provide clients with daily status reports after each day of testing. We can accomplish this task with a Daily Status Report field added to projects and the new project reporting feature. Consultants can now easily collaborate on updates to the daily status and then generate their daily status document from the same dashboard.\nThat’s not all, though. We realized one globally configured report filename would never apply to every possible document or report you might want to generate, so we made some changes. The biggest change is that your filename can now be configured using Jinja2-style templating with access to your project data, familiar filters, and a few additional values (e.g., `now` to include the current date and time). That means you can configure a filename like this that dynamically includes information about your project, client, and more:\n{{now|format_datetime(“Y-m-d”)}} {{company_name}} — {{client.name}} {{project.project_type}} Report\nThat template would produce a filename like 2024–06–05 Acme Corp — SpecterOps Red Team Report.docx. That’s great for a default, but you’d probably be renaming documents often as you expanded the types of documents generated with Ghostwriter. To help with that, we made it possible to configure separate global defaults for reports and project documents.\nJinja2 Templating for Default Filenames for Report Downloads\nWe also added the option to override the filename per template! To revisit the daily status report example, your Word template for such a report can override the global filename template with a filename template like {{now|format_datetime(“Y-m-d”)}} {{company_name}} Daily Status Report.\nAnother enhancement for this feature is a third template type, Project DOCX. You can use this to flag Microsoft Word templates that are intended only for project documents. Templates flagged with this type will only appear in the dropdown menu on the project dashboard. This will keep them out of the list of templates for your reports.\nFinally, Ghostwriter v4.2 also includes a feature proposed by community member Dominic Whewell, support for templating the document properties in your Word templates. If you set values like the document title, author(s), and company, you can now do that in your templates and let Ghostwriter fill in that information for you.\nJinja2 Templating in Document Properties\nBackground Tasks with Cron\nGhostwriter v4.2 also contains various bug fixes and quality-of-life improvements. There are too many details here, but one worth mentioning is support for cron expressions with scheduled background tasks. Previously, you could schedule tasks to run at certain time intervals, but you couldn’t control some of the finer points, like the day of the week.\nYou can now use cron to schedule a task on a more refined schedule, like only on a specific day of the week or weekdays. When scheduling a task, select Cron for the Schedule Type and provide a cron expression–e.g., 00 12 * * 1–5 to run the task every weekday at 12:00.\nUsing Cron to Schedule a Background Task\nCheck out the full CHANGELOG for all the details on this release.\nRelease Ghostwriter v4.2.0 · GhostManager/Ghostwriter\n\nGhostwriter v4.2 was originally published in Posts By SpecterOps Team Members on Medium, where people are continuing the conversation by highlighting and responding to this story.",
      "dc:creator": "Christopher Maddalena",
      "guid": "https://medium.com/p/9fc10d77bf19",
      "categories": [
        "red-team",
        "reporting",
        "project-management",
        "cybersecurity",
        "penetration-testing"
      ],
      "isoDate": "2024-06-10T20:01:29.000Z"
    }
  ],
  "feedUrl": "https://posts.specterops.io/feed",
  "image": {
    "link": "https://posts.specterops.io?source=rss----f05f8696e3cc---4",
    "url": "https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png",
    "title": "Posts By SpecterOps Team Members - Medium"
  },
  "paginationLinks": {
    "self": "https://posts.specterops.io/feed"
  },
  "title": "Posts By SpecterOps Team Members - Medium",
  "description": "Posts from SpecterOps team members on various topics relating information security - Medium",
  "webMaster": "yourfriends@medium.com",
  "generator": "Medium",
  "link": "https://posts.specterops.io?source=rss----f05f8696e3cc---4",
  "lastBuildDate": "Tue, 02 Jul 2024 22:39:44 GMT"
}